{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b864e043-ea87-4276-88e0-ce0e99530902",
   "metadata": {
    "id": "b864e043-ea87-4276-88e0-ce0e99530902"
   },
   "source": [
    "## Timeline for the project\n",
    "That will also be our next meeting times.\n",
    "* 4/19-20 try to have dimensionality reduction done.\n",
    "* 4/26-27 have the best models tuned and selected for the ensemble classification portion to put it together.\n",
    "* 5/3-4 or earlier we will get together to do the presentation\n",
    "* 5/13-14 or earlier we will get together to do the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9730d92-5cc4-473b-8145-bbd4a015c44a",
   "metadata": {
    "id": "d9730d92-5cc4-473b-8145-bbd4a015c44a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rqM3l2sVGHQ5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqM3l2sVGHQ5",
    "outputId": "1d463af3-0f3b-47ed-ea4c-855e063a2324"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madilshamim8/student-depression-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"adilshamim8/student-depression-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40653fa5-6c60-4a2d-b063-8aca74ab33c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "40653fa5-6c60-4a2d-b063-8aca74ab33c6",
    "outputId": "066b70de-727d-4109-9759-f54a6e91b608"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>Work Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Job Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Student</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Student</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Srinagar</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BA</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Student</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Student</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>PhD</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Student</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>'Class 12'</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Ed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Nashik</td>\n",
       "      <td>Student</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>LLB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender   Age           City Profession  Academic Pressure  \\\n",
       "0   2    Male  33.0  Visakhapatnam    Student                5.0   \n",
       "1   8  Female  24.0      Bangalore    Student                2.0   \n",
       "2  26    Male  31.0       Srinagar    Student                3.0   \n",
       "3  30  Female  28.0       Varanasi    Student                3.0   \n",
       "4  32  Female  25.0         Jaipur    Student                4.0   \n",
       "5  33    Male  29.0           Pune    Student                2.0   \n",
       "6  52    Male  30.0          Thane    Student                3.0   \n",
       "7  56  Female  30.0        Chennai    Student                2.0   \n",
       "8  59    Male  28.0         Nagpur    Student                3.0   \n",
       "9  62    Male  31.0         Nashik    Student                2.0   \n",
       "\n",
       "   Work Pressure  CGPA  Study Satisfaction  Job Satisfaction  \\\n",
       "0            0.0  8.97                 2.0               0.0   \n",
       "1            0.0  5.90                 5.0               0.0   \n",
       "2            0.0  7.03                 5.0               0.0   \n",
       "3            0.0  5.59                 2.0               0.0   \n",
       "4            0.0  8.13                 3.0               0.0   \n",
       "5            0.0  5.70                 3.0               0.0   \n",
       "6            0.0  9.54                 4.0               0.0   \n",
       "7            0.0  8.04                 4.0               0.0   \n",
       "8            0.0  9.79                 1.0               0.0   \n",
       "9            0.0  8.38                 3.0               0.0   \n",
       "\n",
       "        Sleep Duration Dietary Habits      Degree  \\\n",
       "0          '5-6 hours'        Healthy     B.Pharm   \n",
       "1          '5-6 hours'       Moderate         BSc   \n",
       "2  'Less than 5 hours'        Healthy          BA   \n",
       "3          '7-8 hours'       Moderate         BCA   \n",
       "4          '5-6 hours'       Moderate      M.Tech   \n",
       "5  'Less than 5 hours'        Healthy         PhD   \n",
       "6          '7-8 hours'        Healthy         BSc   \n",
       "7  'Less than 5 hours'      Unhealthy  'Class 12'   \n",
       "8          '7-8 hours'       Moderate        B.Ed   \n",
       "9  'Less than 5 hours'       Moderate         LLB   \n",
       "\n",
       "  Have you ever had suicidal thoughts ?  Work/Study Hours Financial Stress  \\\n",
       "0                                   Yes               3.0              1.0   \n",
       "1                                    No               3.0              2.0   \n",
       "2                                    No               9.0              1.0   \n",
       "3                                   Yes               4.0              5.0   \n",
       "4                                   Yes               1.0              1.0   \n",
       "5                                    No               4.0              1.0   \n",
       "6                                    No               1.0              2.0   \n",
       "7                                    No               0.0              1.0   \n",
       "8                                   Yes              12.0              3.0   \n",
       "9                                   Yes               2.0              5.0   \n",
       "\n",
       "  Family History of Mental Illness  Depression  \n",
       "0                               No           1  \n",
       "1                              Yes           0  \n",
       "2                              Yes           0  \n",
       "3                              Yes           1  \n",
       "4                               No           0  \n",
       "5                               No           0  \n",
       "6                               No           0  \n",
       "7                              Yes           0  \n",
       "8                               No           1  \n",
       "9                               No           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/student_depression_dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e26cd0-f395-46db-8414-cec1cdf4ea79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "b8e26cd0-f395-46db-8414-cec1cdf4ea79",
    "outputId": "f4a482b2-db74-49d5-ab63-55a0426206db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       27901\n",
       "Gender                                   27901\n",
       "Age                                      27901\n",
       "City                                     27901\n",
       "Profession                               27901\n",
       "Academic Pressure                        27901\n",
       "Work Pressure                            27901\n",
       "CGPA                                     27901\n",
       "Study Satisfaction                       27901\n",
       "Job Satisfaction                         27901\n",
       "Sleep Duration                           27901\n",
       "Dietary Habits                           27901\n",
       "Degree                                   27901\n",
       "Have you ever had suicidal thoughts ?    27901\n",
       "Work/Study Hours                         27901\n",
       "Financial Stress                         27901\n",
       "Family History of Mental Illness         27901\n",
       "Depression                               27901\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90bec90-a46e-4cbd-b8a2-3b5174e723c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "a90bec90-a46e-4cbd-b8a2-3b5174e723c9",
    "outputId": "436f5c9f-ba0d-4831-9e70-3fa45a828df3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Depression\n",
       "1    16336\n",
       "0    11565\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31422029-29b7-4f9d-bee2-ac25a7bebdc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31422029-29b7-4f9d-bee2-ac25a7bebdc0",
    "outputId": "c5477c6d-abef-4b36-9c47-1b0d4f0197a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5854987276441704"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16336 / 27901 # class balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096bed6f-5b54-49d9-bc88-10fc558b31f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "096bed6f-5b54-49d9-bc88-10fc558b31f0",
    "outputId": "1b1dbc98-15f6-470d-fc11-09ee996a1944"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41450127235582956"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11565 / 27901 # class balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc867074-e342-4862-8774-a0fd4c91952d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "bc867074-e342-4862-8774-a0fd4c91952d",
    "outputId": "0aec90c2-4e90-4bb8-ddcd-1a0c84628847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                         int64\n",
       "Gender                                    object\n",
       "Age                                      float64\n",
       "City                                      object\n",
       "Profession                                object\n",
       "Academic Pressure                        float64\n",
       "Work Pressure                            float64\n",
       "CGPA                                     float64\n",
       "Study Satisfaction                       float64\n",
       "Job Satisfaction                         float64\n",
       "Sleep Duration                            object\n",
       "Dietary Habits                            object\n",
       "Degree                                    object\n",
       "Have you ever had suicidal thoughts ?     object\n",
       "Work/Study Hours                         float64\n",
       "Financial Stress                          object\n",
       "Family History of Mental Illness          object\n",
       "Depression                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280b736d-a638-4931-a429-fe4b7e854364",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "280b736d-a638-4931-a429-fe4b7e854364",
    "outputId": "76f883f3-b5b6-456b-958b-52c4cd25d83b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='CGPA'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAGwCAYAAADMjZ3mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVHElEQVR4nO3dfWxVhd3A8V+ppRSFsroINBZSJsoQnQ7mfBvMKZgpJsxkTh1qQgyaoJNhNnWauC0RJnP+seHLusmcjzGyRTZfljk7NTBnFolSNWpkRgRnp2RjlHdEep4/DH2ePj/YfGrbUy6fT3JD7jm39/7uoeV8Offc3qqiKIoAAPhfBpU9AAAw8AgEACARCABAIhAAgEQgAACJQAAAEoEAACSH9PQLOzs7o729PYYNGxZVVVW9ORMA0EeKoogtW7ZEY2NjDBq0/+MEPQ6E9vb2aGpq6umXAwAlevvtt+PII4/c7/oeB8KwYcO6HmD48OE9vRsAoB9t3rw5mpqauvbj+9PjQNj7ssLw4cMFAgAcYP7T6QFOUgQAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAkkPKHgCgTO+99150dHSUPQZ9oL6+PkaOHFn2GAcsgQActN57772Yfcmlsfv9XWWPQh+oGVwb9//XfSKhhwQCcNDq6OiI3e/vih3jpkXnkPqyxynVoB2bom7tytjRPDU660aUPc7HNmhnR8SbK6Kjo0Mg9JBAAA56nUPqo/PQT5Y9xoDQWTfCtiAinKQIAOyDQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCMA+7dy5M9asWRM7d+4sexQ46AyEnz+BAOzT+vXrY+7cubF+/fqyR4GDzkD4+RMIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAACSARUI7e3tMXPmzDjzzDNj5syZ0d7eXvZIAHBQOqTsAfaaPn167N69u+v61q1b4+KLL46amppobW0tcTIAOPgMiCMI/zsOGhoa4oYbboiGhoaIiNi9e3dMnz69zPEA4KBT+hGE9vb2rjhYvnx5VxicffbZsXHjxjj//PNj9+7d0d7eHo2NjWWOCgAHjY8cCLt27Ypdu3Z1Xd+8eXOvDDB37tyI+PDIwd442Gvvso0bN8bcuXPjscce65XHBD66devWlT1Cn6nk58aHDtS/44Ew90cOhEWLFsX3vve9Xh9gx44dERFxxRVX7HP9nDlz4rbbbuu6HdC/brnllrJHgB7z/dtzHzkQbrjhhliwYEHX9c2bN0dTU9PHHqCuri62bt0aP/3pT+Pss89O65cuXdp1O6D/3XjjjTF27Niyx+gT69atswOpcAfq9+9A+N78yIFQW1sbtbW1vT5AS0tLXHzxxbFx48bYuHFjt5cZ9i7bezug/40dOzaOPvrosseAHvH923Oln6TY2NgYNTU1sXv37jj//POjoaEh5syZE0uXLu2Kg5qaGicoAkA/GhBvc2xtbY2ampqI+PCowW233dYtDvweBADoX6UfQdirtbU12tvbY+7cubFjx46oq6uLlpYWRw4AoAQDJhAiPny5wVsZAaB8A+IlBgBgYBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAPZpzJgx0dLSEmPGjCl7FDjoDISfv0NKe2RgQBsyZEgcffTRZY8BB6WB8PPnCAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAEoEAACQCAQBIBAIAkAgEACARCABAIhAAgEQgAACJQAAAkkPKHgCgbIN2dpQ9QukG7djU7c8Dnb/Tj08gAAet+vr6qBlcG/HmirJHGTDq1q4se4ReUzO4Nurr68se44AlEICD1siRI+P+/7ovOjr8b7MS1dfXx8iRI8se44AlEICD2siRI+1EYB+cpAgAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCAAAIlAAAASgQAAJIf09AuLooiIiM2bN/faMABA39q73967H9+fHgfCli1bIiKiqampp3cBAJRky5YtUV9fv9/1VcV/Soj96OzsjPb29hg2bFhUVVX1eMD/a/PmzdHU1BRvv/12DB8+vNful8y27h+2c/+wnfuH7dw/+nI7F0URW7ZsicbGxhg0aP9nGvT4CMKgQYPiyCOP7OmX/0fDhw/3zddPbOv+YTv3D9u5f9jO/aOvtvO/O3Kwl5MUAYBEIAAAyYALhNra2rj55pujtra27FEqnm3dP2zn/mE79w/buX8MhO3c45MUAYDKNeCOIAAA5RMIAEAiEACARCAAAMmAC4Q777wzmpubY8iQITF58uT405/+VPZIFWXRokXxuc99LoYNGxZHHHFEzJo1K15//fWyx6p4ixYtiqqqqpg/f37Zo1Skd955J2bPnh2HH354DB06NE444YR4/vnnyx6ronzwwQdx0003RXNzc9TV1cW4cePi+9//fnR2dpY92gFt5cqVcd5550VjY2NUVVXFb3/7227ri6KI7373u9HY2Bh1dXXxxS9+MV555ZV+mW1ABcKyZcti/vz5ceONN8bq1avjC1/4Qnz5y1+O9evXlz1axVixYkXMmzcv/vKXv0Rra2t88MEHMWPGjNi2bVvZo1WsVatWRUtLSxx//PFlj1KR/vWvf8Vpp50WNTU18fvf/z5effXV+NGPfhQjRowoe7SKcuutt8bdd98dS5Ysiddeey0WL14cP/zhD+MnP/lJ2aMd0LZt2xaf+cxnYsmSJftcv3jx4rj99ttjyZIlsWrVqhg1alRMnz696/OQ+lQxgJx00knFlVde2W3ZhAkTiuuvv76kiSrfhg0biogoVqxYUfYoFWnLli3F+PHji9bW1mLatGnFNddcU/ZIFee6664rTj/99LLHqHjnnntuMWfOnG7Lzj///GL27NklTVR5IqL4zW9+03W9s7OzGDVqVPGDH/yga9nOnTuL+vr64u677+7zeQbMEYT3338/nn/++ZgxY0a35TNmzIhnn322pKkqX0dHR0RENDQ0lDxJZZo3b16ce+65cdZZZ5U9SsV65JFHYsqUKfHVr341jjjiiDjxxBPjZz/7WdljVZzTTz89nnzyyVizZk1ERLz44ovxzDPPxDnnnFPyZJVr7dq18e6773bbL9bW1sa0adP6Zb/Y4w9r6m3/+Mc/Ys+ePTFy5Mhuy0eOHBnvvvtuSVNVtqIoYsGCBXH66afHpEmTyh6n4jz44IPxwgsvxKpVq8oepaK9+eabcdddd8WCBQviO9/5Tjz33HPxjW98I2pra+PSSy8te7yKcd1110VHR0dMmDAhqqurY8+ePXHLLbfERRddVPZoFWvvvm9f+8V169b1+eMPmEDY6/9+dHRRFL36cdL8j6uuuipeeumleOaZZ8oepeK8/fbbcc0118QTTzwRQ4YMKXucitbZ2RlTpkyJhQsXRkTEiSeeGK+88krcddddAqEXLVu2LO6///544IEH4thjj422traYP39+NDY2xmWXXVb2eBWtrP3igAmET37yk1FdXZ2OFmzYsCHVEx/f1VdfHY888kisXLmyTz+2+2D1/PPPx4YNG2Ly5Mldy/bs2RMrV66MJUuWxK5du6K6urrECSvH6NGjY+LEid2WffrTn46HHnqopIkq07e+9a24/vrr48ILL4yIiOOOOy7WrVsXixYtEgh9ZNSoURHx4ZGE0aNHdy3vr/3igDkHYfDgwTF58uRobW3ttry1tTVOPfXUkqaqPEVRxFVXXRXLly+Pp556Kpqbm8seqSKdeeaZ8fLLL0dbW1vXZcqUKfH1r3892traxEEvOu2009JbddesWRNjx44taaLKtH379hg0qPsuo7q62tsc+1Bzc3OMGjWq237x/fffjxUrVvTLfnHAHEGIiFiwYEFccsklMWXKlDjllFOipaUl1q9fH1deeWXZo1WMefPmxQMPPBAPP/xwDBs2rOuITX19fdTV1ZU8XeUYNmxYOq/j0EMPjcMPP9z5Hr3sm9/8Zpx66qmxcOHCuOCCC+K5556LlpaWaGlpKXu0inLeeefFLbfcEmPGjIljjz02Vq9eHbfffnvMmTOn7NEOaFu3bo033nij6/ratWujra0tGhoaYsyYMTF//vxYuHBhjB8/PsaPHx8LFy6MoUOHxsUXX9z3w/X5+yT+n+64445i7NixxeDBg4vPfvaz3n7XyyJin5df/OIXZY9W8bzNse88+uijxaRJk4ra2tpiwoQJRUtLS9kjVZzNmzcX11xzTTFmzJhiyJAhxbhx44obb7yx2LVrV9mjHdCefvrpff6bfNlllxVF8eFbHW+++eZi1KhRRW1tbTF16tTi5Zdf7pfZfNwzAJAMmHMQAICBQyAAAIlAAAASgQAAJAIBAEgEAgCQCAQAIBEIAEAiEACARCBAhXr33Xfj6quvjnHjxkVtbW00NTXFeeedF08++WTXbVavXh1f+9rXYvTo0VFbWxtjx46NmTNnxqOPPhp7f8nqW2+9FVVVVV2XT3ziEzF16tRYsWJFt8f729/+FoMHD44JEyb06/ME+oZAgAr01ltvxeTJk+Opp56KxYsXx8svvxyPP/54nHHGGTFv3ryIiHj44Yfj5JNPjq1bt8Yvf/nLePXVV+PXv/51zJo1K2666abo6Ojodp9//OMf4+9//3usWLEihg8fHuecc06sXbu2a/29994bF1xwQWzfvj3+/Oc/9+vzBXqfz2KACnTOOefESy+9FK+//noceuih3dZt2rQpampqYuzYsTF16tRYvnz5Pu+jKIqoqqqKt956K5qbm2P16tVxwgknRETEO++8E0ceeWTcfffdccUVV0RRFHHUUUfFnXfeGU8//XRs2LAhli5d2tdPE+hDjiBAhdm4cWM8/vjjMW/evBQHEREjRoyIJ554Iv75z3/Gt7/97f3eT1VV1X7XDR06NCIidu/eHRERTz/9dGzfvj3OOuusuOSSS+JXv/pVbNmy5WM+E6BMAgEqzBtvvBFFUfzbcwHWrFkTERHHHHNM17JVq1bFYYcd1nV57LHH9vm127ZtixtuuCGqq6tj2rRpERFxzz33xIUXXhjV1dVx7LHHxlFHHRXLli3rxWcF9LdDyh4A6F17XzX8d0cA9uX444+Ptra2iIgYP358fPDBB93Wn3rqqTFo0KDYvn17jB49Ou6999447rjjYtOmTbF8+fJ45plnum47e/bsWLp0aVx++eUf78kApREIUGHGjx8fVVVV8dprr8WsWbP2e5uIiNdffz1OPvnkiIiora2No446ar/3u2zZspg4cWKMGDEiDj/88K7lDzzwQOzcuTM+//nPdy0riiI6Ozvj1VdfjYkTJ/bCswL6m5cYoMI0NDTE2WefHXfccUds27Ytrd+0aVPMmDEjGhoa4tZbb/3I99vU1BSf+tSnusVBxIcvL1x77bXR1tbWdXnxxRfjjDPOcKIiHMAEAlSgO++8M/bs2RMnnXRSPPTQQ/HXv/41Xnvttfjxj38cp5xyShx22GHx85//PH73u9/FueeeG3/4wx/izTffjJdeeikWL14cERHV1dX/8XHa2trihRdeiMsvvzwmTZrU7XLRRRfFfffd13UiI3BgEQhQgZqbm+OFF16IM844I6699tqYNGlSTJ8+PZ588sm46667IiLiK1/5Sjz77LMxdOjQuPTSS+OYY46JL33pS/HUU0/Fgw8+GDNnzvyPj3PPPffExIkT93lC5KxZs2Ljxo3x6KOP9vrzA/qe34MAACSOIAAAiUAAABKBAAAkAgEASAQCAJAIBAAgEQgAQCIQAIBEIAAAiUAAABKBAAAk/w0SIgxd3t3aHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=df['CGPA']) # Looking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafe518b-8dbc-4cc0-99dc-d67ac260104a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "eafe518b-8dbc-4cc0-99dc-d67ac260104a",
    "outputId": "6f595e28-85c4-4ba5-b1d1-de491bad62ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Have you ever had suicidal thoughts ?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BA</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>PhD</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>'Class 12'</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>B.Ed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>LLB</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Academic Pressure  CGPA  Study Satisfaction  \\\n",
       "0    Male  33.0                5.0  8.97                 2.0   \n",
       "1  Female  24.0                2.0  5.90                 5.0   \n",
       "2    Male  31.0                3.0  7.03                 5.0   \n",
       "3  Female  28.0                3.0  5.59                 2.0   \n",
       "4  Female  25.0                4.0  8.13                 3.0   \n",
       "5    Male  29.0                2.0  5.70                 3.0   \n",
       "6    Male  30.0                3.0  9.54                 4.0   \n",
       "7  Female  30.0                2.0  8.04                 4.0   \n",
       "8    Male  28.0                3.0  9.79                 1.0   \n",
       "9    Male  31.0                2.0  8.38                 3.0   \n",
       "\n",
       "        Sleep Duration Dietary Habits      Degree  \\\n",
       "0          '5-6 hours'        Healthy     B.Pharm   \n",
       "1          '5-6 hours'       Moderate         BSc   \n",
       "2  'Less than 5 hours'        Healthy          BA   \n",
       "3          '7-8 hours'       Moderate         BCA   \n",
       "4          '5-6 hours'       Moderate      M.Tech   \n",
       "5  'Less than 5 hours'        Healthy         PhD   \n",
       "6          '7-8 hours'        Healthy         BSc   \n",
       "7  'Less than 5 hours'      Unhealthy  'Class 12'   \n",
       "8          '7-8 hours'       Moderate        B.Ed   \n",
       "9  'Less than 5 hours'       Moderate         LLB   \n",
       "\n",
       "  Have you ever had suicidal thoughts ?  Work/Study Hours Financial Stress  \\\n",
       "0                                   Yes               3.0              1.0   \n",
       "1                                    No               3.0              2.0   \n",
       "2                                    No               9.0              1.0   \n",
       "3                                   Yes               4.0              5.0   \n",
       "4                                   Yes               1.0              1.0   \n",
       "5                                    No               4.0              1.0   \n",
       "6                                    No               1.0              2.0   \n",
       "7                                    No               0.0              1.0   \n",
       "8                                   Yes              12.0              3.0   \n",
       "9                                   Yes               2.0              5.0   \n",
       "\n",
       "  Family History of Mental Illness  Depression  \n",
       "0                               No           1  \n",
       "1                              Yes           0  \n",
       "2                              Yes           0  \n",
       "3                              Yes           1  \n",
       "4                               No           0  \n",
       "5                               No           0  \n",
       "6                               No           0  \n",
       "7                              Yes           0  \n",
       "8                               No           1  \n",
       "9                               No           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop id, city, profession, work pressure, job satisfaction\n",
    "df = df.drop(['id','City', 'Profession', 'Work Pressure', 'Job Satisfaction'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149eadbb-6061-45e6-905f-6c99687ba445",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "149eadbb-6061-45e6-905f-6c99687ba445",
    "outputId": "4a72f92b-e844-472a-dd3d-44611c7eed95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>History of suicidal thoughts?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>B.Pharm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BSc</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>BA</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>BCA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Academic Pressure  CGPA  Study Satisfaction  \\\n",
       "0    Male  33.0                5.0  8.97                 2.0   \n",
       "1  Female  24.0                2.0  5.90                 5.0   \n",
       "2    Male  31.0                3.0  7.03                 5.0   \n",
       "3  Female  28.0                3.0  5.59                 2.0   \n",
       "4  Female  25.0                4.0  8.13                 3.0   \n",
       "\n",
       "        Sleep Duration Dietary Habits   Degree History of suicidal thoughts?  \\\n",
       "0          '5-6 hours'        Healthy  B.Pharm                           Yes   \n",
       "1          '5-6 hours'       Moderate      BSc                            No   \n",
       "2  'Less than 5 hours'        Healthy       BA                            No   \n",
       "3          '7-8 hours'       Moderate      BCA                           Yes   \n",
       "4          '5-6 hours'       Moderate   M.Tech                           Yes   \n",
       "\n",
       "   Work/Study Hours Financial Stress Family History of Mental Illness  \\\n",
       "0               3.0              1.0                               No   \n",
       "1               3.0              2.0                              Yes   \n",
       "2               9.0              1.0                              Yes   \n",
       "3               4.0              5.0                              Yes   \n",
       "4               1.0              1.0                               No   \n",
       "\n",
       "   Depression  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"Have you ever had suicidal thoughts ?\": \"History of suicidal thoughts?\"})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b77b75d-81b0-49b7-bebe-08fa32b93ac3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7b77b75d-81b0-49b7-bebe-08fa32b93ac3",
    "outputId": "8262108c-03f3-4641-e99d-9ea6b6761e68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sleep Duration     \n",
       "'Less than 5 hours'    8310\n",
       "'7-8 hours'            7346\n",
       "'5-6 hours'            6183\n",
       "'More than 8 hours'    6044\n",
       "Others                   18\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Degree    \n",
       "'Class 12'    6080\n",
       "B.Ed          1867\n",
       "B.Com         1506\n",
       "B.Arch        1478\n",
       "BCA           1433\n",
       "MSc           1190\n",
       "B.Tech        1152\n",
       "MCA           1044\n",
       "M.Tech        1022\n",
       "BHM            925\n",
       "BSc            888\n",
       "M.Ed           821\n",
       "B.Pharm        810\n",
       "M.Com          734\n",
       "MBBS           696\n",
       "BBA            696\n",
       "LLB            671\n",
       "BE             613\n",
       "BA             600\n",
       "M.Pharm        582\n",
       "MD             572\n",
       "MBA            562\n",
       "MA             544\n",
       "PhD            522\n",
       "LLM            482\n",
       "MHM            191\n",
       "ME             185\n",
       "Others          35\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# May need to prep that data now, take the top 3 answers for sleep duration and the rest can be other,\n",
    "# change degree column to be more general\n",
    "display(df.value_counts(['Sleep Duration'])) # ask about how many categories we wanted to have for this\n",
    "display(df.value_counts(['Degree']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1300202f-f32d-4d3c-9eb8-f70759bf09bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "1300202f-f32d-4d3c-9eb8-f70759bf09bf",
    "outputId": "40e3a889-d3ad-43b8-efe1-4d730fab400a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Sleep Duration</th>\n",
       "      <th>Dietary Habits</th>\n",
       "      <th>Degree</th>\n",
       "      <th>History of suicidal thoughts?</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Family History of Mental Illness</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'5-6 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Unhealthy</td>\n",
       "      <td>HighSchool/GED</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>'7-8 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.0</td>\n",
       "      <td>'Less than 5 hours'</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Academic Pressure  CGPA  Study Satisfaction  \\\n",
       "0    Male  33.0                5.0  8.97                 2.0   \n",
       "1  Female  24.0                2.0  5.90                 5.0   \n",
       "2    Male  31.0                3.0  7.03                 5.0   \n",
       "3  Female  28.0                3.0  5.59                 2.0   \n",
       "4  Female  25.0                4.0  8.13                 3.0   \n",
       "5    Male  29.0                2.0  5.70                 3.0   \n",
       "6    Male  30.0                3.0  9.54                 4.0   \n",
       "7  Female  30.0                2.0  8.04                 4.0   \n",
       "8    Male  28.0                3.0  9.79                 1.0   \n",
       "9    Male  31.0                2.0  8.38                 3.0   \n",
       "\n",
       "        Sleep Duration Dietary Habits          Degree  \\\n",
       "0          '5-6 hours'        Healthy      Bachelor's   \n",
       "1          '5-6 hours'       Moderate      Bachelor's   \n",
       "2  'Less than 5 hours'        Healthy      Bachelor's   \n",
       "3          '7-8 hours'       Moderate      Bachelor's   \n",
       "4          '5-6 hours'       Moderate        Master's   \n",
       "5  'Less than 5 hours'        Healthy       Doctorate   \n",
       "6          '7-8 hours'        Healthy      Bachelor's   \n",
       "7  'Less than 5 hours'      Unhealthy  HighSchool/GED   \n",
       "8          '7-8 hours'       Moderate      Bachelor's   \n",
       "9  'Less than 5 hours'       Moderate      Bachelor's   \n",
       "\n",
       "  History of suicidal thoughts?  Work/Study Hours Financial Stress  \\\n",
       "0                           Yes               3.0              1.0   \n",
       "1                            No               3.0              2.0   \n",
       "2                            No               9.0              1.0   \n",
       "3                           Yes               4.0              5.0   \n",
       "4                           Yes               1.0              1.0   \n",
       "5                            No               4.0              1.0   \n",
       "6                            No               1.0              2.0   \n",
       "7                            No               0.0              1.0   \n",
       "8                           Yes              12.0              3.0   \n",
       "9                           Yes               2.0              5.0   \n",
       "\n",
       "  Family History of Mental Illness  Depression  \n",
       "0                               No           1  \n",
       "1                              Yes           0  \n",
       "2                              Yes           0  \n",
       "3                              Yes           1  \n",
       "4                               No           0  \n",
       "5                               No           0  \n",
       "6                               No           0  \n",
       "7                              Yes           0  \n",
       "8                               No           1  \n",
       "9                               No           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simplify_degree(degree):\n",
    "    if degree == \"MBBS\":\n",
    "        return \"Bachelor's\"\n",
    "    elif \"PhD\" in degree:\n",
    "        return \"Doctorate\"\n",
    "    elif \"B\" in degree:\n",
    "        return \"Bachelor's\"\n",
    "    elif \"M\" in degree:\n",
    "        return \"Master's\"\n",
    "    elif \"Class\" in degree:\n",
    "        return \"HighSchool/GED\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the function to the Degree column\n",
    "df['Degree'] = df['Degree'].apply(simplify_degree)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3061a75d-c35a-4010-8c0c-d8b4f8ab99ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3061a75d-c35a-4010-8c0c-d8b4f8ab99ec",
    "outputId": "345d292b-34b9-418e-d153-dbc63c9c9d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Stress\n",
      "5.0    6715\n",
      "4.0    5775\n",
      "3.0    5226\n",
      "1.0    5121\n",
      "2.0    5061\n",
      "?         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Found three non-numeric values in Financial Stress and need to make ? value an na\n",
    "print(df['Financial Stress'].value_counts())\n",
    "\n",
    "df['Financial Stress'] = np.where(df['Financial Stress'] == '?', np.nan, df['Financial Stress'])\n",
    "\n",
    "df['Financial Stress'] = df['Financial Stress'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "195bfdaa-d763-4975-a4c2-073263d851f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "195bfdaa-d763-4975-a4c2-073263d851f2",
    "outputId": "1219856b-1ace-4ddd-9fd1-b2a4c5bd350b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                              0\n",
      "Age                                 0\n",
      "Academic Pressure                   0\n",
      "CGPA                                0\n",
      "Study Satisfaction                  0\n",
      "Sleep Duration                      0\n",
      "Dietary Habits                      0\n",
      "Degree                              0\n",
      "History of suicidal thoughts?       0\n",
      "Work/Study Hours                    0\n",
      "Financial Stress                    3\n",
      "Family History of Mental Illness    0\n",
      "Depression                          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Summing all of the missing values by column\n",
    "missing_val_cols = df.isnull().sum()\n",
    "\n",
    "print(missing_val_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81e2040e-8f5f-4c44-ba64-e0a9edfc5901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "81e2040e-8f5f-4c44-ba64-e0a9edfc5901",
    "outputId": "2f6491c3-39c5-475c-ffc2-163c3d707582"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Sleep Duration_'7-8 hours'</th>\n",
       "      <th>Sleep Duration_'Less than 5 hours'</th>\n",
       "      <th>Sleep Duration_'More than 8 hours'</th>\n",
       "      <th>Sleep Duration_Others</th>\n",
       "      <th>Dietary Habits_Moderate</th>\n",
       "      <th>Dietary Habits_Others</th>\n",
       "      <th>Dietary Habits_Unhealthy</th>\n",
       "      <th>Degree_Doctorate</th>\n",
       "      <th>Degree_HighSchool/GED</th>\n",
       "      <th>Degree_Master's</th>\n",
       "      <th>Degree_Other</th>\n",
       "      <th>History of suicidal thoughts?_Yes</th>\n",
       "      <th>Family History of Mental Illness_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.97</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27896</th>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27897</th>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27898</th>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.61</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27899</th>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.88</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27900</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27901 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Academic Pressure  CGPA  Study Satisfaction  Work/Study Hours  \\\n",
       "0      33.0                5.0  8.97                 2.0               3.0   \n",
       "1      24.0                2.0  5.90                 5.0               3.0   \n",
       "2      31.0                3.0  7.03                 5.0               9.0   \n",
       "3      28.0                3.0  5.59                 2.0               4.0   \n",
       "4      25.0                4.0  8.13                 3.0               1.0   \n",
       "...     ...                ...   ...                 ...               ...   \n",
       "27896  27.0                5.0  5.75                 5.0               7.0   \n",
       "27897  27.0                2.0  9.40                 3.0               0.0   \n",
       "27898  31.0                3.0  6.61                 4.0              12.0   \n",
       "27899  18.0                5.0  6.88                 2.0              10.0   \n",
       "27900  27.0                4.0  9.24                 1.0               2.0   \n",
       "\n",
       "       Financial Stress  Gender_Male  Sleep Duration_'7-8 hours'  \\\n",
       "0                   1.0         True                       False   \n",
       "1                   2.0        False                       False   \n",
       "2                   1.0         True                       False   \n",
       "3                   5.0        False                        True   \n",
       "4                   1.0        False                       False   \n",
       "...                 ...          ...                         ...   \n",
       "27896               1.0        False                       False   \n",
       "27897               3.0         True                       False   \n",
       "27898               2.0         True                       False   \n",
       "27899               5.0        False                       False   \n",
       "27900               3.0         True                       False   \n",
       "\n",
       "       Sleep Duration_'Less than 5 hours'  Sleep Duration_'More than 8 hours'  \\\n",
       "0                                   False                               False   \n",
       "1                                   False                               False   \n",
       "2                                    True                               False   \n",
       "3                                   False                               False   \n",
       "4                                   False                               False   \n",
       "...                                   ...                                 ...   \n",
       "27896                               False                               False   \n",
       "27897                                True                               False   \n",
       "27898                               False                               False   \n",
       "27899                                True                               False   \n",
       "27900                                True                               False   \n",
       "\n",
       "       Sleep Duration_Others  Dietary Habits_Moderate  Dietary Habits_Others  \\\n",
       "0                      False                    False                  False   \n",
       "1                      False                     True                  False   \n",
       "2                      False                    False                  False   \n",
       "3                      False                     True                  False   \n",
       "4                      False                     True                  False   \n",
       "...                      ...                      ...                    ...   \n",
       "27896                  False                    False                  False   \n",
       "27897                  False                    False                  False   \n",
       "27898                  False                    False                  False   \n",
       "27899                  False                    False                  False   \n",
       "27900                  False                    False                  False   \n",
       "\n",
       "       Dietary Habits_Unhealthy  Degree_Doctorate  Degree_HighSchool/GED  \\\n",
       "0                         False             False                  False   \n",
       "1                         False             False                  False   \n",
       "2                         False             False                  False   \n",
       "3                         False             False                  False   \n",
       "4                         False             False                  False   \n",
       "...                         ...               ...                    ...   \n",
       "27896                      True             False                   True   \n",
       "27897                     False             False                  False   \n",
       "27898                      True             False                  False   \n",
       "27899                     False             False                   True   \n",
       "27900                     False             False                  False   \n",
       "\n",
       "       Degree_Master's  Degree_Other  History of suicidal thoughts?_Yes  \\\n",
       "0                False         False                               True   \n",
       "1                False         False                              False   \n",
       "2                False         False                              False   \n",
       "3                False         False                               True   \n",
       "4                 True         False                               True   \n",
       "...                ...           ...                                ...   \n",
       "27896            False         False                               True   \n",
       "27897             True         False                              False   \n",
       "27898             True         False                              False   \n",
       "27899            False         False                               True   \n",
       "27900            False         False                               True   \n",
       "\n",
       "       Family History of Mental Illness_Yes  \n",
       "0                                     False  \n",
       "1                                      True  \n",
       "2                                      True  \n",
       "3                                      True  \n",
       "4                                     False  \n",
       "...                                     ...  \n",
       "27896                                  True  \n",
       "27897                                  True  \n",
       "27898                                 False  \n",
       "27899                                 False  \n",
       "27900                                  True  \n",
       "\n",
       "[27901 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## need to one hot encode the categorical columns\n",
    "X = df.drop(['Depression'], axis=1)\n",
    "y = df['Depression']\n",
    "# display(X)\n",
    "# display(y)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Gender','Sleep Duration', 'Dietary Habits', 'Degree', 'History of suicidal thoughts?', 'Family History of Mental Illness'], drop_first=True)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c4b0a4e-31e1-45eb-a2e4-d3eaca081bf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "1c4b0a4e-31e1-45eb-a2e4-d3eaca081bf5",
    "outputId": "432de457-e1fa-41f7-ab36-b5626d1ecdc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22320, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training set: 80.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5581, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Test set: 20.00%\n"
     ]
    }
   ],
   "source": [
    "## Splitting data into train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2222, stratify=y_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "display(X_train.shape)\n",
    "X_train_percentage = (len(X_train) / len(df)) * 100\n",
    "print(f'X Training set: {X_train_percentage:.2f}%')\n",
    "\n",
    "display(X_test.shape)\n",
    "X_test_percentage = (len(X_test) / len(df)) * 100\n",
    "print(f'X Test set: {X_test_percentage:.2f}%')\n",
    "\n",
    "# display(X_val.shape)\n",
    "# X_validation_percentage = (len(X_val) / len(df)) * 100\n",
    "# print(f'X Validation set: {X_validation_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2729c106-5800-4dda-ac60-1660543137aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2729c106-5800-4dda-ac60-1660543137aa",
    "outputId": "5e83b35c-dd37-4363-d780-41ca006dfb56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                     0\n",
       "Academic Pressure                       0\n",
       "CGPA                                    0\n",
       "Study Satisfaction                      0\n",
       "Work/Study Hours                        0\n",
       "Financial Stress                        0\n",
       "Gender_Male                             0\n",
       "Sleep Duration_'7-8 hours'              0\n",
       "Sleep Duration_'Less than 5 hours'      0\n",
       "Sleep Duration_'More than 8 hours'      0\n",
       "Sleep Duration_Others                   0\n",
       "Dietary Habits_Moderate                 0\n",
       "Dietary Habits_Others                   0\n",
       "Dietary Habits_Unhealthy                0\n",
       "Degree_Doctorate                        0\n",
       "Degree_HighSchool/GED                   0\n",
       "Degree_Master's                         0\n",
       "Degree_Other                            0\n",
       "History of suicidal thoughts?_Yes       0\n",
       "Family History of Mental Illness_Yes    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Age                                     0\n",
       "Academic Pressure                       0\n",
       "CGPA                                    0\n",
       "Study Satisfaction                      0\n",
       "Work/Study Hours                        0\n",
       "Financial Stress                        0\n",
       "Gender_Male                             0\n",
       "Sleep Duration_'7-8 hours'              0\n",
       "Sleep Duration_'Less than 5 hours'      0\n",
       "Sleep Duration_'More than 8 hours'      0\n",
       "Sleep Duration_Others                   0\n",
       "Dietary Habits_Moderate                 0\n",
       "Dietary Habits_Others                   0\n",
       "Dietary Habits_Unhealthy                0\n",
       "Degree_Doctorate                        0\n",
       "Degree_HighSchool/GED                   0\n",
       "Degree_Master's                         0\n",
       "Degree_Other                            0\n",
       "History of suicidal thoughts?_Yes       0\n",
       "Family History of Mental Illness_Yes    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Removing missing values from financial stress column\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## Filling in missing numeric variables\n",
    "\n",
    "# Setting imputer as mean\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "\n",
    "# Imputing numeric columns with mean in train data\n",
    "X_train['Financial Stress'] = imputer.fit_transform(X_train[['Financial Stress']])\n",
    "\n",
    "# # Imputing numeric columns with mean in validation data\n",
    "# X_val['Financial Stress'] = imputer.transform(X_val[['Financial Stress']])\n",
    "\n",
    "# Imputing numeric columns with mean in test data\n",
    "X_test['Financial Stress'] = imputer.transform(X_test[['Financial Stress']])\n",
    "\n",
    "\n",
    "## Verifying train, validation, and test sets have no missing values\n",
    "\n",
    "display(X_train.isnull().sum())\n",
    "\n",
    "# display(X_val.isnull().sum())\n",
    "\n",
    "display(X_test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b50a02b-33a6-466c-9951-9304c3e15150",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "7b50a02b-33a6-466c-9951-9304c3e15150",
    "outputId": "66e230bb-a5da-46ad-f392-2b0fc393e32f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                     float64\n",
       "Academic Pressure                       float64\n",
       "CGPA                                    float64\n",
       "Study Satisfaction                      float64\n",
       "Work/Study Hours                        float64\n",
       "Financial Stress                        float64\n",
       "Gender_Male                                bool\n",
       "Sleep Duration_'7-8 hours'                 bool\n",
       "Sleep Duration_'Less than 5 hours'         bool\n",
       "Sleep Duration_'More than 8 hours'         bool\n",
       "Sleep Duration_Others                      bool\n",
       "Dietary Habits_Moderate                    bool\n",
       "Dietary Habits_Others                      bool\n",
       "Dietary Habits_Unhealthy                   bool\n",
       "Degree_Doctorate                           bool\n",
       "Degree_HighSchool/GED                      bool\n",
       "Degree_Master's                            bool\n",
       "Degree_Other                               bool\n",
       "History of suicidal thoughts?_Yes          bool\n",
       "Family History of Mental Illness_Yes       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c337880-f317-4190-a9fb-059f2ea3e91b",
   "metadata": {
    "id": "6c337880-f317-4190-a9fb-059f2ea3e91b"
   },
   "outputs": [],
   "source": [
    "## Scaling all numerical data\n",
    "\n",
    "# Importing in scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing in scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling training data\n",
    "X_train[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']]= scaler.fit_transform(X_train[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']])\n",
    "\n",
    "\n",
    "# Scaling validation data\n",
    "# X_val[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']] = scaler.transform(X_val[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']])\n",
    "\n",
    "# Scaling testing data\n",
    "X_test[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']] = scaler.transform(X_test[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64c2c01c-7e04-414c-8d5f-442f32461ea2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "64c2c01c-7e04-414c-8d5f-442f32461ea2",
    "outputId": "3c9ea531-62d3-4f5d-882d-eb6e6783ebc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Sleep Duration_'7-8 hours'</th>\n",
       "      <th>Sleep Duration_'Less than 5 hours'</th>\n",
       "      <th>Sleep Duration_'More than 8 hours'</th>\n",
       "      <th>Sleep Duration_Others</th>\n",
       "      <th>Dietary Habits_Moderate</th>\n",
       "      <th>Dietary Habits_Others</th>\n",
       "      <th>Dietary Habits_Unhealthy</th>\n",
       "      <th>Degree_Doctorate</th>\n",
       "      <th>Degree_HighSchool/GED</th>\n",
       "      <th>Degree_Master's</th>\n",
       "      <th>Degree_Other</th>\n",
       "      <th>History of suicidal thoughts?_Yes</th>\n",
       "      <th>Family History of Mental Illness_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17199</th>\n",
       "      <td>0.641936</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>0.868613</td>\n",
       "      <td>-1.422802</td>\n",
       "      <td>0.767329</td>\n",
       "      <td>-1.490144</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>1.253217</td>\n",
       "      <td>-0.099544</td>\n",
       "      <td>0.589374</td>\n",
       "      <td>0.044506</td>\n",
       "      <td>-0.850848</td>\n",
       "      <td>-0.099513</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077</th>\n",
       "      <td>0.438176</td>\n",
       "      <td>-0.099544</td>\n",
       "      <td>0.534888</td>\n",
       "      <td>1.511814</td>\n",
       "      <td>0.497633</td>\n",
       "      <td>-1.490144</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20246</th>\n",
       "      <td>-0.988146</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>0.534888</td>\n",
       "      <td>0.044506</td>\n",
       "      <td>-0.311456</td>\n",
       "      <td>1.291118</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12639</th>\n",
       "      <td>0.845697</td>\n",
       "      <td>-0.099544</td>\n",
       "      <td>-0.282396</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>-1.929633</td>\n",
       "      <td>-0.099513</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26855</th>\n",
       "      <td>0.234416</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>1.406658</td>\n",
       "      <td>-1.422802</td>\n",
       "      <td>1.306722</td>\n",
       "      <td>-0.099513</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21733</th>\n",
       "      <td>0.641936</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>0.064950</td>\n",
       "      <td>-0.689148</td>\n",
       "      <td>0.227937</td>\n",
       "      <td>1.291118</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>0.438176</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>-0.479906</td>\n",
       "      <td>-0.689148</td>\n",
       "      <td>-0.850848</td>\n",
       "      <td>-0.794829</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>-0.376865</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>-0.030400</td>\n",
       "      <td>-1.422802</td>\n",
       "      <td>0.227937</td>\n",
       "      <td>1.291118</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23380</th>\n",
       "      <td>1.660738</td>\n",
       "      <td>-0.824211</td>\n",
       "      <td>0.153489</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>-0.311456</td>\n",
       "      <td>1.291118</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age  Academic Pressure      CGPA  Study Satisfaction  \\\n",
       "17199  0.641936           1.349789  0.868613           -1.422802   \n",
       "8159   1.253217          -0.099544  0.589374            0.044506   \n",
       "13077  0.438176          -0.099544  0.534888            1.511814   \n",
       "20246 -0.988146           0.625122  0.534888            0.044506   \n",
       "12639  0.845697          -0.099544 -0.282396            0.778160   \n",
       "26855  0.234416           1.349789  1.406658           -1.422802   \n",
       "21733  0.641936           1.349789  0.064950           -0.689148   \n",
       "3288   0.438176           0.625122 -0.479906           -0.689148   \n",
       "11714 -0.376865           1.349789 -0.030400           -1.422802   \n",
       "23380  1.660738          -0.824211  0.153489            0.778160   \n",
       "\n",
       "       Work/Study Hours  Financial Stress  Gender_Male  \\\n",
       "17199          0.767329         -1.490144         True   \n",
       "8159          -0.850848         -0.099513        False   \n",
       "13077          0.497633         -1.490144         True   \n",
       "20246         -0.311456          1.291118        False   \n",
       "12639         -1.929633         -0.099513        False   \n",
       "26855          1.306722         -0.099513        False   \n",
       "21733          0.227937          1.291118         True   \n",
       "3288          -0.850848         -0.794829         True   \n",
       "11714          0.227937          1.291118         True   \n",
       "23380         -0.311456          1.291118        False   \n",
       "\n",
       "       Sleep Duration_'7-8 hours'  Sleep Duration_'Less than 5 hours'  \\\n",
       "17199                       False                                True   \n",
       "8159                         True                               False   \n",
       "13077                       False                               False   \n",
       "20246                       False                               False   \n",
       "12639                       False                               False   \n",
       "26855                       False                                True   \n",
       "21733                       False                               False   \n",
       "3288                        False                               False   \n",
       "11714                       False                               False   \n",
       "23380                       False                               False   \n",
       "\n",
       "       Sleep Duration_'More than 8 hours'  Sleep Duration_Others  \\\n",
       "17199                               False                  False   \n",
       "8159                                False                  False   \n",
       "13077                               False                  False   \n",
       "20246                                True                  False   \n",
       "12639                               False                  False   \n",
       "26855                               False                  False   \n",
       "21733                               False                  False   \n",
       "3288                                False                  False   \n",
       "11714                                True                  False   \n",
       "23380                                True                  False   \n",
       "\n",
       "       Dietary Habits_Moderate  Dietary Habits_Others  \\\n",
       "17199                    False                  False   \n",
       "8159                     False                  False   \n",
       "13077                    False                  False   \n",
       "20246                     True                  False   \n",
       "12639                     True                  False   \n",
       "26855                    False                  False   \n",
       "21733                     True                  False   \n",
       "3288                      True                  False   \n",
       "11714                    False                  False   \n",
       "23380                    False                  False   \n",
       "\n",
       "       Dietary Habits_Unhealthy  Degree_Doctorate  Degree_HighSchool/GED  \\\n",
       "17199                      True             False                  False   \n",
       "8159                      False              True                  False   \n",
       "13077                      True             False                  False   \n",
       "20246                     False             False                  False   \n",
       "12639                     False             False                  False   \n",
       "26855                      True             False                  False   \n",
       "21733                     False             False                  False   \n",
       "3288                      False             False                  False   \n",
       "11714                     False             False                  False   \n",
       "23380                      True             False                  False   \n",
       "\n",
       "       Degree_Master's  Degree_Other  History of suicidal thoughts?_Yes  \\\n",
       "17199            False         False                               True   \n",
       "8159             False         False                              False   \n",
       "13077            False         False                               True   \n",
       "20246            False         False                               True   \n",
       "12639            False         False                              False   \n",
       "26855             True         False                               True   \n",
       "21733             True         False                               True   \n",
       "3288             False         False                               True   \n",
       "11714            False         False                               True   \n",
       "23380            False         False                              False   \n",
       "\n",
       "       Family History of Mental Illness_Yes  \n",
       "17199                                  True  \n",
       "8159                                   True  \n",
       "13077                                  True  \n",
       "20246                                  True  \n",
       "12639                                 False  \n",
       "26855                                  True  \n",
       "21733                                 False  \n",
       "3288                                   True  \n",
       "11714                                  True  \n",
       "23380                                  True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Academic Pressure</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Study Satisfaction</th>\n",
       "      <th>Work/Study Hours</th>\n",
       "      <th>Financial Stress</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Sleep Duration_'7-8 hours'</th>\n",
       "      <th>Sleep Duration_'Less than 5 hours'</th>\n",
       "      <th>Sleep Duration_'More than 8 hours'</th>\n",
       "      <th>Sleep Duration_Others</th>\n",
       "      <th>Dietary Habits_Moderate</th>\n",
       "      <th>Dietary Habits_Others</th>\n",
       "      <th>Dietary Habits_Unhealthy</th>\n",
       "      <th>Degree_Doctorate</th>\n",
       "      <th>Degree_HighSchool/GED</th>\n",
       "      <th>Degree_Master's</th>\n",
       "      <th>Degree_Other</th>\n",
       "      <th>History of suicidal thoughts?_Yes</th>\n",
       "      <th>Family History of Mental Illness_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21721</th>\n",
       "      <td>1.253217</td>\n",
       "      <td>-1.548877</td>\n",
       "      <td>0.303324</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>-1.390241</td>\n",
       "      <td>-0.794829</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>-0.784386</td>\n",
       "      <td>-1.548877</td>\n",
       "      <td>0.889045</td>\n",
       "      <td>0.044506</td>\n",
       "      <td>-0.041759</td>\n",
       "      <td>-1.490144</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>1.253217</td>\n",
       "      <td>-0.824211</td>\n",
       "      <td>-1.304001</td>\n",
       "      <td>0.044506</td>\n",
       "      <td>0.767329</td>\n",
       "      <td>-0.099513</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25295</th>\n",
       "      <td>-1.395667</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>-1.426593</td>\n",
       "      <td>-0.689148</td>\n",
       "      <td>-0.311456</td>\n",
       "      <td>1.291118</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>-1.191906</td>\n",
       "      <td>-0.099544</td>\n",
       "      <td>-0.384556</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>0.767329</td>\n",
       "      <td>0.595802</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0.234416</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>-0.806820</td>\n",
       "      <td>-1.422802</td>\n",
       "      <td>1.037026</td>\n",
       "      <td>1.291118</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22462</th>\n",
       "      <td>-1.599427</td>\n",
       "      <td>-0.099544</td>\n",
       "      <td>1.181905</td>\n",
       "      <td>-1.422802</td>\n",
       "      <td>-1.929633</td>\n",
       "      <td>-0.099513</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17660</th>\n",
       "      <td>1.456977</td>\n",
       "      <td>1.349789</td>\n",
       "      <td>1.454333</td>\n",
       "      <td>-0.689148</td>\n",
       "      <td>0.767329</td>\n",
       "      <td>-1.490144</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>-1.599427</td>\n",
       "      <td>-1.548877</td>\n",
       "      <td>0.848180</td>\n",
       "      <td>1.511814</td>\n",
       "      <td>1.306722</td>\n",
       "      <td>-0.794829</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>-1.599427</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>0.391864</td>\n",
       "      <td>0.778160</td>\n",
       "      <td>-0.311456</td>\n",
       "      <td>-1.490144</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age  Academic Pressure      CGPA  Study Satisfaction  \\\n",
       "21721  1.253217          -1.548877  0.303324            0.778160   \n",
       "8720  -0.784386          -1.548877  0.889045            0.044506   \n",
       "5175   1.253217          -0.824211 -1.304001            0.044506   \n",
       "25295 -1.395667           1.349789 -1.426593           -0.689148   \n",
       "24991 -1.191906          -0.099544 -0.384556            0.778160   \n",
       "1163   0.234416           1.349789 -0.806820           -1.422802   \n",
       "22462 -1.599427          -0.099544  1.181905           -1.422802   \n",
       "17660  1.456977           1.349789  1.454333           -0.689148   \n",
       "14312 -1.599427          -1.548877  0.848180            1.511814   \n",
       "3827  -1.599427           0.625122  0.391864            0.778160   \n",
       "\n",
       "       Work/Study Hours  Financial Stress  Gender_Male  \\\n",
       "21721         -1.390241         -0.794829        False   \n",
       "8720          -0.041759         -1.490144        False   \n",
       "5175           0.767329         -0.099513        False   \n",
       "25295         -0.311456          1.291118        False   \n",
       "24991          0.767329          0.595802         True   \n",
       "1163           1.037026          1.291118         True   \n",
       "22462         -1.929633         -0.099513         True   \n",
       "17660          0.767329         -1.490144        False   \n",
       "14312          1.306722         -0.794829         True   \n",
       "3827          -0.311456         -1.490144         True   \n",
       "\n",
       "       Sleep Duration_'7-8 hours'  Sleep Duration_'Less than 5 hours'  \\\n",
       "21721                       False                               False   \n",
       "8720                         True                               False   \n",
       "5175                        False                                True   \n",
       "25295                        True                               False   \n",
       "24991                       False                               False   \n",
       "1163                        False                               False   \n",
       "22462                       False                               False   \n",
       "17660                        True                               False   \n",
       "14312                       False                                True   \n",
       "3827                        False                               False   \n",
       "\n",
       "       Sleep Duration_'More than 8 hours'  Sleep Duration_Others  \\\n",
       "21721                               False                  False   \n",
       "8720                                False                  False   \n",
       "5175                                False                  False   \n",
       "25295                               False                  False   \n",
       "24991                                True                  False   \n",
       "1163                                 True                  False   \n",
       "22462                                True                  False   \n",
       "17660                               False                  False   \n",
       "14312                               False                  False   \n",
       "3827                                 True                  False   \n",
       "\n",
       "       Dietary Habits_Moderate  Dietary Habits_Others  \\\n",
       "21721                    False                  False   \n",
       "8720                     False                  False   \n",
       "5175                     False                  False   \n",
       "25295                    False                  False   \n",
       "24991                    False                  False   \n",
       "1163                     False                  False   \n",
       "22462                    False                  False   \n",
       "17660                    False                  False   \n",
       "14312                     True                  False   \n",
       "3827                     False                  False   \n",
       "\n",
       "       Dietary Habits_Unhealthy  Degree_Doctorate  Degree_HighSchool/GED  \\\n",
       "21721                     False             False                  False   \n",
       "8720                      False             False                  False   \n",
       "5175                      False             False                  False   \n",
       "25295                      True             False                   True   \n",
       "24991                      True             False                   True   \n",
       "1163                      False             False                  False   \n",
       "22462                      True             False                   True   \n",
       "17660                      True             False                  False   \n",
       "14312                     False             False                   True   \n",
       "3827                      False             False                   True   \n",
       "\n",
       "       Degree_Master's  Degree_Other  History of suicidal thoughts?_Yes  \\\n",
       "21721            False         False                               True   \n",
       "8720              True         False                               True   \n",
       "5175              True         False                               True   \n",
       "25295            False         False                               True   \n",
       "24991            False         False                               True   \n",
       "1163             False         False                               True   \n",
       "22462            False         False                               True   \n",
       "17660            False         False                              False   \n",
       "14312            False         False                               True   \n",
       "3827             False         False                               True   \n",
       "\n",
       "       Family History of Mental Illness_Yes  \n",
       "21721                                  True  \n",
       "8720                                   True  \n",
       "5175                                   True  \n",
       "25295                                 False  \n",
       "24991                                 False  \n",
       "1163                                   True  \n",
       "22462                                  True  \n",
       "17660                                 False  \n",
       "14312                                 False  \n",
       "3827                                  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Verifying data has been scaled\n",
    "\n",
    "display(X_train.head(10))\n",
    "\n",
    "# display(X_val.head(10))\n",
    "\n",
    "display(X_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37aa05c9-c38f-46c7-814d-5b0976dfc6b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37aa05c9-c38f-46c7-814d-5b0976dfc6b1",
    "outputId": "bbe60862-e1c9-4ec0-fd07-865d478f1cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "26133    0\n",
      "26134    0\n",
      "26135    0\n",
      "26136    0\n",
      "26137    0\n",
      "Name: Depression, Length: 26138, dtype: int64\n",
      "            Age  Academic Pressure      CGPA  Study Satisfaction  \\\n",
      "0      0.641936           1.349789  0.868613           -1.422802   \n",
      "1      1.253217          -0.099544  0.589374            0.044506   \n",
      "2      0.438176          -0.099544  0.534888            1.511814   \n",
      "3     -0.988146           0.625122  0.534888            0.044506   \n",
      "4      0.845697          -0.099544 -0.282396            0.778160   \n",
      "...         ...                ...       ...                 ...   \n",
      "26133 -0.085378           0.469124 -1.100430            1.511814   \n",
      "26134  0.603447          -0.236430  0.319897           -1.422802   \n",
      "26135 -0.216104          -0.099544 -0.359567            0.778160   \n",
      "26136 -0.173105          -0.824211 -1.295736            1.511814   \n",
      "26137  1.043695          -0.099544 -0.549449           -0.689148   \n",
      "\n",
      "       Work/Study Hours  Financial Stress  Gender_Male  \\\n",
      "0              0.767329         -1.490144         True   \n",
      "1             -0.850848         -0.099513        False   \n",
      "2              0.497633         -1.490144         True   \n",
      "3             -0.311456          1.291118        False   \n",
      "4             -1.929633         -0.099513        False   \n",
      "...                 ...               ...          ...   \n",
      "26133         -1.178602          0.050167         True   \n",
      "26134         -1.608993          1.291118         True   \n",
      "26135          0.334328          0.458656        False   \n",
      "26136         -1.332650          1.142642        False   \n",
      "26137          0.782583          1.291118        False   \n",
      "\n",
      "       Sleep Duration_'7-8 hours'  Sleep Duration_'Less than 5 hours'  \\\n",
      "0                           False                                True   \n",
      "1                            True                               False   \n",
      "2                           False                               False   \n",
      "3                           False                               False   \n",
      "4                           False                               False   \n",
      "...                           ...                                 ...   \n",
      "26133                        True                               False   \n",
      "26134                       False                               False   \n",
      "26135                       False                                True   \n",
      "26136                       False                               False   \n",
      "26137                        True                               False   \n",
      "\n",
      "       Sleep Duration_'More than 8 hours'  Sleep Duration_Others  \\\n",
      "0                                   False                  False   \n",
      "1                                   False                  False   \n",
      "2                                   False                  False   \n",
      "3                                    True                  False   \n",
      "4                                   False                  False   \n",
      "...                                   ...                    ...   \n",
      "26133                               False                  False   \n",
      "26134                                True                  False   \n",
      "26135                               False                  False   \n",
      "26136                                True                  False   \n",
      "26137                               False                  False   \n",
      "\n",
      "       Dietary Habits_Moderate  Dietary Habits_Others  \\\n",
      "0                        False                  False   \n",
      "1                        False                  False   \n",
      "2                        False                  False   \n",
      "3                         True                  False   \n",
      "4                         True                  False   \n",
      "...                        ...                    ...   \n",
      "26133                    False                  False   \n",
      "26134                     True                  False   \n",
      "26135                     True                  False   \n",
      "26136                    False                  False   \n",
      "26137                    False                  False   \n",
      "\n",
      "       Dietary Habits_Unhealthy  Degree_Doctorate  Degree_HighSchool/GED  \\\n",
      "0                          True             False                  False   \n",
      "1                         False              True                  False   \n",
      "2                          True             False                  False   \n",
      "3                         False             False                  False   \n",
      "4                         False             False                  False   \n",
      "...                         ...               ...                    ...   \n",
      "26133                      True             False                  False   \n",
      "26134                     False             False                  False   \n",
      "26135                     False             False                  False   \n",
      "26136                      True             False                  False   \n",
      "26137                     False             False                  False   \n",
      "\n",
      "       Degree_Master's  Degree_Other  History of suicidal thoughts?_Yes  \\\n",
      "0                False         False                               True   \n",
      "1                False         False                              False   \n",
      "2                False         False                               True   \n",
      "3                False         False                               True   \n",
      "4                False         False                              False   \n",
      "...                ...           ...                                ...   \n",
      "26133            False         False                               True   \n",
      "26134            False         False                               True   \n",
      "26135            False         False                              False   \n",
      "26136            False         False                              False   \n",
      "26137            False         False                              False   \n",
      "\n",
      "       Family History of Mental Illness_Yes  \n",
      "0                                      True  \n",
      "1                                      True  \n",
      "2                                      True  \n",
      "3                                      True  \n",
      "4                                     False  \n",
      "...                                     ...  \n",
      "26133                                 False  \n",
      "26134                                  True  \n",
      "26135                                  True  \n",
      "26136                                 False  \n",
      "26137                                  True  \n",
      "\n",
      "[26138 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "#Use ADASYN and Undersampling\n",
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state = RANDOM_STATE)\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "print(y_resampled_adasyn)\n",
    "print(X_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d826dad8-58d1-4560-9982-0aaa41411a0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d826dad8-58d1-4560-9982-0aaa41411a0e",
    "outputId": "215827c3-e8e0-47c9-fe52-8dab884ebf0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8159     0\n",
      "12639    0\n",
      "23380    0\n",
      "3749     0\n",
      "13141    0\n",
      "        ..\n",
      "9733     1\n",
      "21224    1\n",
      "18901    1\n",
      "20842    1\n",
      "1338     1\n",
      "Name: Depression, Length: 18504, dtype: int64\n",
      "            Age  Academic Pressure      CGPA  Study Satisfaction  \\\n",
      "8159   1.253217          -0.099544  0.589374            0.044506   \n",
      "12639  0.845697          -0.099544 -0.282396            0.778160   \n",
      "23380  1.660738          -0.824211  0.153489            0.778160   \n",
      "3749  -0.988146          -0.099544 -0.357313            1.511814   \n",
      "13141 -0.173105           0.625122  0.602995           -0.689148   \n",
      "...         ...                ...       ...                 ...   \n",
      "9733   1.049457          -0.824211 -0.207478            0.778160   \n",
      "21224 -0.173105          -0.099544  1.345362            1.511814   \n",
      "18901 -0.988146          -0.824211  1.556493           -1.422802   \n",
      "20842 -0.988146           1.349789  1.570115           -1.422802   \n",
      "1338   1.049457           0.625122 -1.351676            0.778160   \n",
      "\n",
      "       Work/Study Hours  Financial Stress  Gender_Male  \\\n",
      "8159          -0.850848         -0.099513        False   \n",
      "12639         -1.929633         -0.099513        False   \n",
      "23380         -0.311456          1.291118        False   \n",
      "3749          -1.929633          1.291118         True   \n",
      "13141         -0.311456         -1.490144        False   \n",
      "...                 ...               ...          ...   \n",
      "9733          -0.311456          1.291118         True   \n",
      "21224          0.767329          1.291118         True   \n",
      "18901          0.227937          1.291118        False   \n",
      "20842          0.497633         -0.099513        False   \n",
      "1338          -0.581152          0.595802        False   \n",
      "\n",
      "       Sleep Duration_'7-8 hours'  Sleep Duration_'Less than 5 hours'  \\\n",
      "8159                         True                               False   \n",
      "12639                       False                               False   \n",
      "23380                       False                               False   \n",
      "3749                         True                               False   \n",
      "13141                       False                                True   \n",
      "...                           ...                                 ...   \n",
      "9733                        False                               False   \n",
      "21224                       False                               False   \n",
      "18901                       False                                True   \n",
      "20842                        True                               False   \n",
      "1338                         True                               False   \n",
      "\n",
      "       Sleep Duration_'More than 8 hours'  Sleep Duration_Others  \\\n",
      "8159                                False                  False   \n",
      "12639                               False                  False   \n",
      "23380                                True                  False   \n",
      "3749                                False                  False   \n",
      "13141                               False                  False   \n",
      "...                                   ...                    ...   \n",
      "9733                                 True                  False   \n",
      "21224                               False                  False   \n",
      "18901                               False                  False   \n",
      "20842                               False                  False   \n",
      "1338                                False                  False   \n",
      "\n",
      "       Dietary Habits_Moderate  Dietary Habits_Others  \\\n",
      "8159                     False                  False   \n",
      "12639                     True                  False   \n",
      "23380                    False                  False   \n",
      "3749                     False                  False   \n",
      "13141                    False                  False   \n",
      "...                        ...                    ...   \n",
      "9733                      True                  False   \n",
      "21224                    False                  False   \n",
      "18901                     True                  False   \n",
      "20842                     True                  False   \n",
      "1338                     False                  False   \n",
      "\n",
      "       Dietary Habits_Unhealthy  Degree_Doctorate  Degree_HighSchool/GED  \\\n",
      "8159                      False              True                  False   \n",
      "12639                     False             False                  False   \n",
      "23380                      True             False                  False   \n",
      "3749                       True             False                  False   \n",
      "13141                     False             False                  False   \n",
      "...                         ...               ...                    ...   \n",
      "9733                      False             False                  False   \n",
      "21224                      True             False                  False   \n",
      "18901                     False             False                  False   \n",
      "20842                     False             False                  False   \n",
      "1338                      False             False                  False   \n",
      "\n",
      "       Degree_Master's  Degree_Other  History of suicidal thoughts?_Yes  \\\n",
      "8159             False         False                              False   \n",
      "12639            False         False                              False   \n",
      "23380            False         False                              False   \n",
      "3749             False         False                              False   \n",
      "13141             True         False                              False   \n",
      "...                ...           ...                                ...   \n",
      "9733              True         False                               True   \n",
      "21224            False         False                               True   \n",
      "18901            False         False                               True   \n",
      "20842             True         False                               True   \n",
      "1338              True         False                               True   \n",
      "\n",
      "       Family History of Mental Illness_Yes  \n",
      "8159                                   True  \n",
      "12639                                 False  \n",
      "23380                                  True  \n",
      "3749                                  False  \n",
      "13141                                 False  \n",
      "...                                     ...  \n",
      "9733                                  False  \n",
      "21224                                  True  \n",
      "18901                                 False  \n",
      "20842                                  True  \n",
      "1338                                   True  \n",
      "\n",
      "[18504 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "random_under_sampler = RandomUnderSampler(random_state = RANDOM_STATE)\n",
    "X_resampled_rus, y_resampled_rus = random_under_sampler.fit_resample(X_train, y_train)\n",
    "print(y_resampled_rus)\n",
    "print(X_resampled_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c541e85b-b88e-4e3c-8cc2-5c8e08448001",
   "metadata": {
    "id": "c541e85b-b88e-4e3c-8cc2-5c8e08448001"
   },
   "source": [
    "## Models we can use: RandomForestClassifier, SVM, LogisticRegression, NaiveBayes, KNN, Decision Tree\n",
    "* We each choose 2 models from the list above.\n",
    "* Perform feature reduction: PCA, LDA, Kernel PCA\n",
    "* Tune hyperparameters: Using the best version of the model we have\n",
    "* After finding the best model from tuning, then perform K-cross validation\n",
    "* Select the best model from each of our selected 2, then we can put it together in a voting classifier for the ensemble portion.\n",
    "## Notes\n",
    "* Use charts and metrics where appropriate such as f1_score, precision, and accuracy.\n",
    "* Don't use the validation sets for the feature/dimensionality reduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c840cd-43b9-4534-833d-5cfd206f1901",
   "metadata": {
    "id": "97c840cd-43b9-4534-833d-5cfd206f1901"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278fad6-0334-4fd0-90e8-1500f48cbd82",
   "metadata": {
    "id": "9278fad6-0334-4fd0-90e8-1500f48cbd82"
   },
   "source": [
    "# David Braun\n",
    "* KNN\n",
    "* SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "669628f4-5fb9-4685-be07-536a3c4d63cc",
   "metadata": {
    "id": "669628f4-5fb9-4685-be07-536a3c4d63cc"
   },
   "outputs": [],
   "source": [
    "# ---------- extra imports for modelling ----------\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.decomposition   import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.metrics         import f1_score, classification_report, confusion_matrix, RocCurveDisplay\n",
    "import seaborn as sns, matplotlib.pyplot as plt, pandas as pd, joblib, pathlib\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "Eeqg2O0aMxbK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "Eeqg2O0aMxbK",
    "outputId": "3ec0492e-e39d-497e-edd1-e52060e529bb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-efefbdf75cc4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"KNN ADA\"),\n\u001b[1;32m      6\u001b[0m                      (X_resampled_rus,    y_resampled_rus,    \"KNN RUS\") ]:\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mquick_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"SVM ADA\"),\n",
      "\u001b[0;32m<ipython-input-96-efefbdf75cc4>\u001b[0m in \u001b[0;36mquick_score\u001b[0;34m(model, Xb, yb, tag)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquick_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{tag}: F1 = {f1_score(y_val, model.predict(X_val)):.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"KNN ADA\"),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_val' is not defined"
     ]
    }
   ],
   "source": [
    "def quick_score(model, Xb, yb, tag):\n",
    "    model.fit(Xb, yb)\n",
    "    print(f\"{tag}: F1 = {f1_score(y_val, model.predict(X_val)):.3f}\")\n",
    "\n",
    "for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"KNN ADA\"),\n",
    "                     (X_resampled_rus,    y_resampled_rus,    \"KNN RUS\") ]:\n",
    "    quick_score(KNeighborsClassifier(n_neighbors=5, weights='distance'), Xb, yb, tag)\n",
    "\n",
    "for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"SVM ADA\"),\n",
    "                     (X_resampled_rus,    y_resampled_rus,    \"SVM RUS\") ]:\n",
    "    quick_score(SVC(kernel='linear', C=1, random_state=42), Xb, yb, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Wqz4G0uM9C4",
   "metadata": {
    "id": "0Wqz4G0uM9C4"
   },
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('dr',    'passthrough'),          # placeholder\n",
    "    ('clf',   KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('dr',    'passthrough'),\n",
    "    ('clf',   SVC(probability=True, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N9Wo8JhBNDN1",
   "metadata": {
    "id": "N9Wo8JhBNDN1"
   },
   "outputs": [],
   "source": [
    "# ───────────────── 0.  nuke any zombie cluster ──────────────────────────\n",
    "try:\n",
    "    client.close(); cluster.close()\n",
    "except NameError:\n",
    "    pass                   # first run – nothing to clean up\n",
    "\n",
    "# ───────────────── 1.  dask‑timeout & CPU threads ───────────────────────\n",
    "import os, dask\n",
    "dask.config.set({\n",
    "    \"distributed.comm.timeouts.connect\": \"120s\",   # ← was 30 s\n",
    "    \"distributed.comm.timeouts.tcp\":    \"120s\",\n",
    "})\n",
    "os.environ[\"OMP_NUM_THREADS\"] = os.environ[\"MKL_NUM_THREADS\"] = \"18\"\n",
    "\n",
    "# ───────────────── 2.  start a TCP‑only 2‑GPU cluster ───────────────────\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = LocalCUDACluster(\n",
    "    protocol       =\"tcp\",        # skip UCX (fewer moving parts)\n",
    "    interface      =\"lo\",         # loop‑back only\n",
    "    enable_nvlink  =False,\n",
    "    CUDA_VISIBLE_DEVICES=\"0,1\",\n",
    "    threads_per_worker = 6,       # 12 CPU threads total\n",
    "    memory_limit       =\"24GB\",   # host RAM / worker\n",
    "    rmm_pool_size      =\"4GB\"     # pre‑alloc on each GPU\n",
    ")\n",
    "client  = Client(cluster)\n",
    "client.wait_for_workers(2)        # block until both GPUs are ready\n",
    "print(\"Dask dashboard:\", client.dashboard_link)\n",
    "\n",
    "# ───────────────── 3.  cuML‑UMAP wrapper (same as before) ───────────────\n",
    "import cupy as cp\n",
    "from cuml.manifold import UMAP as GPUUMAP\n",
    "from sklearn.base  import BaseEstimator, TransformerMixin\n",
    "class CumlUMAP(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=10, n_neighbors=30, random_state=42):\n",
    "        self.n_components, self.n_neighbors, self.random_state = (\n",
    "            n_components, n_neighbors, random_state)\n",
    "    def get_params(self, deep=True): return vars(self).copy()\n",
    "    def set_params(self, **p):\n",
    "        for k,v in p.items(): setattr(self,k,v); return self\n",
    "    def fit(self, X, y=None):\n",
    "        self._umap = GPUUMAP(**self.get_params()).fit(cp.asarray(X))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return self._umap.transform(cp.asarray(X)).get()\n",
    "\n",
    "# ───────────────── 4.  pipelines + param grids  ─────────────────────────\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from dask_ml.model_selection import GridSearchCV    # ← dask‑ml version\n",
    "\n",
    "base_pre = [('impute', SimpleImputer(strategy='median')),\n",
    "            ('scale',  StandardScaler())]\n",
    "\n",
    "knn_pipe = Pipeline(base_pre + [('dr','passthrough'),\n",
    "                                ('clf',KNeighborsClassifier())])\n",
    "\n",
    "svm_pipe = Pipeline(base_pre + [('dr','passthrough'),\n",
    "                                ('clf',SVC())])\n",
    "\n",
    "knn_param = {\n",
    "    'dr': [None,\n",
    "           PCA(n_components=10, random_state=42),\n",
    "           LDA(n_components=1),\n",
    "           CumlUMAP(n_components=10, n_neighbors=30, random_state=42)],\n",
    "    'clf__n_neighbors':[3,5,7,11],\n",
    "    'clf__weights':    ['uniform','distance'],\n",
    "    'clf__metric':     ['euclidean','manhattan']\n",
    "}\n",
    "svm_param = {\n",
    "    'dr': [None,\n",
    "           PCA(n_components=15, random_state=42),\n",
    "           CumlUMAP(n_components=15, n_neighbors=30, random_state=42)],\n",
    "    'clf__kernel':['linear','rbf'],\n",
    "    'clf__C':     [0.1,1,10],\n",
    "    'clf__gamma': ['scale','auto']\n",
    "}\n",
    "\n",
    "knn_gs = GridSearchCV(knn_pipe, knn_param, scoring='f1', cv=10,\n",
    "                      n_jobs=-1, error_score='raise')\n",
    "svm_gs = GridSearchCV(svm_pipe, svm_param, scoring='f1', cv=10,\n",
    "                      n_jobs=-1, error_score='raise')\n",
    "\n",
    "# ───────────────── 5.  run the grid searches  ───────────────────────────\n",
    "print(\"▶ fitting k‑NN grid …\"); knn_gs.fit(Xb, yb)\n",
    "print(\"▶ fitting SVM grid …\");  svm_gs.fit(Xb, yb)\n",
    "\n",
    "print(\"✓ finished\")\n",
    "print(\"best k‑NN:\", knn_gs.best_params_, \"  F1 =\", knn_gs.best_score_)\n",
    "print(\"best SVM:\", svm_gs.best_params_, \"  F1 =\", svm_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0JQ22YNgNE-w",
   "metadata": {
    "id": "0JQ22YNgNE-w"
   },
   "outputs": [],
   "source": [
    "best_knn = knn_gs.best_estimator_\n",
    "best_svm = svm_gs.best_estimator_\n",
    "\n",
    "print(\"KNN best params:\", knn_gs.best_params_)\n",
    "print(\"SVM best params:\", svm_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GNo1BuYxNKHB",
   "metadata": {
    "id": "GNo1BuYxNKHB"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             RocCurveDisplay)\n",
    "\n",
    "def eval_model(mdl, label):\n",
    "    # CUPY → NUMPY if necessary\n",
    "    y_pred = mdl.predict(X_val)\n",
    "    if hasattr(y_pred, \"get\"):                      # cupy.ndarray\n",
    "        y_pred = y_pred.get()\n",
    "\n",
    "    print(f\"\\n{label}\\n\", classification_report(y_val, y_pred, digits=3))\n",
    "\n",
    "    sns.heatmap(confusion_matrix(y_val, y_pred),\n",
    "                annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{label} – Confusion'); plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_estimator(mdl, X_val, y_val)\n",
    "    plt.title(f'{label} – ROC'); plt.show()\n",
    "\n",
    "eval_model(best_knn, \"Best KNN\")\n",
    "eval_model(best_svm, \"Best SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fnh3HrecNOJE",
   "metadata": {
    "id": "Fnh3HrecNOJE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "full_X = pd.concat([X_train, X_val])\n",
    "full_y = pd.concat([y_train, y_val])\n",
    "\n",
    "for mdl, name in [(best_knn, 'KNN'), (best_svm, 'SVM')]:\n",
    "    scores = cross_val_score(mdl, full_X, full_y,\n",
    "                             cv=cv, scoring='f1')      # n_jobs = 1\n",
    "    print(f\"{name} 10‑fold F1: {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cm114iGoNQB8",
   "metadata": {
    "id": "cm114iGoNQB8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for mdl, name in [(best_knn, 'KNN'), (best_svm, 'SVM')]:\n",
    "    y_hat = mdl.predict(X_test)\n",
    "    if hasattr(y_hat, \"get\"):\n",
    "        y_hat = y_hat.get()\n",
    "    print(name, \"TEST F1 =\", f1_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4FRMQzBnNRm3",
   "metadata": {
    "id": "4FRMQzBnNRm3"
   },
   "outputs": [],
   "source": [
    "import pathlib, joblib\n",
    "pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "# detach cupy arrays so joblib can pickle (safe‑guard)\n",
    "for pipe in (best_knn, best_svm):\n",
    "    if hasattr(pipe, \"steps\"):\n",
    "        for name, step in pipe.steps:\n",
    "            if hasattr(step, \"release_cache\"):    # many cuML objects\n",
    "                step.release_cache()\n",
    "\n",
    "joblib.dump(best_knn, \"models/best_knn.pkl\")\n",
    "joblib.dump(best_svm, \"models/best_svm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06hUtGgyNSav",
   "metadata": {
    "id": "06hUtGgyNSav"
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame(knn_gs.cv_results_)\n",
    "   .groupby('param_clf__n_neighbors')['mean_test_score']\n",
    "   .mean()\n",
    "   .plot(marker='o'))\n",
    "plt.ylabel('Mean CV F1'); plt.xlabel('k'); plt.title('KNN: k vs F1'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11751c2f-e5a6-4b7d-9a14-56cec8f9ec6c",
   "metadata": {
    "id": "11751c2f-e5a6-4b7d-9a14-56cec8f9ec6c"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8113c0e-cfef-46b5-9b5b-0adda88de6f0",
   "metadata": {
    "id": "f8113c0e-cfef-46b5-9b5b-0adda88de6f0"
   },
   "source": [
    "# Karryn Leake\n",
    "* Logistic Regression\n",
    "* NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02fad486-95f4-4495-9768-5be31c4fe373",
   "metadata": {
    "id": "02fad486-95f4-4495-9768-5be31c4fe373"
   },
   "outputs": [],
   "source": [
    "## Importing in needed packages for dimensionality reduction\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dDtCp1GuNtfJ",
   "metadata": {
    "id": "dDtCp1GuNtfJ"
   },
   "outputs": [],
   "source": [
    "### Creating base log model code\n",
    "\n",
    "def train_log_model(X_train_values, y_train_values, X_test_values, y_test_values):\n",
    "    # Setting up logistic regression model\n",
    "    log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "    # Training model\n",
    "    log_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "    ## Displaying model accuracy\n",
    "\n",
    "    log_y_hat = log_model.predict(X_test_values)\n",
    "\n",
    "    # Getting classification report\n",
    "    report = classification_report(y_test_values, log_y_hat)\n",
    "\n",
    "    # Getting accuracy specifically\n",
    "    accuracy = accuracy_score(y_test_values, log_y_hat)\n",
    "\n",
    "    print(f\"Our current model accuracy is {accuracy:.2f}.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"A more detailed report of the model's overall accuracy is:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "IiAIu1ArNtoS",
   "metadata": {
    "id": "IiAIu1ArNtoS"
   },
   "outputs": [],
   "source": [
    "### Creating base naive bayes code\n",
    "\n",
    "def train_nb_model(X_train_values, y_train_values, X_test_values, y_test_values):\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "    # Predicting y_hat\n",
    "    nb_y_hat = nb_model.predict(X_test_values)\n",
    "\n",
    "    # Getting classification report\n",
    "    report = classification_report(y_test_values, nb_y_hat)\n",
    "\n",
    "    # Getting accuracy specifically\n",
    "    accuracy = accuracy_score(y_test_values, nb_y_hat)\n",
    "\n",
    "    print(f\"Our current model accuracy is {accuracy:.2f}.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"A more detailed report of the model's overall accuracy is:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AU4h8ATUN_o3",
   "metadata": {
    "id": "AU4h8ATUN_o3"
   },
   "source": [
    "### Initial log model on oversampled and undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "OPcaBwV3OFGs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPcaBwV3OFGs",
    "outputId": "b8cad04b-f986-446c-814e-bd5a20fdbd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.85.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      2313\n",
      "           1       0.90      0.83      0.86      3268\n",
      "\n",
      "    accuracy                           0.85      5581\n",
      "   macro avg       0.84      0.85      0.84      5581\n",
      "weighted avg       0.85      0.85      0.85      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training log model using oversampled data\n",
    "train_log_model(X_resampled_adasyn, y_resampled_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8Va3bPRsOWAF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Va3bPRsOWAF",
    "outputId": "104ac00d-b20d-4390-ed42-3a23c7400d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.85.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      2313\n",
      "           1       0.89      0.86      0.87      3268\n",
      "\n",
      "    accuracy                           0.85      5581\n",
      "   macro avg       0.85      0.85      0.85      5581\n",
      "weighted avg       0.85      0.85      0.85      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training log model on undersampled data\n",
    "train_log_model(X_resampled_rus, y_resampled_rus, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aCeXaAZROjkm",
   "metadata": {
    "id": "aCeXaAZROjkm"
   },
   "source": [
    "### Initial nb model on oversampled and undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vCpOWMxMOlSb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCpOWMxMOlSb",
    "outputId": "be0e1d1c-6310-4b2d-c8a0-d88b11654b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.84.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      2313\n",
      "           1       0.88      0.85      0.86      3268\n",
      "\n",
      "    accuracy                           0.84      5581\n",
      "   macro avg       0.84      0.84      0.84      5581\n",
      "weighted avg       0.84      0.84      0.84      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training nb model on oversampled data\n",
    "train_nb_model(X_resampled_adasyn, y_resampled_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "wv59U-YfOlXd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wv59U-YfOlXd",
    "outputId": "e48a4e2f-6f7d-495e-e5ce-2e130f35c1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.84.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      2313\n",
      "           1       0.87      0.86      0.86      3268\n",
      "\n",
      "    accuracy                           0.84      5581\n",
      "   macro avg       0.84      0.84      0.84      5581\n",
      "weighted avg       0.84      0.84      0.84      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training nb model on undersampled data\n",
    "train_nb_model(X_resampled_rus, y_resampled_rus, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EsMrMhEjOwUb",
   "metadata": {
    "id": "EsMrMhEjOwUb"
   },
   "source": [
    "## Experimenting with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sinm0zdNO1Pj",
   "metadata": {
    "id": "sinm0zdNO1Pj"
   },
   "source": [
    "### Completing LDA on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24Dn5PZrOyOT",
   "metadata": {
    "id": "24Dn5PZrOyOT"
   },
   "outputs": [],
   "source": [
    "## Completing LDA on over sampled data\n",
    "\n",
    "# Getting LDA with n_components = 1 as n_components = number of classes - 1\n",
    "lda = LinearDiscriminantAnalysis(n_components = 1)\n",
    "\n",
    "# Performing LDA on train and test data\n",
    "X_train_lda = lda.fit_transform(X_resampled_adasyn, y_resampled_adasyn)\n",
    "X_test_lda = lda.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qO3ZH2_LPLd7",
   "metadata": {
    "id": "qO3ZH2_LPLd7"
   },
   "source": [
    "### Training log and naive bayes models on oversampled data with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "MIpIpcLLOx94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIpIpcLLOx94",
    "outputId": "5b685355-afb4-44a8-8ddb-ca421991916b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.84.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      2313\n",
      "           1       0.90      0.83      0.86      3268\n",
      "\n",
      "    accuracy                           0.84      5581\n",
      "   macro avg       0.84      0.85      0.84      5581\n",
      "weighted avg       0.85      0.84      0.84      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_log_model(X_train_lda, y_resampled_adasyn, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hRbV0iVvOx0x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRbV0iVvOx0x",
    "outputId": "6d76eacd-31c8-4f0a-81c3-2e64cf02c2a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.85.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      2313\n",
      "           1       0.89      0.84      0.86      3268\n",
      "\n",
      "    accuracy                           0.85      5581\n",
      "   macro avg       0.84      0.85      0.84      5581\n",
      "weighted avg       0.85      0.85      0.85      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_nb_model(X_train_lda, y_resampled_adasyn, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YlZsyelRPgrJ",
   "metadata": {
    "id": "YlZsyelRPgrJ"
   },
   "source": [
    "## Experimenting with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DRNPJH44PgeY",
   "metadata": {
    "id": "DRNPJH44PgeY"
   },
   "source": [
    "### Setting up PCA on oversampled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ZVeuGvYqPgIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVeuGvYqPgIA",
    "outputId": "189762a1-9b3f-462c-86c0-5012590a8d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131]\n",
      "0.15808130701427758\n"
     ]
    }
   ],
   "source": [
    "## Choosing 1 as number of components and testing variance\n",
    "pca = PCA(n_components = 1)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "TZfUr4rsPrmn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZfUr4rsPrmn",
    "outputId": "78c51e8d-646a-4d9b-9fc3-c29db167f0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      2313\n",
      "           1       0.84      0.75      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.77      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "heCwE6EsPrdw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heCwE6EsPrdw",
    "outputId": "2c9f8b85-3ed3-4865-8bf6-20a6653b00a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74      2313\n",
      "           1       0.84      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.77      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on naive bayes model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5M-7sIN5P3NT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5M-7sIN5P3NT",
    "outputId": "19bd1994-bd3f-4de1-83ca-97fb4a5a9b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219]\n",
      "0.28954349718390704\n"
     ]
    }
   ],
   "source": [
    "## Choosing 2 as number of components and testing variance\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "SIWPt-ieP3Le",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIWPt-ieP3Le",
    "outputId": "d44de017-0205-4e2b-8997-e91a0b2e839d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      2313\n",
      "           1       0.85      0.75      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.77      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "NuMe03jbP3I4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuMe03jbP3I4",
    "outputId": "9314042e-2602-4a61-c004-db33332ceae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      2313\n",
      "           1       0.84      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "s3y3cmagP3BD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3y3cmagP3BD",
    "outputId": "2a1f8d24-5b75-42b0-cd9f-882874d117a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591]\n",
      "0.41357940296234397\n"
     ]
    }
   ],
   "source": [
    "## Choosing 3 as number of components and testing variance\n",
    "pca = PCA(n_components = 3)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "VOI2QIJBP2_O",
   "metadata": {
    "id": "VOI2QIJBP2_O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.78.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      2313\n",
      "           1       0.85      0.75      0.80      3268\n",
      "\n",
      "    accuracy                           0.78      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.79      0.78      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "_D-JO6wsP285",
   "metadata": {
    "id": "_D-JO6wsP285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.78.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.75      2313\n",
      "           1       0.85      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.78      5581\n",
      "   macro avg       0.78      0.78      0.78      5581\n",
      "weighted avg       0.79      0.78      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "nAAZLpP3P26i",
   "metadata": {
    "id": "nAAZLpP3P26i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967]\n",
      "0.5319790776901799\n"
     ]
    }
   ],
   "source": [
    "## Choosing 4 as number of components and testing variance\n",
    "pca = PCA(n_components = 4)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "Vwf6_OxPP24e",
   "metadata": {
    "id": "Vwf6_OxPP24e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.78.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      2313\n",
      "           1       0.85      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.78      5581\n",
      "   macro avg       0.78      0.78      0.78      5581\n",
      "weighted avg       0.79      0.78      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8xCCag48P22J",
   "metadata": {
    "id": "8xCCag48P22J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.78.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      2313\n",
      "           1       0.85      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.78      5581\n",
      "   macro avg       0.77      0.78      0.78      5581\n",
      "weighted avg       0.79      0.78      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "UyE8kuOAP2vH",
   "metadata": {
    "id": "UyE8kuOAP2vH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319]\n",
      "0.6425522695808913\n"
     ]
    }
   ],
   "source": [
    "## Choosing 5 as number of components and testing variance\n",
    "pca = PCA(n_components = 5)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "tJGyCw2PQWof",
   "metadata": {
    "id": "tJGyCw2PQWof"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.78.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      2313\n",
      "           1       0.85      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.78      5581\n",
      "   macro avg       0.78      0.79      0.78      5581\n",
      "weighted avg       0.79      0.78      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dhe_N6g4QWjB",
   "metadata": {
    "id": "dhe_N6g4QWjB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.78.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      2313\n",
      "           1       0.85      0.76      0.80      3268\n",
      "\n",
      "    accuracy                           0.78      5581\n",
      "   macro avg       0.78      0.79      0.78      5581\n",
      "weighted avg       0.79      0.78      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "JBYAYJbcQWgL",
   "metadata": {
    "id": "JBYAYJbcQWgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047]\n",
      "0.7468627437658267\n"
     ]
    }
   ],
   "source": [
    "# Choosing 6 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 6)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "s8l_C9B8QWYo",
   "metadata": {
    "id": "s8l_C9B8QWYo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      2313\n",
      "           1       0.86      0.76      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.79      0.79      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "KWlEK_OiQwK2",
   "metadata": {
    "id": "KWlEK_OiQwK2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      2313\n",
      "           1       0.86      0.76      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.78      0.79      0.78      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bngzCiU3QwIf",
   "metadata": {
    "id": "bngzCiU3QwIf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154]\n",
      "0.7918942853578181\n"
     ]
    }
   ],
   "source": [
    "# Choosing 7 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 7)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "soN4XhBSQwGb",
   "metadata": {
    "id": "soN4XhBSQwGb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      2313\n",
      "           1       0.86      0.77      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "_42LTqyVQwD1",
   "metadata": {
    "id": "_42LTqyVQwD1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      2313\n",
      "           1       0.86      0.77      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "u0YonTwyQv8D",
   "metadata": {
    "id": "u0YonTwyQv8D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154 0.03535052]\n",
      "0.8272448094317142\n"
     ]
    }
   ],
   "source": [
    "# Choosing 8 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "nT4Jx-PlQ9ah",
   "metadata": {
    "id": "nT4Jx-PlQ9ah"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      2313\n",
      "           1       0.86      0.77      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "YH_ZBIJ-Q9kN",
   "metadata": {
    "id": "YH_ZBIJ-Q9kN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77      2313\n",
      "           1       0.86      0.77      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.80      0.79      0.80      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "pLXiEMT1Q9oV",
   "metadata": {
    "id": "pLXiEMT1Q9oV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154 0.03535052 0.03127994]\n",
      "0.8585247503865235\n"
     ]
    }
   ],
   "source": [
    "# Choosing 9 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 9)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "CrRvKy6ZQ9q5",
   "metadata": {
    "id": "CrRvKy6ZQ9q5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2313\n",
      "           1       0.86      0.77      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "wG8Z3AM1Q9tg",
   "metadata": {
    "id": "wG8Z3AM1Q9tg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.79.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2313\n",
      "           1       0.86      0.77      0.81      3268\n",
      "\n",
      "    accuracy                           0.79      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.80      0.79      0.79      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ksYproEXQ9v2",
   "metadata": {
    "id": "ksYproEXQ9v2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154 0.03535052 0.03127994 0.02999719]\n",
      "0.8885219386131462\n"
     ]
    }
   ],
   "source": [
    "# Choosing 10 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8foDIi7BQ9x8",
   "metadata": {
    "id": "8foDIi7BQ9x8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.80.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78      2313\n",
      "           1       0.87      0.77      0.82      3268\n",
      "\n",
      "    accuracy                           0.80      5581\n",
      "   macro avg       0.80      0.81      0.80      5581\n",
      "weighted avg       0.81      0.80      0.80      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "L6JfNi6ERNKV",
   "metadata": {
    "id": "L6JfNi6ERNKV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.80.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2313\n",
      "           1       0.87      0.77      0.82      3268\n",
      "\n",
      "    accuracy                           0.80      5581\n",
      "   macro avg       0.79      0.80      0.80      5581\n",
      "weighted avg       0.81      0.80      0.80      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "R6ys-skeRQdg",
   "metadata": {
    "id": "R6ys-skeRQdg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154 0.03535052 0.03127994 0.02999719 0.02956184]\n",
      "0.9180837815139106\n"
     ]
    }
   ],
   "source": [
    "# Choosing 11 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 11)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "IhZq2HQbRQaK",
   "metadata": {
    "id": "IhZq2HQbRQaK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.80.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78      2313\n",
      "           1       0.87      0.77      0.82      3268\n",
      "\n",
      "    accuracy                           0.80      5581\n",
      "   macro avg       0.80      0.81      0.80      5581\n",
      "weighted avg       0.81      0.80      0.80      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "Y7mrPI53RQVL",
   "metadata": {
    "id": "Y7mrPI53RQVL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.80.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2313\n",
      "           1       0.87      0.77      0.82      3268\n",
      "\n",
      "    accuracy                           0.80      5581\n",
      "   macro avg       0.79      0.80      0.79      5581\n",
      "weighted avg       0.81      0.80      0.80      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "Ivlg6wXaRQS0",
   "metadata": {
    "id": "Ivlg6wXaRQS0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154 0.03535052 0.03127994 0.02999719 0.02956184 0.02602467]\n",
      "0.9441084489161142\n"
     ]
    }
   ],
   "source": [
    "# Choosing 12 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 12)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50j4LbbiRQP8",
   "metadata": {
    "id": "50j4LbbiRQP8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.83.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81      2313\n",
      "           1       0.89      0.81      0.85      3268\n",
      "\n",
      "    accuracy                           0.83      5581\n",
      "   macro avg       0.83      0.84      0.83      5581\n",
      "weighted avg       0.84      0.83      0.83      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fxas4-ebRQN4",
   "metadata": {
    "id": "fxas4-ebRQN4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.83.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81      2313\n",
      "           1       0.90      0.79      0.84      3268\n",
      "\n",
      "    accuracy                           0.83      5581\n",
      "   macro avg       0.83      0.83      0.83      5581\n",
      "weighted avg       0.84      0.83      0.83      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "wSnkbNvzRQLR",
   "metadata": {
    "id": "wSnkbNvzRQLR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15808131 0.13146219 0.12403591 0.11839967 0.11057319 0.10431047\n",
      " 0.04503154 0.03535052 0.03127994 0.02999719 0.02956184 0.02602467\n",
      " 0.02270169]\n",
      "0.96681014287141\n"
     ]
    }
   ],
   "source": [
    "# Choosing 13 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 13)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "EIRAwZd_RQFk",
   "metadata": {
    "id": "EIRAwZd_RQFk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.83.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81      2313\n",
      "           1       0.89      0.81      0.85      3268\n",
      "\n",
      "    accuracy                           0.83      5581\n",
      "   macro avg       0.83      0.84      0.83      5581\n",
      "weighted avg       0.84      0.83      0.83      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "Ii8YX46VRQIq",
   "metadata": {
    "id": "Ii8YX46VRQIq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.83.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81      2313\n",
      "           1       0.90      0.79      0.84      3268\n",
      "\n",
      "    accuracy                           0.83      5581\n",
      "   macro avg       0.83      0.84      0.83      5581\n",
      "weighted avg       0.84      0.83      0.83      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y016yAJbRqQz",
   "metadata": {
    "id": "Y016yAJbRqQz"
   },
   "source": [
    "## Experimenting with Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dAhxGUBKRzq7",
   "metadata": {
    "id": "dAhxGUBKRzq7"
   },
   "source": [
    "### Testing Kernel PCA on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ewws7puYR6zo",
   "metadata": {
    "id": "ewws7puYR6zo"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 1, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3sKJmJleR6xT",
   "metadata": {
    "id": "3sKJmJleR6xT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74      2313\n",
      "           1       0.84      0.75      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.77      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "oQW8oa52R6u-",
   "metadata": {
    "id": "oQW8oa52R6u-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74      2313\n",
      "           1       0.84      0.75      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.77      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "lRv36l7IR6s4",
   "metadata": {
    "id": "lRv36l7IR6s4"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "q89jfsN0R6qz",
   "metadata": {
    "id": "q89jfsN0R6qz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      2313\n",
      "           1       0.85      0.75      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.78      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "TmvxWw9gR6ky",
   "metadata": {
    "id": "TmvxWw9gR6ky"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current model accuracy is 0.77.\n",
      "\n",
      "\n",
      "A more detailed report of the model's overall accuracy is:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.75      2313\n",
      "           1       0.85      0.75      0.79      3268\n",
      "\n",
      "    accuracy                           0.77      5581\n",
      "   macro avg       0.77      0.78      0.77      5581\n",
      "weighted avg       0.78      0.77      0.77      5581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "URkQeDhaR6iu",
   "metadata": {
    "id": "URkQeDhaR6iu"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 3, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4lVnv4GGR6go",
   "metadata": {
    "id": "4lVnv4GGR6go"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ml73RlphR6ej",
   "metadata": {
    "id": "Ml73RlphR6ej"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LI3RgEzDR6cO",
   "metadata": {
    "id": "LI3RgEzDR6cO"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 4, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmTaybubR6aH",
   "metadata": {
    "id": "zmTaybubR6aH"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KlG3ZTSjSQbg",
   "metadata": {
    "id": "KlG3ZTSjSQbg"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eJJIR0CuR6Xj",
   "metadata": {
    "id": "eJJIR0CuR6Xj"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 5, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5MH6wx13SZEF",
   "metadata": {
    "id": "5MH6wx13SZEF"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lqpKkPDsSZB_",
   "metadata": {
    "id": "lqpKkPDsSZB_"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rfOi3nsVSY_7",
   "metadata": {
    "id": "rfOi3nsVSY_7"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 6, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fg6u0pJOSY91",
   "metadata": {
    "id": "Fg6u0pJOSY91"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jzD3NNbFSY7v",
   "metadata": {
    "id": "jzD3NNbFSY7v"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WDZ3oxofSY5a",
   "metadata": {
    "id": "WDZ3oxofSY5a"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 7, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rJA5uxygSY3E",
   "metadata": {
    "id": "rJA5uxygSY3E"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wQdoWoI2SY0t",
   "metadata": {
    "id": "wQdoWoI2SY0t"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oFGw162oSYyY",
   "metadata": {
    "id": "oFGw162oSYyY"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 8, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BaMObfBKSYwD",
   "metadata": {
    "id": "BaMObfBKSYwD"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ch2pYSoRC",
   "metadata": {
    "id": "e83ch2pYSoRC"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MQfqadq1Sobx",
   "metadata": {
    "id": "MQfqadq1Sobx"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 9, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqxevkVYSoej",
   "metadata": {
    "id": "gqxevkVYSoej"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "osam7_w_Ss3k",
   "metadata": {
    "id": "osam7_w_Ss3k"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pVNXOKC8SuPr",
   "metadata": {
    "id": "pVNXOKC8SuPr"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 10, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O-cMl1piSuW3",
   "metadata": {
    "id": "O-cMl1piSuW3"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52257cd8-ef05-47b9-aa0e-d59e957a1d80",
   "metadata": {
    "id": "LesYXd0LSucW"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c12e0-2178-4361-8bf4-ea48c4f2e651",
   "metadata": {},
   "source": [
    "### Plotting LDA with Class Distinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e614b859-0826-41d3-bc7c-7078d4682358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Getting plot of LDA 1 and classifier value for train data\n",
    "\n",
    "# Getting columns named properly \n",
    "feature_1 = X_train_lda[:1000, 0]\n",
    "y = np.array(y_resampled_adasyn[:1000])\n",
    "second_y = np.zeros(1000)\n",
    "\n",
    "class_colors = {0: 'red', 1: 'blue'}\n",
    "\n",
    "# Plotting data with class-based colors\n",
    "for i in range(len(feature_1)):\n",
    "    plt.scatter(feature_1[i], second_y[i], color=class_colors[y[i]])\n",
    "\n",
    "# Creating legend elements\n",
    "legend_elements = [mpatches.Patch(color=color, label=cls) for cls, color in class_colors.items()]\n",
    "\n",
    "# Adding labels, legends and making graph nice\n",
    "plt.xlabel(\"LDA 1\")\n",
    "\n",
    "plt.title(\"LDA 1 with Class Distinction\")\n",
    "\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "# Showing plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e4ec9-e9c2-4893-9894-c1f1cb5cf5e1",
   "metadata": {},
   "source": [
    "## Model Selection: Hyperparameter Tuning and Cross Validation\n",
    "\n",
    "Based on the above dimensionality results, we will be using LDA, PCA with 10 components, and PCA with 13 components to train/tune our model. This is because LDA produced the highest metrics for both naive bayes and logistic regression with the greatest amount of dimensionality reduction. Additionally, PCA with 13 components also produced relatively similar metrics, while reducing the dataset to 13 columns that account for over `95%` of the overall data. PCA with 10 components will be used to see if after tunning, the results are similar to our other two dimensionality reduction methods and is a fun experiment to see if we can reduce half the number of columns. Finally based on the results of kernel PCA, we will not be using kernel PCA as a dimensionality reducer, as it provided similar/worse results in terms of model metrics for both naive bayes and logistic regression and was more computationaly expensive to reduce the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a73c2-7bca-4459-9d95-8c9a4a3cbab3",
   "metadata": {},
   "source": [
    "### Experimenting with GridSearchCV for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c556a60-becf-4eb8-987a-03c7613e7b4d",
   "metadata": {},
   "source": [
    "#### Setting up Logistic Regression model using GridsSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69692023-554e-4bdd-a0d9-886b9ba49f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up GridSearch for logistic regresion on all solvers\n",
    "\n",
    "# Importing in GridSearch and time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "    'penalty': ['l2'], # Can only do l2 for all models because some models do not take other penalties\n",
    "    'C': [0.001, 0.0001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52b02d-35ce-4e1a-b5aa-21f5475bd7cb",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on un-reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a10ca0fc-035b-4db5-9010-0ebaa547d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "The total elapsed time is: 5.331812858581543\n",
      "0.8060641446061142\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a1e72-5abe-4720-88c4-1ee609144ebe",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49715915-6501-48a7-b922-7ebac6f2c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "The total elapsed time is: 23.476019144058228\n",
      "0.8079004547777278\n",
      "{'C': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c113f3c-458f-4543-92ab-440627225437",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on PCA data with n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7221a81-e563-47da-a9b5-171fd81f2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 13 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 13)\n",
    "\n",
    "X_train_pca_13 = pca.fit_transform(X_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49602897-51d5-4f81-b001-e2663d6199c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "The total elapsed time is: 32.71337103843689\n",
      "0.8059112687945836\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fed116-795e-4015-83d7-06ffb3c79cf0",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on PCA data with n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc9d51cb-9bc8-4a48-a5e4-3e2967eac473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 10 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "X_train_pca_10 = pca.fit_transform(X_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f6c79e8-5bbc-4409-8ac1-383638c7fd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.827 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.3s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 3/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.8s\n",
      "[CV 3/5] END C=10, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.6s\n",
      "[CV 4/5] END C=10, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.8s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.9s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 4/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.830 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.783 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.758 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.800 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 2/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 3/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.8s\n",
      "[CV 2/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 3/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 2/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.5s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.769 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.712 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.828 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.830 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=liblinear;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.810 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.788 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=liblinear;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=liblinear;, score=0.839 total time=   0.1s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=liblinear;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.3s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.5s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.5s\n",
      "[CV 1/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.8s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.8s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.5s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.827 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.773 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.757 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "The total elapsed time is: 39.353209018707275\n",
      "0.7769882601506012\n",
      "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5736e23e-9b31-48f1-8f92-d7f360e5aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing grid parameters to exclude liblinear and add None as penalty option\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n",
    "    'penalty': ['l2', None], \n",
    "    'C': [0.001, 0.0001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4285f98-5c21-44e0-a74f-4a351a246d25",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73991b51-f54e-4506-b484-217d2740e1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 10.045046091079712\n",
      "0.8060641446061142\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69463bf6-f017-4384-9635-5ef470bad50f",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94f88c40-f528-41ad-8d7e-8fe9b49d3457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV 1/5] END .......C=1, penalty=l2, solver=sag;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END .C=100, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END ..C=10000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=10000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END .C=10000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, penalty=l2, solver=sag;, score=0.828 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.834 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .C=1, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=100, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, penalty=l2, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END .C=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=10000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END ...C=10000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ..C=10000, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END .C=10000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.779 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.2s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.2s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.4s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.8s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.832 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.800 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.0001, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.01, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END .C=0.01, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END .C=0.01, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END .C=0.01, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .C=0.01, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END .C=100, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END .C=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ...C=10000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=l2, solver=newton-cg;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, penalty=l2, solver=sag;, score=0.827 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.809 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END .C=0.0001, penalty=l2, solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END .C=0.0001, penalty=l2, solver=saga;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END .C=0.0001, penalty=l2, solver=saga;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END .C=0.0001, penalty=l2, solver=saga;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.01, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.01, penalty=None, solver=sag;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.01, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END .C=0.01, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END .C=0.01, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .C=0.01, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .C=0.01, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END .C=0.01, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ...C=100, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ...C=100, penalty=None, solver=sag;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END ..C=100, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, penalty=None, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ..C=100, penalty=None, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 2/5] END C=10000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=10000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=10000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.724 total time=   0.2s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.808 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.788 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.737 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.773 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.803 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.01, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ..C=0.01, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=1, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, penalty=l2, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ...C=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ..C=10000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ..C=10000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=10000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END .C=10000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.823 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.3s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.2s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.6s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.6s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.793 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.769 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.830 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.797 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.758 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.790 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.840 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 18.904957056045532\n",
      "0.8076325415281638\n",
      "{'C': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d6435-d187-478a-90d2-a0915ca3495a",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on PCA n = 13 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df21952e-f95b-4eec-ae4b-6586e359cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV 2/5] END ......C=10, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END ..C=10000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END .C=10000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, penalty=l2, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, penalty=l2, solver=saga;, score=0.827 total time=   0.1s\n",
      "[CV 1/5] END .C=0.001, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END .C=0.001, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.0001, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END ....C=1, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ....C=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ....C=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ....C=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ....C=1000, penalty=l2, solver=sag;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=10000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END .C=10000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.827 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.4s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.725 total time=   0.5s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.725 total time=   0.5s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.778 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.812 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.830 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.709 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.783 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.806 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.830 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.830 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.830 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.779 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.724 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END ..C=10000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=10000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, penalty=l2, solver=sag;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END .C=0.001, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END .C=0.001, penalty=None, solver=sag;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=0.0001, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=0.0001, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.1, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.1, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ..C=0.1, penalty=None, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ..C=0.1, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END .C=100, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END .C=100, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .C=100, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .C=100, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END .C=100, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ...C=100, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END .C=1000, penalty=None, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.1s\n",
      "[CV 2/5] END ...C=10000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=10000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=10000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=10000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.779 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.826 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.822 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.790 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.727 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.2s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.4s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.791 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.784 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.790 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.727 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.724 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=100, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END .....C=100, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END .....C=100, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END .....C=100, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END .....C=100, penalty=l2, solver=sag;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 3/5] END .C=1000, penalty=None, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=10000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ...C=10000, penalty=l2, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 4/5] END ..C=10000, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=10000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.823 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.823 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.790 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.727 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.4s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 3/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.753 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.791 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.773 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.757 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.693 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.803 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.790 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.8s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.6s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.0001, penalty=l2, solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.0001, penalty=l2, solver=sag;, score=0.809 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=l2, solver=newton-cg;, score=0.789 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.01, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.01, penalty=l2, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END ......C=10, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ......C=10, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ......C=10, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ......C=10, penalty=l2, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 5/5] END .C=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END C=10000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ...C=10000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=10000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .C=10000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.830 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.3s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.724 total time=   0.2s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.840 total time=   0.4s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.700 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.793 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.791 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.688 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=10, l1_ratio=0, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, penalty=l2, solver=lbfgs;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.0001, penalty=l2, solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.0001, penalty=l2, solver=sag;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.0001, penalty=l2, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0001, penalty=l2, solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END ...C=10, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END ...C=10, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 2/5] END .C=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END .C=10000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END ...C=10000, penalty=l2, solver=sag;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ..C=10000, penalty=l2, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END .C=10000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0, penalty=l1, solver=saga;, score=0.724 total time=   0.2s\n",
      "[CV 1/5] END C=1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.3s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=10, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.787 total time=   0.6s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=l1, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.827 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.753 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.830 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.830 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, penalty=l1, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, penalty=l1, solver=saga;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, penalty=l1, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=l1, solver=saga;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.800 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 3/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=1000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.830 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.765 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.766 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.810 total time=   0.1s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 34.79592204093933\n",
      "0.8056434799652032\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39952f67-abca-411b-9cf0-81cc5b46a649",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on PCA n = 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4ff3a2e-d002-42c3-9c6a-3678e2c8fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1208: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 47.463353872299194\n",
      "0.7769882601506012\n",
      "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37d4a8e9-0edd-4c73-baf6-df64bafa4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying all possible combinations with saga solver that have not been explored\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['saga'], \n",
    "    'penalty': ['l1','elasticnet'], \n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    'l1_ratio': [0, 0.5, 1], \n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77241ec3-8379-44a2-8a1e-7b79380bb51a",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df268bf4-8481-46e5-8c8a-67136b357ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 13.877839088439941\n",
      "0.8061407069320632\n",
      "{'C': 0.01, 'l1_ratio': 0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eeb97e-297d-48c8-afd1-0fd0ce9049e3",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77c66237-29a8-4158-8664-8b9931a88709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, l1_ratio=1, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=1, penalty=l1, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 3/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=1, penalty=l1, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=l1, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 4/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=10000, l1_ratio=0.5, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=1, penalty=l1, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.724 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.765 total time=   0.1s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.712 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.788 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, penalty=elasticnet, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, l1_ratio=1, penalty=elasticnet, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10000, l1_ratio=0, penalty=l1, solver=saga;, score=0.807 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.8s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.788 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.840 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.1s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.828 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.829 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.731 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.797 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.703 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.792 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.703 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 19.97633671760559\n",
      "0.8067527298154233\n",
      "{'C': 0.001, 'l1_ratio': 0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5c185-655c-4504-8c33-3be95bd7fbef",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on PCA n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39b62551-968f-4e80-b89b-b79391584a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.2s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.2s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.6s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.842 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.725 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.809 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.757 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.713 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.810 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.766 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.810 total time=   0.1s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.843 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.829 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.763 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.757 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.752 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.752 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.703 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.823 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 32.37112379074097\n",
      "0.8056434799652032\n",
      "{'C': 0.01, 'l1_ratio': 0, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0e8eb-8af6-4ea5-a691-c026277d75a2",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on PCA n = 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77489724-c775-482d-b28e-77f2d851076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.3s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.3s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.827 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.829 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.834 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.797 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.758 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.1s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.779 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.779 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.2s\n",
      "[CV 4/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.2s\n",
      "[CV 5/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.725 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.839 total time=   0.4s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.4s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.839 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=sag;, score=0.729 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.827 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.709 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.793 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.752 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.703 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.806 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.828 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.838 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.2s\n",
      "[CV 1/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.3s\n",
      "[CV 1/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 4/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 5/5] END C=10, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=100, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.8s\n",
      "[CV 3/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.4s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.725 total time=   0.2s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.840 total time=   0.5s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.842 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.839 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.732 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.787 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=saga;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.730 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=sag;, score=0.757 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.830 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.789 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.729 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.842 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 2/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.841 total time=   0.3s\n",
      "[CV 3/5] END C=1, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 3/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END C=1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 4/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.724 total time=   0.2s\n",
      "[CV 4/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 5/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.3s\n",
      "[CV 1/5] END C=10, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.8s\n",
      "[CV 2/5] END C=10, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 4/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 5/5] END C=100, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 5/5] END C=100, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=100, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.8s\n",
      "[CV 1/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.6s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.839 total time=   0.3s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.787 total time=   0.5s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.785 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.839 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.844 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=sag;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 3/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END C=10, max_iter=1000, penalty=None, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=l2, solver=saga;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.841 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.838 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=sag;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.835 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.828 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.810 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.809 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.811 total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.810 total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.811 total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=l2, solver=saga;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.834 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=None, solver=lbfgs;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.730 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.833 total time=   0.1s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.787 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.757 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 4/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=0.0001, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=None, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.805 total time=   0.1s\n",
      "[CV 2/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.759 total time=   0.1s\n",
      "[CV 5/5] END C=1, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.1s\n",
      "[CV 1/5] END C=1, max_iter=1000, penalty=l2, solver=saga;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=100, max_iter=1000, penalty=l2, solver=saga;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.799 total time=   0.1s\n",
      "[CV 4/5] END C=100, max_iter=1000, penalty=None, solver=newton-cg;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END C=1000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END C=1000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END C=1000, max_iter=1000, penalty=None, solver=sag;, score=0.807 total time=   0.1s\n",
      "[CV 3/5] END C=1000, max_iter=1000, penalty=None, solver=saga;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=l2, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END C=10000, max_iter=1000, penalty=l2, solver=sag;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END C=10000, max_iter=1000, penalty=None, solver=newton-cg;, score=0.805 total time=   0.0s\n",
      "[CV 3/5] END C=10000, max_iter=1000, penalty=None, solver=lbfgs;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=10000, max_iter=1000, penalty=None, solver=saga;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.829 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.817 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.774 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.790 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.790 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.727 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.788 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.724 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, l1_ratio=1, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.1s\n",
      "[CV 1/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=1, l1_ratio=0.5, max_iter=1000, penalty=l1, solver=saga;, score=0.841 total time=   0.4s\n",
      "[CV 5/5] END C=10, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.725 total time=   0.4s\n",
      "[CV 1/5] END C=10, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.839 total time=   0.5s\n",
      "[CV 2/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.840 total time=   0.6s\n",
      "[CV 3/5] END C=10, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 3/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=100, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.787 total time=   0.9s\n",
      "[CV 1/5] END C=100, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.839 total time=   0.7s\n",
      "[CV 2/5] END C=100, l1_ratio=1, max_iter=1000, penalty=l1, solver=saga;, score=0.840 total time=   0.7s\n",
      "[CV 3/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=l1, solver=saga;, score=0.837 total time=   0.5s\n",
      "[CV 4/5] END C=1000, l1_ratio=0, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.7s\n",
      "[CV 4/5] END C=1000, l1_ratio=0.5, max_iter=1000, penalty=elasticnet, solver=saga;, score=0.787 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total elapsed time is: 47.356590032577515\n",
      "0.7769882601506012\n",
      "{'C': 0.1, 'l1_ratio': 0, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d749c-a718-49fc-b821-ba7411ac80b8",
   "metadata": {},
   "source": [
    "#### Testing all versions of liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16f0c64f-49e0-463c-9283-89e678047f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying all possible combinations with saga solver that have not been explored\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['liblinear'], \n",
    "    'penalty': ['l1','l2'], \n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16314f-636c-469f-8124-f4d590140ea4",
   "metadata": {},
   "source": [
    "##### Completing GridSearch on unreduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9205e508-ec82-402e-bc4a-982af74d168d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The total elapsed time is: 62.81328797340393\n",
      "0.806867555007261\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86359cd-b260-4df6-bd7d-5be12019a097",
   "metadata": {},
   "source": [
    "##### Completing GridSearch for LDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3bc8a7f-0dee-47ca-ac6a-391e7ddf8f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The total elapsed time is: 111.20862102508545\n",
      "0.8081683021577828\n",
      "{'C': 0.001, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c4c0f-11d2-4a66-8446-289ede68f450",
   "metadata": {},
   "source": [
    "##### Completing GridSearch for PCA dataset with n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e71bdea9-c49b-4ddf-b661-daca0acb1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The total elapsed time is: 169.07081699371338\n",
      "0.8059495975299813\n",
      "{'C': 0.01, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675211f-043e-4dab-a5d1-2f960ee9b828",
   "metadata": {},
   "source": [
    "##### Completing GridSearch for PCA dataset with n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "344bcc6c-0182-473e-b8c8-d8708d18db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The total elapsed time is: 228.55464696884155\n",
      "0.7769882601506012\n",
      "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59666b-651e-48bf-90ea-3ce2492543c9",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning/Cross Validation with Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e4d62-9a6b-464a-ac89-9797ce4bf6ca",
   "metadata": {},
   "source": [
    "#### Creating GridSearch for Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b397774-2d0e-4583-8748-bdb109d3a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying all possible combinations with saga solver that have not been explored\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'var_smoothing': [1e-11, 1e-10, 1e-9],\n",
    "    'priors': [[0.9, 0.1], [0.8, 0.2], [0.7, 0.3], [0.6, 0.4], None]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator = nb_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa0559-cada-443a-8496-92201566a8c8",
   "metadata": {},
   "source": [
    "##### Testing on unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c11023a-0787-4e2f-8bbb-0404bb3a8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "The total elapsed time is: 72.99946880340576\n",
      "0.7885798592412506\n",
      "{'priors': [0.6, 0.4], 'var_smoothing': 1e-11}\n"
     ]
    }
   ],
   "source": [
    "nb_grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5f3d0-0297-4755-893e-c638e548d363",
   "metadata": {},
   "source": [
    "##### Testing on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d845ba8-8b0f-4115-b884-877818ae2614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "The total elapsed time is: 132.46868705749512\n",
      "0.8066007103075096\n",
      "{'priors': [0.6, 0.4], 'var_smoothing': 1e-11}\n"
     ]
    }
   ],
   "source": [
    "nb_grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc82e9-5bf2-401a-aea7-1c1aff6ee3f1",
   "metadata": {},
   "source": [
    "##### Testing on PCA data where n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f79ac81-ce20-48bf-9a40-f36b1372d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "The total elapsed time is: 186.01744198799133\n",
      "0.8035013962140255\n",
      "{'priors': None, 'var_smoothing': 1e-11}\n"
     ]
    }
   ],
   "source": [
    "nb_grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77fc53-a30c-4c81-9c22-d1d714473685",
   "metadata": {},
   "source": [
    "##### Testing on PCA data where n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "346f87ba-8c35-413c-8323-ecf96662174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "The total elapsed time is: 255.01480412483215\n",
      "0.7713259634623297\n",
      "{'priors': None, 'var_smoothing': 1e-11}\n"
     ]
    }
   ],
   "source": [
    "nb_grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b9939-faf1-48a4-9507-46e8bf9b9d5b",
   "metadata": {
    "id": "423b9939-faf1-48a4-9507-46e8bf9b9d5b"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df72ff-d842-4556-94bf-54c322cfc05d",
   "metadata": {
    "id": "59df72ff-d842-4556-94bf-54c322cfc05d"
   },
   "source": [
    "# Cristian Zendejas\n",
    "* RandomForestClassifier\n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217afe96-9a5c-4e14-ada5-2b0ce17a9c1b",
   "metadata": {
    "id": "217afe96-9a5c-4e14-ada5-2b0ce17a9c1b"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547541b-b758-4c5b-a843-9858e68fe96b",
   "metadata": {
    "id": "b547541b-b758-4c5b-a843-9858e68fe96b"
   },
   "source": [
    "### Performing PCA here with the 2 different resampled datasets. Both will also be used to train separate models for RandomForestClassifier & Decision Tree. The experiement for this section will be to see which form of analysis PCA, LDA, or Kernel PCA will produce the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f921d-58a2-4078-b9d7-52e95755d4be",
   "metadata": {
    "id": "1a0f921d-58a2-4078-b9d7-52e95755d4be"
   },
   "outputs": [],
   "source": [
    "# look into a chart to display the current data we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b181db-5ada-460a-bd3c-77cf8a0cc9bf",
   "metadata": {
    "id": "03b181db-5ada-460a-bd3c-77cf8a0cc9bf"
   },
   "outputs": [],
   "source": [
    "# keep an eye on the accuracy for the base models and after the dimensionality reduction, Karryn said her accuracy did not change much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751960a-da24-45ce-931c-d468374c11f1",
   "metadata": {
    "id": "2751960a-da24-45ce-931c-d468374c11f1"
   },
   "outputs": [],
   "source": [
    "# did we decide to drop random under sampler since it didn't provide much value when using it in the models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbeb620-fc2c-43e4-a51b-bb7fc6b23d94",
   "metadata": {
    "id": "dcbeb620-fc2c-43e4-a51b-bb7fc6b23d94"
   },
   "source": [
    "## Establishing some base models to compare later models too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23060a-68de-481e-978d-d03649fd938b",
   "metadata": {
    "id": "3f23060a-68de-481e-978d-d03649fd938b"
   },
   "outputs": [],
   "source": [
    "rfc_base_model = RandomForestClassifier(criterion='entropy')\n",
    "rfc_base_model.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "rfc_base_y_hat = rfc_base_model.predict(X_test)\n",
    "print(rfc_base_y_hat)\n",
    "\n",
    "rfc_base_precision = precision_score(y_test, rfc_base_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_base_recall = recall_score(y_test, rfc_base_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_base_f1 = f1_score(y_test, rfc_base_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_base_accuracy = rfc_base_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_base_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_base_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_base_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_base_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8685c-a3a2-4c83-a0d6-d6915bc35b5d",
   "metadata": {
    "id": "41d8685c-a3a2-4c83-a0d6-d6915bc35b5d"
   },
   "outputs": [],
   "source": [
    "dtc_base_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_base_model.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "dtc_base_y_hat = dtc_base_model.predict(X_test)\n",
    "\n",
    "dtc_base_precision = precision_score(y_test, dtc_base_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_base_recall = recall_score(y_test, dtc_base_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_base_f1 = f1_score(y_test, dtc_base_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_base_accuracy = dtc_base_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_base_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_base_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_base_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_base_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbaeb9-f820-41d0-b4aa-b128998136cd",
   "metadata": {
    "id": "f4cbaeb9-f820-41d0-b4aa-b128998136cd"
   },
   "source": [
    "### I'm expecting the RandomForestClassifier to do better than DecisionTreeClassifier since it is just an improved version of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5959665-a190-425a-bbc4-7b54a2078b54",
   "metadata": {
    "id": "b5959665-a190-425a-bbc4-7b54a2078b54"
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8544ca-9bfc-4ff3-8a1e-859a3e262abe",
   "metadata": {
    "id": "3a8544ca-9bfc-4ff3-8a1e-859a3e262abe"
   },
   "outputs": [],
   "source": [
    "def find_best_explained_variance(model_class, X_train, y_train):\n",
    "    print(model_class)\n",
    "    best_explained_variance = -np.inf # using negative infinity to ensure the variable is updated.\n",
    "    best_n_components = None\n",
    "    n_range = np.arange(1,15)\n",
    "\n",
    "    for n in n_range:\n",
    "        if model_class == PCA:\n",
    "            model = PCA(n_components=n)\n",
    "        elif model_class == LinearDiscriminantAnalysis: # do I event want to find the best components for this?\n",
    "            n_classes = len(np.unique(y_train))\n",
    "            max_components = min(X_train.shape[1], n_classes - 1)\n",
    "            if n > max_components:\n",
    "                continue\n",
    "            model = LinearDiscriminantAnalysis(n_components=n)\n",
    "        elif model_class == KernelPCA:\n",
    "            model = KernelPCA(n_components=n, kernel='rbf')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model class\")\n",
    "\n",
    "        if model_class == PCA or model_class == KernelPCA:\n",
    "            X_train_transformed = model.fit_transform(X_train)\n",
    "        else:\n",
    "            X_train_transformed = model.fit_transform(X_train, y_train)\n",
    "\n",
    "        if model_class == PCA or model_class == LinearDiscriminantAnalysis:\n",
    "            explained_variance = np.sum(model.explained_variance_ratio_)\n",
    "            # print(explained_variance)\n",
    "        elif model_class == KernelPCA:\n",
    "            explained_variance = np.sum(np.var(X_train_transformed, axis=0)) / np.sum(np.var(X_train, axis=0))\n",
    "\n",
    "        if explained_variance > best_explained_variance:\n",
    "            best_explained_variance = explained_variance\n",
    "            best_n_components = n\n",
    "\n",
    "    return best_explained_variance, best_n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6e2dd-bdcc-4d6a-9805-41e569c4d747",
   "metadata": {
    "id": "41e6e2dd-bdcc-4d6a-9805-41e569c4d747"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(PCA, X_resampled_adasyn, y_resampled_adasyn)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f0dcc-8a6d-4a77-a1c1-dd4231c36c09",
   "metadata": {
    "id": "473f0dcc-8a6d-4a77-a1c1-dd4231c36c09"
   },
   "outputs": [],
   "source": [
    "pca_1 = PCA(n_components=best_n_components)\n",
    "X_train_pca_adasyn = pca_1.fit_transform(X_resampled_adasyn)\n",
    "print(X_train_pca_adasyn.shape)\n",
    "# did not actually use adasyn for test set, just using the naming to keep track which variables belong with their respective algorithms\n",
    "X_test_pca_adasyn = pca_1.transform(X_test)\n",
    "print(X_test_pca_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de567eeb-b7dd-420e-9bc0-9f7399c4b917",
   "metadata": {
    "id": "de567eeb-b7dd-420e-9bc0-9f7399c4b917"
   },
   "outputs": [],
   "source": [
    "pca_1.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560eeadc-b52e-4cb7-8a90-866c3c9b56f3",
   "metadata": {
    "id": "560eeadc-b52e-4cb7-8a90-866c3c9b56f3"
   },
   "outputs": [],
   "source": [
    "pca_1.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2151ba-3794-4e54-b103-e5eb0025b13c",
   "metadata": {
    "id": "9e2151ba-3794-4e54-b103-e5eb0025b13c"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_1.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7c701-2af2-4df8-baca-4d24bd382cdf",
   "metadata": {
    "id": "51f7c701-2af2-4df8-baca-4d24bd382cdf"
   },
   "outputs": [],
   "source": [
    "print(X_train_pca_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086cfcf7-7fb8-463d-917b-5fa00a37df97",
   "metadata": {
    "id": "086cfcf7-7fb8-463d-917b-5fa00a37df97"
   },
   "source": [
    "### 14 components seems to get me the closest to .95 or greater variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c842622-31df-4580-b0d2-52b5512b92cf",
   "metadata": {
    "id": "2c842622-31df-4580-b0d2-52b5512b92cf"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(PCA, X_resampled_rus, y_resampled_rus)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9cb1d-137b-4a46-a807-8abe44ab1e59",
   "metadata": {
    "id": "05d9cb1d-137b-4a46-a807-8abe44ab1e59"
   },
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=best_n_components)\n",
    "X_train_pca_rus = pca_2.fit_transform(X_resampled_rus)\n",
    "print(X_train_pca_rus.shape)\n",
    "# did not actually use rus for test set, just using the naming to keep track which variables belong with their respective algorithms\n",
    "X_test_pca_rus = pca_2.transform(X_test)\n",
    "print(X_test_pca_rus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0a3d5-9d36-4146-8602-86ae99b2e9e3",
   "metadata": {
    "id": "ddf0a3d5-9d36-4146-8602-86ae99b2e9e3"
   },
   "outputs": [],
   "source": [
    "pca_2.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0a445-6131-46f9-8f85-49c28c68fd64",
   "metadata": {
    "id": "bcd0a445-6131-46f9-8f85-49c28c68fd64"
   },
   "outputs": [],
   "source": [
    "pca_2.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19446e64-bd60-4924-bf49-f94024a7470f",
   "metadata": {
    "id": "19446e64-bd60-4924-bf49-f94024a7470f"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_2.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1effc-cd32-4981-a7be-d10ad1e312ae",
   "metadata": {
    "id": "5ae1effc-cd32-4981-a7be-d10ad1e312ae"
   },
   "outputs": [],
   "source": [
    "print(X_train_pca_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939a50d-cbe9-4dad-bd00-f9b5ba37a389",
   "metadata": {
    "id": "0939a50d-cbe9-4dad-bd00-f9b5ba37a389"
   },
   "source": [
    "### RandomForestClassifier models with one using the ADASYN training data and the other using the RandomUnderSampler data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c3956-026f-4a1a-b5e5-0a91b1597eaa",
   "metadata": {
    "id": "435c3956-026f-4a1a-b5e5-0a91b1597eaa"
   },
   "outputs": [],
   "source": [
    "rfc_pca_1_model = RandomForestClassifier(criterion='entropy')# need to verify this is the right criterion\n",
    "rfc_pca_1_model.fit(X_train_pca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b0b2a-f5c7-415b-9b2c-fc2ea9275a37",
   "metadata": {
    "id": "175b0b2a-f5c7-415b-9b2c-fc2ea9275a37"
   },
   "outputs": [],
   "source": [
    "rfc_pca_1_y_hat = rfc_pca_1_model.predict(X_test_pca_adasyn)\n",
    "print(rfc_pca_1_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7e3a9-cbaf-41e0-a950-bc9219d000aa",
   "metadata": {
    "id": "cda7e3a9-cbaf-41e0-a950-bc9219d000aa"
   },
   "outputs": [],
   "source": [
    "rfc_pca_1_precision = precision_score(y_test, rfc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_1_recall = recall_score(y_test, rfc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_1_f1 = f1_score(y_test, rfc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_1_accuracy = rfc_pca_1_model.score(X_test_pca_adasyn, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_pca_1_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_pca_1_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_pca_1_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_pca_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23c493-c50d-493b-80d0-e90ced884280",
   "metadata": {
    "id": "1c23c493-c50d-493b-80d0-e90ced884280"
   },
   "outputs": [],
   "source": [
    "rfc_pca_2_model = RandomForestClassifier(criterion='entropy')# need to verify this is the right criterion\n",
    "rfc_pca_2_model.fit(X_train_pca_rus, y_resampled_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e19ab-8fef-4791-8bdd-282f37b1967d",
   "metadata": {
    "id": "d83e19ab-8fef-4791-8bdd-282f37b1967d"
   },
   "outputs": [],
   "source": [
    "rfc_pca_2_y_hat = rfc_pca_2_model.predict(X_test_pca_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481a2ed-6619-4fe2-ac7d-a4f60a5d8a8f",
   "metadata": {
    "id": "2481a2ed-6619-4fe2-ac7d-a4f60a5d8a8f"
   },
   "outputs": [],
   "source": [
    "rfc_pca_2_precision = precision_score(y_test, rfc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_2_recall = recall_score(y_test, rfc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_2_f1 = f1_score(y_test, rfc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_2_accuracy = rfc_pca_2_model.score(X_test_pca_rus, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_pca_2_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_pca_2_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_pca_2_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_pca_2_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c61d260-45f0-49f6-862b-8c0381e901a5",
   "metadata": {
    "id": "0c61d260-45f0-49f6-862b-8c0381e901a5"
   },
   "source": [
    "### When looking at the metrics there isn't much of a difference between using RandomUnderSampling and ADASYN. I may decide not use RandomUnderSampling for future models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c3e37-8d84-4f60-b256-74c315e6887f",
   "metadata": {
    "id": "732c3e37-8d84-4f60-b256-74c315e6887f"
   },
   "source": [
    "### Let's check with the decision tree models to see if there is any improvements. I'll use ADASYN and the RandomUnderSampling data sets again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49a307-5da8-4551-b56c-d9192df2488a",
   "metadata": {
    "id": "1f49a307-5da8-4551-b56c-d9192df2488a"
   },
   "outputs": [],
   "source": [
    "dtc_pca_1_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_pca_1_model.fit(X_train_pca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94d07f-f779-4b30-bace-4df5cc874f6d",
   "metadata": {
    "id": "eb94d07f-f779-4b30-bace-4df5cc874f6d"
   },
   "outputs": [],
   "source": [
    "dtc_pca_1_y_hat = dtc_pca_1_model.predict(X_test_pca_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2286e-9667-4db1-aac7-9566f21b7037",
   "metadata": {
    "id": "f4e2286e-9667-4db1-aac7-9566f21b7037"
   },
   "outputs": [],
   "source": [
    "dtc_pca_1_precision = precision_score(y_test, dtc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_1_recall = recall_score(y_test, dtc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_1_f1 = f1_score(y_test, dtc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_1_accuracy = dtc_pca_1_model.score(X_test_pca_adasyn, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_pca_1_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_pca_1_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_pca_1_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_pca_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb6fae-5ac2-4ed9-9d23-99bb86ff9187",
   "metadata": {
    "id": "9afb6fae-5ac2-4ed9-9d23-99bb86ff9187"
   },
   "outputs": [],
   "source": [
    "dtc_pca_2_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_pca_2_model.fit(X_train_pca_rus, y_resampled_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0435d-86a1-4fcc-9410-f2d171320c72",
   "metadata": {
    "id": "06d0435d-86a1-4fcc-9410-f2d171320c72"
   },
   "outputs": [],
   "source": [
    "dtc_pca_2_y_hat = dtc_pca_2_model.predict(X_test_pca_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633cb69-882f-4607-8cfe-08bc8f11913c",
   "metadata": {
    "id": "7633cb69-882f-4607-8cfe-08bc8f11913c"
   },
   "outputs": [],
   "source": [
    "dtc_pca_2_precision = precision_score(y_test, dtc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_2_recall = recall_score(y_test, dtc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_2_f1 = f1_score(y_test, dtc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_2_accuracy = dtc_pca_2_model.score(X_test_pca_rus, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_pca_2_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_pca_2_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_pca_2_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_pca_2_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570fec1-eaf1-4898-8a28-9f54072ddaf9",
   "metadata": {
    "id": "6570fec1-eaf1-4898-8a28-9f54072ddaf9"
   },
   "source": [
    "### Using the RandomUnderSampling technique again didn't provide much benefit here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e82626-5319-47f7-b196-61e444f078e9",
   "metadata": {
    "id": "c5e82626-5319-47f7-b196-61e444f078e9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c771f-6fe3-45a4-962e-96ff5fcf1430",
   "metadata": {
    "id": "c16c771f-6fe3-45a4-962e-96ff5fcf1430"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(LinearDiscriminantAnalysis, X_resampled_adasyn, y_resampled_adasyn)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6703b0-6a08-4249-b6b2-34172c4904c3",
   "metadata": {
    "id": "9a6703b0-6a08-4249-b6b2-34172c4904c3"
   },
   "outputs": [],
   "source": [
    "lda_1 = LinearDiscriminantAnalysis(n_components=best_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072294e3-a9fe-4577-9445-44ee7933d292",
   "metadata": {
    "id": "072294e3-a9fe-4577-9445-44ee7933d292"
   },
   "outputs": [],
   "source": [
    "X_train_lda_adasyn = lda_1.fit_transform(X_resampled_adasyn, y_resampled_adasyn)\n",
    "X_test_lda_adasyn = lda_1.transform(X_test)\n",
    "print(X_train_lda_adasyn.shape)\n",
    "print(X_test_lda_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b74a78-9f4d-4ca1-be6a-4dae738ef01e",
   "metadata": {
    "id": "14b74a78-9f4d-4ca1-be6a-4dae738ef01e"
   },
   "outputs": [],
   "source": [
    "# need to update these\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(X_train_lda_adasyn, y_resampled_adasyn, c=y_resampled_adasyn, cmap='tab20')\n",
    "\n",
    "# plt.xlabel('LDA Component')\n",
    "# plt.ylabel('Class')\n",
    "# plt.title('LDA Component 1 vs Class')\n",
    "# plt.colorbar(label='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17756bb-8a57-4d23-9922-c8b3b6450e12",
   "metadata": {
    "id": "d17756bb-8a57-4d23-9922-c8b3b6450e12"
   },
   "outputs": [],
   "source": [
    "rfc_lda_1_model = RandomForestClassifier(criterion='entropy')\n",
    "rfc_lda_1_model.fit(X_train_lda_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d8aba-3543-4fa0-bdf7-06dc057eda92",
   "metadata": {
    "id": "fb5d8aba-3543-4fa0-bdf7-06dc057eda92"
   },
   "outputs": [],
   "source": [
    "rfc_lda_1_y_hat = rfc_lda_1_model.predict(X_test_lda_adasyn)\n",
    "print(rfc_lda_1_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606b8c0-a8e6-4f39-a776-c2c27849fe6b",
   "metadata": {
    "id": "f606b8c0-a8e6-4f39-a776-c2c27849fe6b"
   },
   "outputs": [],
   "source": [
    "rfc_lda_1_precision = precision_score(y_test, rfc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_lda_1_recall = recall_score(y_test, rfc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_lda_1_f1 = f1_score(y_test, rfc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_lda_1_accuracy = rfc_lda_1_model.score(X_test_lda_adasyn, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_lda_1_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_lda_1_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_lda_1_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_lda_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fee02f-9005-4272-95d7-d9736956c9cf",
   "metadata": {
    "id": "00fee02f-9005-4272-95d7-d9736956c9cf"
   },
   "outputs": [],
   "source": [
    "dtc_lda_1_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_lda_1_model.fit(X_train_lda_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b432053-a92d-44e0-94a2-8a9dae7f2c89",
   "metadata": {
    "id": "2b432053-a92d-44e0-94a2-8a9dae7f2c89"
   },
   "outputs": [],
   "source": [
    "dtc_lda_1_y_hat = dtc_lda_1_model.predict(X_test_lda_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0064b-cfcc-4dd4-8c64-0a34640bb846",
   "metadata": {
    "id": "32f0064b-cfcc-4dd4-8c64-0a34640bb846"
   },
   "outputs": [],
   "source": [
    "dtc_lda_1_precision = precision_score(y_test, dtc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_lda_1_recall = recall_score(y_test, dtc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_lda_1_f1 = f1_score(y_test, dtc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_lda_1_accuracy = dtc_lda_1_model.score(X_test_lda_adasyn, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_lda_1_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_lda_1_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_lda_1_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_lda_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418c57f-4da9-41af-b009-f4947cb83d58",
   "metadata": {
    "id": "0418c57f-4da9-41af-b009-f4947cb83d58"
   },
   "source": [
    "### With LDA proving to have lower metrics for both the RandomForestClassifier and DecisionTreeClassifiers, I do not believe using LinearDiscriminantAnalysis with the RandomUnderSampling technique will be much better so I'll go straight to Kernel PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e358b-fea6-4fe2-8114-3f825b43fa7f",
   "metadata": {
    "id": "725e358b-fea6-4fe2-8114-3f825b43fa7f"
   },
   "outputs": [],
   "source": [
    "# a chart here to display the metrics for both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1bad0-f138-4a73-943a-5ba2fa9f2ebe",
   "metadata": {
    "id": "a3a1bad0-f138-4a73-943a-5ba2fa9f2ebe"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f76f7-24b0-4cec-8c43-309714b82a03",
   "metadata": {
    "id": "7c7f76f7-24b0-4cec-8c43-309714b82a03"
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('kpca', KernelPCA(kernel='rbf')),\n",
    "#     ('rfc', RandomForestClassifier(criterion='entropy'))\n",
    "# ])\n",
    "\n",
    "# n = np.arange(1,11)\n",
    "# param_grid = {\n",
    "#     'kpca__n_components': n,\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline, param_grid)\n",
    "# grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# print(f\"Optimal parameters: {best_params}\")\n",
    "\n",
    "# kernel_pca_optimal = KernelPCA(n_components=best_params['kpca__n_components'], kernel='rbf')\n",
    "# X_train_kpca_adasyn = kernel_pca_optimal.fit_transform(X_resampled_adasyn)\n",
    "# X_test_kpca_adasyn = kernel_pca_optimal.transform(X_test)\n",
    "\n",
    "# rfc_kpca_model = RandomForestClassifier(criterion='entropy')\n",
    "# rfc_kpca_model.fit(X_train_kpca_adasyn, y_resampled_adasyn)\n",
    "\n",
    "# cv_scores = cross_val_score(rfc_kpca_model, X_train_kpca_adasyn, y_resampled_adasyn)\n",
    "# print(f\"Cross-validation scores: {cv_scores}\")\n",
    "# print(f\"Mean cross-validation score: {cv_scores.mean()}\")\n",
    "\n",
    "# test_score = rfc_kpca_model.score(X_test_kpca_adasyn, y_test)\n",
    "# print(f\"Test set score: {test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124a6df-0f62-4a3d-b7ab-8883b6f1fe29",
   "metadata": {
    "id": "1124a6df-0f62-4a3d-b7ab-8883b6f1fe29"
   },
   "outputs": [],
   "source": [
    "# kernel_pca_1 = KernelPCA(n_components=2, kernel='rbf')\n",
    "# X_train_kpca_adasyn = kernel_pca_1.fit_transform(X_resampled_adasyn)\n",
    "# X_test_kpca_adasyn = kernel_pca_1.transform(X_test)\n",
    "# print(X_train_kpca_adasyn.shape)\n",
    "# print(X_test_kpca_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182de7d4-95e3-4c0b-8d2e-f15486dfadf5",
   "metadata": {
    "id": "182de7d4-95e3-4c0b-8d2e-f15486dfadf5"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(KernelPCA, X_resampled_adasyn, y_resampled_adasyn)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1768152-7eff-4ef4-8f63-03c1b522e67f",
   "metadata": {
    "id": "a1768152-7eff-4ef4-8f63-03c1b522e67f"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(X_train_kpca_adasyn, X_train_kpca_adasyn, c=y_resampled_adasyn, cmap='tab20')\n",
    "\n",
    "# plt.xlabel('Kernel PCA Component 1')\n",
    "# plt.ylabel('Kernel PCA Component 2')\n",
    "# plt.title('Kernel PCA Component vs Class')\n",
    "# plt.colorbar(label='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd08513-d902-4e1d-89ca-15e348ebecd2",
   "metadata": {
    "id": "acd08513-d902-4e1d-89ca-15e348ebecd2"
   },
   "outputs": [],
   "source": [
    "optimal_kpca = KernelPCA(n_components=best_n_components, kernel='rbf')\n",
    "X_train_kpca_adasyn = optimal_kpca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kpca_adasyn = optimal_kpca.transform(X_test)\n",
    "print(X_train_kpca_adasyn.shape)\n",
    "print(X_test_kpca_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bada26b-9da0-4ba0-9454-77423c069f7c",
   "metadata": {
    "id": "1bada26b-9da0-4ba0-9454-77423c069f7c"
   },
   "outputs": [],
   "source": [
    "rfc_kpca_model = RandomForestClassifier(criterion='entropy')\n",
    "rfc_kpca_model.fit(X_train_kpca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca81b93-0098-4a8a-bf89-6e0ddb208ce4",
   "metadata": {
    "id": "1ca81b93-0098-4a8a-bf89-6e0ddb208ce4"
   },
   "outputs": [],
   "source": [
    "rfc_kpca_y_hat = rfc_kpca_model.predict(X_test_kpca_adasyn)\n",
    "print(rfc_kpca_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ab7a9-85f6-45c6-b1d6-b4b69cd5eb0b",
   "metadata": {
    "id": "690ab7a9-85f6-45c6-b1d6-b4b69cd5eb0b"
   },
   "outputs": [],
   "source": [
    "rfc_kpca_precision = precision_score(y_test, rfc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_kpca_recall = recall_score(y_test, rfc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_kpca_f1 = f1_score(y_test, rfc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_kpca_accuracy = rfc_kpca_model.score(X_test_kpca_adasyn, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_kpca_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_kpca_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_kpca_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_kpca_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1094cd2-af52-46f3-920f-b7b96278acd9",
   "metadata": {
    "id": "f1094cd2-af52-46f3-920f-b7b96278acd9"
   },
   "outputs": [],
   "source": [
    "dtc_kpca_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_kpca_model.fit(X_train_kpca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda52f5-c68f-40ec-a914-52af07916e48",
   "metadata": {
    "id": "eeda52f5-c68f-40ec-a914-52af07916e48"
   },
   "outputs": [],
   "source": [
    "dtc_kpca_y_hat = dtc_kpca_model.predict(X_test_kpca_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b49e4-b007-40f8-9ad5-3e72d601a7b8",
   "metadata": {
    "id": "fc5b49e4-b007-40f8-9ad5-3e72d601a7b8"
   },
   "outputs": [],
   "source": [
    "dtc_kpca_precision = precision_score(y_test, dtc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_kpca_recall = recall_score(y_test, dtc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_kpca_f1 = f1_score(y_test, dtc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_kpca_accuracy = dtc_kpca_model.score(X_test_kpca_adasyn, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_kpca_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_kpca_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_kpca_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_kpca_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc564b-bb6a-416c-808a-3167ad92d87d",
   "metadata": {
    "id": "04cc564b-bb6a-416c-808a-3167ad92d87d"
   },
   "source": [
    "### Both models did not do well with KPCA, which means I will want to stick with just PCA outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cb9d6-bc71-41ab-ace0-3359ada5f0c7",
   "metadata": {
    "id": "e40cb9d6-bc71-41ab-ace0-3359ada5f0c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad661f2f-fbe0-40a7-a176-340cae0a9581",
   "metadata": {
    "id": "ad661f2f-fbe0-40a7-a176-340cae0a9581"
   },
   "source": [
    "### Could use this code to compare all the models accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a86fe-69ff-44ad-bc15-74a6ddd7b9e6",
   "metadata": {
    "id": "7b4a86fe-69ff-44ad-bc15-74a6ddd7b9e6"
   },
   "outputs": [],
   "source": [
    "# need to update it still\n",
    "accuracies = {\n",
    "    'Logistic Regression': lr_accuracy,\n",
    "    'PCA 1': lr_accuracy_2,\n",
    "    'PCA 2': lr_accuracy_3,\n",
    "    'LDA': lr_accuracy_4,\n",
    "    'KPCA': lr_accuracy_5\n",
    "}\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(list(accuracies.keys()), list(accuracies.values()),\n",
    "         marker='o',\n",
    "         linestyle='-',\n",
    "         linewidth=2,\n",
    "         markersize=8)\n",
    "\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Accuracy Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "for i, v in enumerate(accuracies.values()):\n",
    "    plt.text(i, v, f'{v:.3f}',\n",
    "             ha='center',\n",
    "             va='bottom',\n",
    "             fontsize=10)\n",
    "\n",
    "plt.ylim(0, 1.0)  # Assuming accuracy values are between 0 and 1\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Accuracy'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
