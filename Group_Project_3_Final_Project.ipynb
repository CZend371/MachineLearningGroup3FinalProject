{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b864e043-ea87-4276-88e0-ce0e99530902",
   "metadata": {
    "id": "b864e043-ea87-4276-88e0-ce0e99530902"
   },
   "source": [
    "## Timeline for the project\n",
    "That will also be our next meeting times.\n",
    "* 4/19-20 try to have dimensionality reduction done.\n",
    "* 4/26-27 have the best models tuned and selected for the ensemble classification portion to put it together.\n",
    "* 5/3-4 or earlier we will get together to do the presentation\n",
    "* 5/13-14 or earlier we will get together to do the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9730d92-5cc4-473b-8145-bbd4a015c44a",
   "metadata": {
    "id": "d9730d92-5cc4-473b-8145-bbd4a015c44a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqM3l2sVGHQ5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqM3l2sVGHQ5",
    "outputId": "1d463af3-0f3b-47ed-ea4c-855e063a2324"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"adilshamim8/student-depression-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40653fa5-6c60-4a2d-b063-8aca74ab33c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "40653fa5-6c60-4a2d-b063-8aca74ab33c6",
    "outputId": "066b70de-727d-4109-9759-f54a6e91b608"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/student_depression_dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e26cd0-f395-46db-8414-cec1cdf4ea79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "b8e26cd0-f395-46db-8414-cec1cdf4ea79",
    "outputId": "f4a482b2-db74-49d5-ab63-55a0426206db"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90bec90-a46e-4cbd-b8a2-3b5174e723c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "a90bec90-a46e-4cbd-b8a2-3b5174e723c9",
    "outputId": "436f5c9f-ba0d-4831-9e70-3fa45a828df3"
   },
   "outputs": [],
   "source": [
    "df.value_counts('Depression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31422029-29b7-4f9d-bee2-ac25a7bebdc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31422029-29b7-4f9d-bee2-ac25a7bebdc0",
    "outputId": "c5477c6d-abef-4b36-9c47-1b0d4f0197a1"
   },
   "outputs": [],
   "source": [
    "16336 / 27901 # class balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bed6f-5b54-49d9-bc88-10fc558b31f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "096bed6f-5b54-49d9-bc88-10fc558b31f0",
    "outputId": "1b1dbc98-15f6-470d-fc11-09ee996a1944"
   },
   "outputs": [],
   "source": [
    "11565 / 27901 # class balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc867074-e342-4862-8774-a0fd4c91952d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "bc867074-e342-4862-8774-a0fd4c91952d",
    "outputId": "0aec90c2-4e90-4bb8-ddcd-1a0c84628847"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b736d-a638-4931-a429-fe4b7e854364",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "280b736d-a638-4931-a429-fe4b7e854364",
    "outputId": "76f883f3-b5b6-456b-958b-52c4cd25d83b"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['CGPA']) # Looking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe518b-8dbc-4cc0-99dc-d67ac260104a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "eafe518b-8dbc-4cc0-99dc-d67ac260104a",
    "outputId": "6f595e28-85c4-4ba5-b1d1-de491bad62ac"
   },
   "outputs": [],
   "source": [
    "# drop id, city, profession, work pressure, job satisfaction\n",
    "df = df.drop(['id','City', 'Profession', 'Work Pressure', 'Job Satisfaction'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149eadbb-6061-45e6-905f-6c99687ba445",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "149eadbb-6061-45e6-905f-6c99687ba445",
    "outputId": "4a72f92b-e844-472a-dd3d-44611c7eed95"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Have you ever had suicidal thoughts ?\": \"History of suicidal thoughts?\"})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77b75d-81b0-49b7-bebe-08fa32b93ac3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7b77b75d-81b0-49b7-bebe-08fa32b93ac3",
    "outputId": "8262108c-03f3-4641-e99d-9ea6b6761e68"
   },
   "outputs": [],
   "source": [
    "# May need to prep that data now, take the top 3 answers for sleep duration and the rest can be other,\n",
    "# change degree column to be more general\n",
    "display(df.value_counts(['Sleep Duration'])) # ask about how many categories we wanted to have for this\n",
    "display(df.value_counts(['Degree']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300202f-f32d-4d3c-9eb8-f70759bf09bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "1300202f-f32d-4d3c-9eb8-f70759bf09bf",
    "outputId": "40e3a889-d3ad-43b8-efe1-4d730fab400a"
   },
   "outputs": [],
   "source": [
    "def simplify_degree(degree):\n",
    "    if degree == \"MBBS\":\n",
    "        return \"Bachelor's\"\n",
    "    elif \"PhD\" in degree:\n",
    "        return \"Doctorate\"\n",
    "    elif \"B\" in degree:\n",
    "        return \"Bachelor's\"\n",
    "    elif \"M\" in degree:\n",
    "        return \"Master's\"\n",
    "    elif \"Class\" in degree:\n",
    "        return \"HighSchool/GED\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply the function to the Degree column\n",
    "df['Degree'] = df['Degree'].apply(simplify_degree)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061a75d-c35a-4010-8c0c-d8b4f8ab99ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3061a75d-c35a-4010-8c0c-d8b4f8ab99ec",
    "outputId": "345d292b-34b9-418e-d153-dbc63c9c9d69"
   },
   "outputs": [],
   "source": [
    "## Found three non-numeric values in Financial Stress and need to make ? value an na\n",
    "print(df['Financial Stress'].value_counts())\n",
    "\n",
    "df['Financial Stress'] = np.where(df['Financial Stress'] == '?', np.nan, df['Financial Stress'])\n",
    "\n",
    "df['Financial Stress'] = df['Financial Stress'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195bfdaa-d763-4975-a4c2-073263d851f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "195bfdaa-d763-4975-a4c2-073263d851f2",
    "outputId": "1219856b-1ace-4ddd-9fd1-b2a4c5bd350b"
   },
   "outputs": [],
   "source": [
    "## Summing all of the missing values by column\n",
    "missing_val_cols = df.isnull().sum()\n",
    "\n",
    "print(missing_val_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2040e-8f5f-4c44-ba64-e0a9edfc5901",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "81e2040e-8f5f-4c44-ba64-e0a9edfc5901",
    "outputId": "2f6491c3-39c5-475c-ffc2-163c3d707582"
   },
   "outputs": [],
   "source": [
    "## need to one hot encode the categorical columns\n",
    "X = df.drop(['Depression'], axis=1)\n",
    "y = df['Depression']\n",
    "# display(X)\n",
    "# display(y)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Gender','Sleep Duration', 'Dietary Habits', 'Degree', 'History of suicidal thoughts?', 'Family History of Mental Illness'], drop_first=True)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b0a4e-31e1-45eb-a2e4-d3eaca081bf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "1c4b0a4e-31e1-45eb-a2e4-d3eaca081bf5",
    "outputId": "432de457-e1fa-41f7-ab36-b5626d1ecdc1"
   },
   "outputs": [],
   "source": [
    "## Splitting data into train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2222, stratify=y_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "display(X_train.shape)\n",
    "X_train_percentage = (len(X_train) / len(df)) * 100\n",
    "print(f'X Training set: {X_train_percentage:.2f}%')\n",
    "\n",
    "display(X_test.shape)\n",
    "X_test_percentage = (len(X_test) / len(df)) * 100\n",
    "print(f'X Test set: {X_test_percentage:.2f}%')\n",
    "\n",
    "# display(X_val.shape)\n",
    "# X_validation_percentage = (len(X_val) / len(df)) * 100\n",
    "# print(f'X Validation set: {X_validation_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729c106-5800-4dda-ac60-1660543137aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2729c106-5800-4dda-ac60-1660543137aa",
    "outputId": "5e83b35c-dd37-4363-d780-41ca006dfb56"
   },
   "outputs": [],
   "source": [
    "## Removing missing values from financial stress column\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## Filling in missing numeric variables\n",
    "\n",
    "# Setting imputer as mean\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "\n",
    "# Imputing numeric columns with mean in train data\n",
    "X_train['Financial Stress'] = imputer.fit_transform(X_train[['Financial Stress']])\n",
    "\n",
    "# # Imputing numeric columns with mean in validation data\n",
    "# X_val['Financial Stress'] = imputer.transform(X_val[['Financial Stress']])\n",
    "\n",
    "# Imputing numeric columns with mean in test data\n",
    "X_test['Financial Stress'] = imputer.transform(X_test[['Financial Stress']])\n",
    "\n",
    "\n",
    "## Verifying train, validation, and test sets have no missing values\n",
    "\n",
    "display(X_train.isnull().sum())\n",
    "\n",
    "# display(X_val.isnull().sum())\n",
    "\n",
    "display(X_test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50a02b-33a6-466c-9951-9304c3e15150",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "7b50a02b-33a6-466c-9951-9304c3e15150",
    "outputId": "66e230bb-a5da-46ad-f392-2b0fc393e32f"
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c337880-f317-4190-a9fb-059f2ea3e91b",
   "metadata": {
    "id": "6c337880-f317-4190-a9fb-059f2ea3e91b"
   },
   "outputs": [],
   "source": [
    "## Scaling all numerical data\n",
    "\n",
    "# Importing in scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing in scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scaling training data\n",
    "X_train[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']]= scaler.fit_transform(X_train[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']])\n",
    "\n",
    "\n",
    "# Scaling validation data\n",
    "# X_val[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']] = scaler.transform(X_val[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']])\n",
    "\n",
    "# Scaling testing data\n",
    "X_test[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']] = scaler.transform(X_test[['Age', 'Academic Pressure', 'CGPA', 'Study Satisfaction', 'Work/Study Hours', 'Financial Stress']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2c01c-7e04-414c-8d5f-442f32461ea2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "64c2c01c-7e04-414c-8d5f-442f32461ea2",
    "outputId": "3c9ea531-62d3-4f5d-882d-eb6e6783ebc3"
   },
   "outputs": [],
   "source": [
    "## Verifying data has been scaled\n",
    "\n",
    "display(X_train.head(10))\n",
    "\n",
    "# display(X_val.head(10))\n",
    "\n",
    "display(X_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa05c9-c38f-46c7-814d-5b0976dfc6b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37aa05c9-c38f-46c7-814d-5b0976dfc6b1",
    "outputId": "bbe60862-e1c9-4ec0-fd07-865d478f1cca"
   },
   "outputs": [],
   "source": [
    "#Use ADASYN and Undersampling\n",
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN(random_state = RANDOM_STATE)\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "print(y_resampled_adasyn)\n",
    "print(X_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826dad8-58d1-4560-9982-0aaa41411a0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d826dad8-58d1-4560-9982-0aaa41411a0e",
    "outputId": "215827c3-e8e0-47c9-fe52-8dab884ebf0a"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "random_under_sampler = RandomUnderSampler(random_state = RANDOM_STATE)\n",
    "X_resampled_rus, y_resampled_rus = random_under_sampler.fit_resample(X_train, y_train)\n",
    "print(y_resampled_rus)\n",
    "print(X_resampled_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c541e85b-b88e-4e3c-8cc2-5c8e08448001",
   "metadata": {
    "id": "c541e85b-b88e-4e3c-8cc2-5c8e08448001"
   },
   "source": [
    "## Models we can use: RandomForestClassifier, SVM, LogisticRegression, NaiveBayes, KNN, Decision Tree\n",
    "* We each choose 2 models from the list above.\n",
    "* Perform feature reduction: PCA, LDA, Kernel PCA\n",
    "* Tune hyperparameters: Using the best version of the model we have\n",
    "* After finding the best model from tuning, then perform K-cross validation\n",
    "* Select the best model from each of our selected 2, then we can put it together in a voting classifier for the ensemble portion.\n",
    "## Notes\n",
    "* Use charts and metrics where appropriate such as f1_score, precision, and accuracy.\n",
    "* Don't use the validation sets for the feature/dimensionality reduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c840cd-43b9-4534-833d-5cfd206f1901",
   "metadata": {
    "id": "97c840cd-43b9-4534-833d-5cfd206f1901"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278fad6-0334-4fd0-90e8-1500f48cbd82",
   "metadata": {
    "id": "9278fad6-0334-4fd0-90e8-1500f48cbd82"
   },
   "source": [
    "# David Braun\n",
    "* KNN\n",
    "* SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669628f4-5fb9-4685-be07-536a3c4d63cc",
   "metadata": {
    "id": "669628f4-5fb9-4685-be07-536a3c4d63cc"
   },
   "outputs": [],
   "source": [
    "# ---------- extra imports for modelling ----------\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.decomposition   import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.metrics         import f1_score, classification_report, confusion_matrix, RocCurveDisplay\n",
    "import seaborn as sns, matplotlib.pyplot as plt, pandas as pd, joblib, pathlib\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Eeqg2O0aMxbK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "Eeqg2O0aMxbK",
    "outputId": "3ec0492e-e39d-497e-edd1-e52060e529bb"
   },
   "outputs": [],
   "source": [
    "def quick_score(model, Xb, yb, tag):\n",
    "    model.fit(Xb, yb)\n",
    "    print(f\"{tag}: F1 = {f1_score(y_val, model.predict(X_val)):.3f}\")\n",
    "\n",
    "for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"KNN ADA\"),\n",
    "                     (X_resampled_rus,    y_resampled_rus,    \"KNN RUS\") ]:\n",
    "    quick_score(KNeighborsClassifier(n_neighbors=5, weights='distance'), Xb, yb, tag)\n",
    "\n",
    "for Xb, yb, tag in [ (X_resampled_adasyn, y_resampled_adasyn, \"SVM ADA\"),\n",
    "                     (X_resampled_rus,    y_resampled_rus,    \"SVM RUS\") ]:\n",
    "    quick_score(SVC(kernel='linear', C=1, random_state=42), Xb, yb, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0Wqz4G0uM9C4",
   "metadata": {
    "id": "0Wqz4G0uM9C4"
   },
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('dr',    'passthrough'),          # placeholder\n",
    "    ('clf',   KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('dr',    'passthrough'),\n",
    "    ('clf',   SVC(probability=True, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N9Wo8JhBNDN1",
   "metadata": {
    "id": "N9Wo8JhBNDN1"
   },
   "outputs": [],
   "source": [
    "# ───────────────── 0.  nuke any zombie cluster ──────────────────────────\n",
    "try:\n",
    "    client.close(); cluster.close()\n",
    "except NameError:\n",
    "    pass                   # first run – nothing to clean up\n",
    "\n",
    "# ───────────────── 1.  dask‑timeout & CPU threads ───────────────────────\n",
    "import os, dask\n",
    "dask.config.set({\n",
    "    \"distributed.comm.timeouts.connect\": \"120s\",   # ← was 30 s\n",
    "    \"distributed.comm.timeouts.tcp\":    \"120s\",\n",
    "})\n",
    "os.environ[\"OMP_NUM_THREADS\"] = os.environ[\"MKL_NUM_THREADS\"] = \"18\"\n",
    "\n",
    "# ───────────────── 2.  start a TCP‑only 2‑GPU cluster ───────────────────\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = LocalCUDACluster(\n",
    "    protocol       =\"tcp\",        # skip UCX (fewer moving parts)\n",
    "    interface      =\"lo\",         # loop‑back only\n",
    "    enable_nvlink  =False,\n",
    "    CUDA_VISIBLE_DEVICES=\"0,1\",\n",
    "    threads_per_worker = 6,       # 12 CPU threads total\n",
    "    memory_limit       =\"24GB\",   # host RAM / worker\n",
    "    rmm_pool_size      =\"4GB\"     # pre‑alloc on each GPU\n",
    ")\n",
    "client  = Client(cluster)\n",
    "client.wait_for_workers(2)        # block until both GPUs are ready\n",
    "print(\"Dask dashboard:\", client.dashboard_link)\n",
    "\n",
    "# ───────────────── 3.  cuML‑UMAP wrapper (same as before) ───────────────\n",
    "import cupy as cp\n",
    "from cuml.manifold import UMAP as GPUUMAP\n",
    "from sklearn.base  import BaseEstimator, TransformerMixin\n",
    "class CumlUMAP(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=10, n_neighbors=30, random_state=42):\n",
    "        self.n_components, self.n_neighbors, self.random_state = (\n",
    "            n_components, n_neighbors, random_state)\n",
    "    def get_params(self, deep=True): return vars(self).copy()\n",
    "    def set_params(self, **p):\n",
    "        for k,v in p.items(): setattr(self,k,v); return self\n",
    "    def fit(self, X, y=None):\n",
    "        self._umap = GPUUMAP(**self.get_params()).fit(cp.asarray(X))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return self._umap.transform(cp.asarray(X)).get()\n",
    "\n",
    "# ───────────────── 4.  pipelines + param grids  ─────────────────────────\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.svm             import SVC\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from dask_ml.model_selection import GridSearchCV    # ← dask‑ml version\n",
    "\n",
    "base_pre = [('impute', SimpleImputer(strategy='median')),\n",
    "            ('scale',  StandardScaler())]\n",
    "\n",
    "knn_pipe = Pipeline(base_pre + [('dr','passthrough'),\n",
    "                                ('clf',KNeighborsClassifier())])\n",
    "\n",
    "svm_pipe = Pipeline(base_pre + [('dr','passthrough'),\n",
    "                                ('clf',SVC())])\n",
    "\n",
    "knn_param = {\n",
    "    'dr': [None,\n",
    "           PCA(n_components=10, random_state=42),\n",
    "           LDA(n_components=1),\n",
    "           CumlUMAP(n_components=10, n_neighbors=30, random_state=42)],\n",
    "    'clf__n_neighbors':[3,5,7,11],\n",
    "    'clf__weights':    ['uniform','distance'],\n",
    "    'clf__metric':     ['euclidean','manhattan']\n",
    "}\n",
    "svm_param = {\n",
    "    'dr': [None,\n",
    "           PCA(n_components=15, random_state=42),\n",
    "           CumlUMAP(n_components=15, n_neighbors=30, random_state=42)],\n",
    "    'clf__kernel':['linear','rbf'],\n",
    "    'clf__C':     [0.1,1,10],\n",
    "    'clf__gamma': ['scale','auto']\n",
    "}\n",
    "\n",
    "knn_gs = GridSearchCV(knn_pipe, knn_param, scoring='f1', cv=10,\n",
    "                      n_jobs=-1, error_score='raise')\n",
    "svm_gs = GridSearchCV(svm_pipe, svm_param, scoring='f1', cv=10,\n",
    "                      n_jobs=-1, error_score='raise')\n",
    "\n",
    "# ───────────────── 5.  run the grid searches  ───────────────────────────\n",
    "print(\"▶ fitting k‑NN grid …\"); knn_gs.fit(Xb, yb)\n",
    "print(\"▶ fitting SVM grid …\");  svm_gs.fit(Xb, yb)\n",
    "\n",
    "print(\"✓ finished\")\n",
    "print(\"best k‑NN:\", knn_gs.best_params_, \"  F1 =\", knn_gs.best_score_)\n",
    "print(\"best SVM:\", svm_gs.best_params_, \"  F1 =\", svm_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0JQ22YNgNE-w",
   "metadata": {
    "id": "0JQ22YNgNE-w"
   },
   "outputs": [],
   "source": [
    "best_knn = knn_gs.best_estimator_\n",
    "best_svm = svm_gs.best_estimator_\n",
    "\n",
    "print(\"KNN best params:\", knn_gs.best_params_)\n",
    "print(\"SVM best params:\", svm_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GNo1BuYxNKHB",
   "metadata": {
    "id": "GNo1BuYxNKHB"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                             RocCurveDisplay)\n",
    "\n",
    "def eval_model(mdl, label):\n",
    "    # CUPY → NUMPY if necessary\n",
    "    y_pred = mdl.predict(X_val)\n",
    "    if hasattr(y_pred, \"get\"):                      # cupy.ndarray\n",
    "        y_pred = y_pred.get()\n",
    "\n",
    "    print(f\"\\n{label}\\n\", classification_report(y_val, y_pred, digits=3))\n",
    "\n",
    "    sns.heatmap(confusion_matrix(y_val, y_pred),\n",
    "                annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{label} – Confusion'); plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_estimator(mdl, X_val, y_val)\n",
    "    plt.title(f'{label} – ROC'); plt.show()\n",
    "\n",
    "eval_model(best_knn, \"Best KNN\")\n",
    "eval_model(best_svm, \"Best SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fnh3HrecNOJE",
   "metadata": {
    "id": "Fnh3HrecNOJE"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "full_X = pd.concat([X_train, X_val])\n",
    "full_y = pd.concat([y_train, y_val])\n",
    "\n",
    "for mdl, name in [(best_knn, 'KNN'), (best_svm, 'SVM')]:\n",
    "    scores = cross_val_score(mdl, full_X, full_y,\n",
    "                             cv=cv, scoring='f1')      # n_jobs = 1\n",
    "    print(f\"{name} 10‑fold F1: {scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cm114iGoNQB8",
   "metadata": {
    "id": "cm114iGoNQB8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for mdl, name in [(best_knn, 'KNN'), (best_svm, 'SVM')]:\n",
    "    y_hat = mdl.predict(X_test)\n",
    "    if hasattr(y_hat, \"get\"):\n",
    "        y_hat = y_hat.get()\n",
    "    print(name, \"TEST F1 =\", f1_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4FRMQzBnNRm3",
   "metadata": {
    "id": "4FRMQzBnNRm3"
   },
   "outputs": [],
   "source": [
    "import pathlib, joblib\n",
    "pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "# detach cupy arrays so joblib can pickle (safe‑guard)\n",
    "for pipe in (best_knn, best_svm):\n",
    "    if hasattr(pipe, \"steps\"):\n",
    "        for name, step in pipe.steps:\n",
    "            if hasattr(step, \"release_cache\"):    # many cuML objects\n",
    "                step.release_cache()\n",
    "\n",
    "joblib.dump(best_knn, \"models/best_knn.pkl\")\n",
    "joblib.dump(best_svm, \"models/best_svm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06hUtGgyNSav",
   "metadata": {
    "id": "06hUtGgyNSav"
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame(knn_gs.cv_results_)\n",
    "   .groupby('param_clf__n_neighbors')['mean_test_score']\n",
    "   .mean()\n",
    "   .plot(marker='o'))\n",
    "plt.ylabel('Mean CV F1'); plt.xlabel('k'); plt.title('KNN: k vs F1'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11751c2f-e5a6-4b7d-9a14-56cec8f9ec6c",
   "metadata": {
    "id": "11751c2f-e5a6-4b7d-9a14-56cec8f9ec6c"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8113c0e-cfef-46b5-9b5b-0adda88de6f0",
   "metadata": {
    "id": "f8113c0e-cfef-46b5-9b5b-0adda88de6f0"
   },
   "source": [
    "# Karryn Leake\n",
    "* Logistic Regression\n",
    "* NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fad486-95f4-4495-9768-5be31c4fe373",
   "metadata": {
    "id": "02fad486-95f4-4495-9768-5be31c4fe373"
   },
   "outputs": [],
   "source": [
    "## Importing in needed packages for dimensionality reduction\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dDtCp1GuNtfJ",
   "metadata": {
    "id": "dDtCp1GuNtfJ"
   },
   "outputs": [],
   "source": [
    "### Creating base log model code\n",
    "\n",
    "def train_log_model(X_train_values, y_train_values, X_test_values, y_test_values):\n",
    "    # Setting up logistic regression model\n",
    "    log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "    # Training model\n",
    "    log_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "    ## Displaying model accuracy\n",
    "\n",
    "    log_y_hat = log_model.predict(X_test_values)\n",
    "\n",
    "    # Getting classification report\n",
    "    report = classification_report(y_test_values, log_y_hat)\n",
    "\n",
    "    # Getting accuracy specifically\n",
    "    accuracy = accuracy_score(y_test_values, log_y_hat)\n",
    "\n",
    "    print(f\"Our current model accuracy is {accuracy:.2f}.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"A more detailed report of the model's overall accuracy is:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IiAIu1ArNtoS",
   "metadata": {
    "id": "IiAIu1ArNtoS"
   },
   "outputs": [],
   "source": [
    "### Creating base naive bayes code\n",
    "\n",
    "def train_nb_model(X_train_values, y_train_values, X_test_values, y_test_values):\n",
    "    nb_model = GaussianNB()\n",
    "    nb_model.fit(X_train_values, y_train_values)\n",
    "\n",
    "    # Predicting y_hat\n",
    "    nb_y_hat = nb_model.predict(X_test_values)\n",
    "\n",
    "    # Getting classification report\n",
    "    report = classification_report(y_test_values, nb_y_hat)\n",
    "\n",
    "    # Getting accuracy specifically\n",
    "    accuracy = accuracy_score(y_test_values, nb_y_hat)\n",
    "\n",
    "    print(f\"Our current model accuracy is {accuracy:.2f}.\")\n",
    "    print(\"\\n\")\n",
    "    print(\"A more detailed report of the model's overall accuracy is:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AU4h8ATUN_o3",
   "metadata": {
    "id": "AU4h8ATUN_o3"
   },
   "source": [
    "### Initial log model on oversampled and undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OPcaBwV3OFGs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPcaBwV3OFGs",
    "outputId": "b8cad04b-f986-446c-814e-bd5a20fdbd1f"
   },
   "outputs": [],
   "source": [
    "## Training log model using oversampled data\n",
    "train_log_model(X_resampled_adasyn, y_resampled_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Va3bPRsOWAF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Va3bPRsOWAF",
    "outputId": "104ac00d-b20d-4390-ed42-3a23c7400d33"
   },
   "outputs": [],
   "source": [
    "## Training log model on undersampled data\n",
    "train_log_model(X_resampled_rus, y_resampled_rus, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aCeXaAZROjkm",
   "metadata": {
    "id": "aCeXaAZROjkm"
   },
   "source": [
    "### Initial nb model on oversampled and undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vCpOWMxMOlSb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCpOWMxMOlSb",
    "outputId": "be0e1d1c-6310-4b2d-c8a0-d88b11654b0f"
   },
   "outputs": [],
   "source": [
    "## Training nb model on oversampled data\n",
    "train_nb_model(X_resampled_adasyn, y_resampled_adasyn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wv59U-YfOlXd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wv59U-YfOlXd",
    "outputId": "e48a4e2f-6f7d-495e-e5ce-2e130f35c1e0"
   },
   "outputs": [],
   "source": [
    "## Training nb model on undersampled data\n",
    "train_nb_model(X_resampled_rus, y_resampled_rus, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EsMrMhEjOwUb",
   "metadata": {
    "id": "EsMrMhEjOwUb"
   },
   "source": [
    "## Experimenting with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sinm0zdNO1Pj",
   "metadata": {
    "id": "sinm0zdNO1Pj"
   },
   "source": [
    "### Completing LDA on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24Dn5PZrOyOT",
   "metadata": {
    "id": "24Dn5PZrOyOT"
   },
   "outputs": [],
   "source": [
    "## Completing LDA on over sampled data\n",
    "\n",
    "# Getting LDA with n_components = 1 as n_components = number of classes - 1\n",
    "lda = LinearDiscriminantAnalysis(n_components = 1)\n",
    "\n",
    "# Performing LDA on train and test data\n",
    "X_train_lda = lda.fit_transform(X_resampled_adasyn, y_resampled_adasyn)\n",
    "X_test_lda = lda.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qO3ZH2_LPLd7",
   "metadata": {
    "id": "qO3ZH2_LPLd7"
   },
   "source": [
    "### Training log and naive bayes models on oversampled data with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MIpIpcLLOx94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIpIpcLLOx94",
    "outputId": "5b685355-afb4-44a8-8ddb-ca421991916b"
   },
   "outputs": [],
   "source": [
    "train_log_model(X_train_lda, y_resampled_adasyn, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hRbV0iVvOx0x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRbV0iVvOx0x",
    "outputId": "6d76eacd-31c8-4f0a-81c3-2e64cf02c2a0"
   },
   "outputs": [],
   "source": [
    "train_nb_model(X_train_lda, y_resampled_adasyn, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YlZsyelRPgrJ",
   "metadata": {
    "id": "YlZsyelRPgrJ"
   },
   "source": [
    "## Experimenting with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DRNPJH44PgeY",
   "metadata": {
    "id": "DRNPJH44PgeY"
   },
   "source": [
    "### Setting up PCA on oversampled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZVeuGvYqPgIA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVeuGvYqPgIA",
    "outputId": "189762a1-9b3f-462c-86c0-5012590a8d00"
   },
   "outputs": [],
   "source": [
    "## Choosing 1 as number of components and testing variance\n",
    "pca = PCA(n_components = 1)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TZfUr4rsPrmn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZfUr4rsPrmn",
    "outputId": "78c51e8d-646a-4d9b-9fc3-c29db167f0a6"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heCwE6EsPrdw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "heCwE6EsPrdw",
    "outputId": "2c9f8b85-3ed3-4865-8bf6-20a6653b00a5"
   },
   "outputs": [],
   "source": [
    "## Testing on naive bayes model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5M-7sIN5P3NT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5M-7sIN5P3NT",
    "outputId": "19bd1994-bd3f-4de1-83ca-97fb4a5a9b58"
   },
   "outputs": [],
   "source": [
    "## Choosing 2 as number of components and testing variance\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SIWPt-ieP3Le",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIWPt-ieP3Le",
    "outputId": "d44de017-0205-4e2b-8997-e91a0b2e839d"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NuMe03jbP3I4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuMe03jbP3I4",
    "outputId": "9314042e-2602-4a61-c004-db33332ceae5"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3y3cmagP3BD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3y3cmagP3BD",
    "outputId": "2a1f8d24-5b75-42b0-cd9f-882874d117a9"
   },
   "outputs": [],
   "source": [
    "## Choosing 3 as number of components and testing variance\n",
    "pca = PCA(n_components = 3)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VOI2QIJBP2_O",
   "metadata": {
    "id": "VOI2QIJBP2_O"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_D-JO6wsP285",
   "metadata": {
    "id": "_D-JO6wsP285"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nAAZLpP3P26i",
   "metadata": {
    "id": "nAAZLpP3P26i"
   },
   "outputs": [],
   "source": [
    "## Choosing 4 as number of components and testing variance\n",
    "pca = PCA(n_components = 4)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vwf6_OxPP24e",
   "metadata": {
    "id": "Vwf6_OxPP24e"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8xCCag48P22J",
   "metadata": {
    "id": "8xCCag48P22J"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UyE8kuOAP2vH",
   "metadata": {
    "id": "UyE8kuOAP2vH"
   },
   "outputs": [],
   "source": [
    "## Choosing 5 as number of components and testing variance\n",
    "pca = PCA(n_components = 5)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tJGyCw2PQWof",
   "metadata": {
    "id": "tJGyCw2PQWof"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dhe_N6g4QWjB",
   "metadata": {
    "id": "dhe_N6g4QWjB"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JBYAYJbcQWgL",
   "metadata": {
    "id": "JBYAYJbcQWgL"
   },
   "outputs": [],
   "source": [
    "# Choosing 6 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 6)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s8l_C9B8QWYo",
   "metadata": {
    "id": "s8l_C9B8QWYo"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KWlEK_OiQwK2",
   "metadata": {
    "id": "KWlEK_OiQwK2"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bngzCiU3QwIf",
   "metadata": {
    "id": "bngzCiU3QwIf"
   },
   "outputs": [],
   "source": [
    "# Choosing 7 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 7)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soN4XhBSQwGb",
   "metadata": {
    "id": "soN4XhBSQwGb"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_42LTqyVQwD1",
   "metadata": {
    "id": "_42LTqyVQwD1"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u0YonTwyQv8D",
   "metadata": {
    "id": "u0YonTwyQv8D"
   },
   "outputs": [],
   "source": [
    "# Choosing 8 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nT4Jx-PlQ9ah",
   "metadata": {
    "id": "nT4Jx-PlQ9ah"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YH_ZBIJ-Q9kN",
   "metadata": {
    "id": "YH_ZBIJ-Q9kN"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pLXiEMT1Q9oV",
   "metadata": {
    "id": "pLXiEMT1Q9oV"
   },
   "outputs": [],
   "source": [
    "# Choosing 9 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 9)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CrRvKy6ZQ9q5",
   "metadata": {
    "id": "CrRvKy6ZQ9q5"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wG8Z3AM1Q9tg",
   "metadata": {
    "id": "wG8Z3AM1Q9tg"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ksYproEXQ9v2",
   "metadata": {
    "id": "ksYproEXQ9v2"
   },
   "outputs": [],
   "source": [
    "# Choosing 10 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8foDIi7BQ9x8",
   "metadata": {
    "id": "8foDIi7BQ9x8"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L6JfNi6ERNKV",
   "metadata": {
    "id": "L6JfNi6ERNKV"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R6ys-skeRQdg",
   "metadata": {
    "id": "R6ys-skeRQdg"
   },
   "outputs": [],
   "source": [
    "# Choosing 11 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 11)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IhZq2HQbRQaK",
   "metadata": {
    "id": "IhZq2HQbRQaK"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y7mrPI53RQVL",
   "metadata": {
    "id": "Y7mrPI53RQVL"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ivlg6wXaRQS0",
   "metadata": {
    "id": "Ivlg6wXaRQS0"
   },
   "outputs": [],
   "source": [
    "# Choosing 12 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 12)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50j4LbbiRQP8",
   "metadata": {
    "id": "50j4LbbiRQP8"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fxas4-ebRQN4",
   "metadata": {
    "id": "fxas4-ebRQN4"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wSnkbNvzRQLR",
   "metadata": {
    "id": "wSnkbNvzRQLR"
   },
   "outputs": [],
   "source": [
    "# Choosing 13 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 13)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EIRAwZd_RQFk",
   "metadata": {
    "id": "EIRAwZd_RQFk"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ii8YX46VRQIq",
   "metadata": {
    "id": "Ii8YX46VRQIq"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_pca, y_resampled_adasyn, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y016yAJbRqQz",
   "metadata": {
    "id": "Y016yAJbRqQz"
   },
   "source": [
    "## Experimenting with Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dAhxGUBKRzq7",
   "metadata": {
    "id": "dAhxGUBKRzq7"
   },
   "source": [
    "### Testing Kernel PCA on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ewws7puYR6zo",
   "metadata": {
    "id": "ewws7puYR6zo"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 1, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3sKJmJleR6xT",
   "metadata": {
    "id": "3sKJmJleR6xT"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oQW8oa52R6u-",
   "metadata": {
    "id": "oQW8oa52R6u-"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lRv36l7IR6s4",
   "metadata": {
    "id": "lRv36l7IR6s4"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q89jfsN0R6qz",
   "metadata": {
    "id": "q89jfsN0R6qz"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TmvxWw9gR6ky",
   "metadata": {
    "id": "TmvxWw9gR6ky"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "URkQeDhaR6iu",
   "metadata": {
    "id": "URkQeDhaR6iu"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 3, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4lVnv4GGR6go",
   "metadata": {
    "id": "4lVnv4GGR6go"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ml73RlphR6ej",
   "metadata": {
    "id": "Ml73RlphR6ej"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LI3RgEzDR6cO",
   "metadata": {
    "id": "LI3RgEzDR6cO"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 4, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmTaybubR6aH",
   "metadata": {
    "id": "zmTaybubR6aH"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KlG3ZTSjSQbg",
   "metadata": {
    "id": "KlG3ZTSjSQbg"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eJJIR0CuR6Xj",
   "metadata": {
    "id": "eJJIR0CuR6Xj"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 5, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5MH6wx13SZEF",
   "metadata": {
    "id": "5MH6wx13SZEF"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lqpKkPDsSZB_",
   "metadata": {
    "id": "lqpKkPDsSZB_"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rfOi3nsVSY_7",
   "metadata": {
    "id": "rfOi3nsVSY_7"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 6, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fg6u0pJOSY91",
   "metadata": {
    "id": "Fg6u0pJOSY91"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jzD3NNbFSY7v",
   "metadata": {
    "id": "jzD3NNbFSY7v"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WDZ3oxofSY5a",
   "metadata": {
    "id": "WDZ3oxofSY5a"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 7, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rJA5uxygSY3E",
   "metadata": {
    "id": "rJA5uxygSY3E"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wQdoWoI2SY0t",
   "metadata": {
    "id": "wQdoWoI2SY0t"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oFGw162oSYyY",
   "metadata": {
    "id": "oFGw162oSYyY"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 8, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BaMObfBKSYwD",
   "metadata": {
    "id": "BaMObfBKSYwD"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ch2pYSoRC",
   "metadata": {
    "id": "e83ch2pYSoRC"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MQfqadq1Sobx",
   "metadata": {
    "id": "MQfqadq1Sobx"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 9, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqxevkVYSoej",
   "metadata": {
    "id": "gqxevkVYSoej"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "osam7_w_Ss3k",
   "metadata": {
    "id": "osam7_w_Ss3k"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pVNXOKC8SuPr",
   "metadata": {
    "id": "pVNXOKC8SuPr"
   },
   "outputs": [],
   "source": [
    "## Setting up Kernel PCA on train and test data\n",
    "\n",
    "# Getting kernel PCA started\n",
    "kernel_pca = KernelPCA(n_components = 10, kernel = 'rbf')\n",
    "\n",
    "# Performing kernel PCA on train and test data\n",
    "X_train_kernel = kernel_pca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kernel = kernel_pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O-cMl1piSuW3",
   "metadata": {
    "id": "O-cMl1piSuW3"
   },
   "outputs": [],
   "source": [
    "## Testing on log model\n",
    "train_log_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52257cd8-ef05-47b9-aa0e-d59e957a1d80",
   "metadata": {
    "id": "LesYXd0LSucW"
   },
   "outputs": [],
   "source": [
    "## Testing on nb model\n",
    "train_nb_model(X_train_kernel, y_resampled_adasyn, X_test_kernel, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c12e0-2178-4361-8bf4-ea48c4f2e651",
   "metadata": {},
   "source": [
    "### Plotting LDA with Class Distinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614b859-0826-41d3-bc7c-7078d4682358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting plot of LDA 1 and classifier value for train data\n",
    "\n",
    "# Getting columns named properly \n",
    "feature_1 = X_train_lda[:1000, 0]\n",
    "y = np.array(y_resampled_adasyn[:1000])\n",
    "second_y = np.zeros(1000)\n",
    "\n",
    "class_colors = {0: 'red', 1: 'blue'}\n",
    "\n",
    "# Plotting data with class-based colors\n",
    "for i in range(len(feature_1)):\n",
    "    plt.scatter(feature_1[i], second_y[i], color=class_colors[y[i]])\n",
    "\n",
    "# Creating legend elements\n",
    "legend_elements = [mpatches.Patch(color=color, label=cls) for cls, color in class_colors.items()]\n",
    "\n",
    "# Adding labels, legends and making graph nice\n",
    "plt.xlabel(\"LDA 1\")\n",
    "\n",
    "plt.title(\"LDA 1 with Class Distinction\")\n",
    "\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "# Showing plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e4ec9-e9c2-4893-9894-c1f1cb5cf5e1",
   "metadata": {},
   "source": [
    "## Model Selection: Hyperparameter Tuning and Cross Validation\n",
    "\n",
    "Based on the above dimensionality results, we will be using LDA, PCA with 10 components, and PCA with 13 components to train/tune our model. This is because LDA produced the highest metrics for both naive bayes and logistic regression with the greatest amount of dimensionality reduction. Additionally, PCA with 13 components also produced relatively similar metrics, while reducing the dataset to 13 columns that account for over `95%` of the overall data. PCA with 10 components will be used to see if after tunning, the results are similar to our other two dimensionality reduction methods and is a fun experiment to see if we can reduce half the number of columns. Finally based on the results of kernel PCA, we will not be using kernel PCA as a dimensionality reducer, as it provided similar/worse results in terms of model metrics for both naive bayes and logistic regression and was more computationaly expensive to reduce the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a73c2-7bca-4459-9d95-8c9a4a3cbab3",
   "metadata": {},
   "source": [
    "### Experimenting with GridSearchCV for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c556a60-becf-4eb8-987a-03c7613e7b4d",
   "metadata": {},
   "source": [
    "#### Setting up Logistic Regression model using GridsSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69692023-554e-4bdd-a0d9-886b9ba49f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up GridSearch for logistic regresion on all solvers\n",
    "\n",
    "# Importing in GridSearch and time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n",
    "    'penalty': ['l2'], # Can only do l2 for all models because some models do not take other penalties\n",
    "    'C': [0.001, 0.0001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52b02d-35ce-4e1a-b5aa-21f5475bd7cb",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on un-reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ca0fc-035b-4db5-9010-0ebaa547d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a1e72-5abe-4720-88c4-1ee609144ebe",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49715915-6501-48a7-b922-7ebac6f2c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c113f3c-458f-4543-92ab-440627225437",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on PCA data with n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7221a81-e563-47da-a9b5-171fd81f2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 13 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 13)\n",
    "\n",
    "X_train_pca_13 = pca.fit_transform(X_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49602897-51d5-4f81-b001-e2663d6199c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fed116-795e-4015-83d7-06ffb3c79cf0",
   "metadata": {},
   "source": [
    "##### Fitting first Logistic Regression GridSearch on PCA data with n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d51cb-9bc8-4a48-a5e4-3e2967eac473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 10 as a random number of components\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "X_train_pca_10 = pca.fit_transform(X_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c79e8-5bbc-4409-8ac1-383638c7fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736e23e-9b31-48f1-8f92-d7f360e5aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing grid parameters to exclude liblinear and add None as penalty option\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n",
    "    'penalty': ['l2', None], \n",
    "    'C': [0.001, 0.0001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4285f98-5c21-44e0-a74f-4a351a246d25",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73991b51-f54e-4506-b484-217d2740e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69463bf6-f017-4384-9635-5ef470bad50f",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f88c40-f528-41ad-8d7e-8fe9b49d3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d6435-d187-478a-90d2-a0915ca3495a",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on PCA n = 13 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21952e-f95b-4eec-ae4b-6586e359cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39952f67-abca-411b-9cf0-81cc5b46a649",
   "metadata": {},
   "source": [
    "##### Completing second GridSearch on PCA n = 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff3a2e-d002-42c3-9c6a-3678e2c8fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4a8e9-0edd-4c73-baf6-df64bafa4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying all possible combinations with saga solver that have not been explored\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['saga'], \n",
    "    'penalty': ['l1','elasticnet'], \n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    'l1_ratio': [0, 0.5, 1], \n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77241ec3-8379-44a2-8a1e-7b79380bb51a",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df268bf4-8481-46e5-8c8a-67136b357ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eeb97e-297d-48c8-afd1-0fd0ce9049e3",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c66237-29a8-4158-8664-8b9931a88709",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5c185-655c-4504-8c33-3be95bd7fbef",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on PCA n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b62551-968f-4e80-b89b-b79391584a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0e8eb-8af6-4ea5-a691-c026277d75a2",
   "metadata": {},
   "source": [
    "##### Completing third GridSearch on PCA n = 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77489724-c775-482d-b28e-77f2d851076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d749c-a718-49fc-b821-ba7411ac80b8",
   "metadata": {},
   "source": [
    "#### Testing all versions of liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0c64f-49e0-463c-9283-89e678047f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying all possible combinations with saga solver that have not been explored\n",
    "log_model = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'solver': ['liblinear'], \n",
    "    'penalty': ['l1','l2'], \n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = log_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16314f-636c-469f-8124-f4d590140ea4",
   "metadata": {},
   "source": [
    "##### Completing GridSearch on unreduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205e508-ec82-402e-bc4a-982af74d168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86359cd-b260-4df6-bd7d-5be12019a097",
   "metadata": {},
   "source": [
    "##### Completing GridSearch for LDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc8a7f-0dee-47ca-ac6a-391e7ddf8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c4c0f-11d2-4a66-8446-289ede68f450",
   "metadata": {},
   "source": [
    "##### Completing GridSearch for PCA dataset with n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bdea9-c49b-4ddf-b661-daca0acb1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675211f-043e-4dab-a5d1-2f960ee9b828",
   "metadata": {},
   "source": [
    "##### Completing GridSearch for PCA dataset with n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bcc6c-0182-473e-b8c8-d8708d18db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59666b-651e-48bf-90ea-3ce2492543c9",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning/Cross Validation with Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e4d62-9a6b-464a-ac89-9797ce4bf6ca",
   "metadata": {},
   "source": [
    "#### Creating GridSearch for Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b397774-2d0e-4583-8748-bdb109d3a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying all possible combinations with saga solver that have not been explored\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Setting up hyperparameters\n",
    "grid_param = {\n",
    "    'var_smoothing': [1e-11, 1e-10, 1e-9],\n",
    "    'priors': [[0.9, 0.1], [0.8, 0.2], [0.7, 0.3], [0.6, 0.4], None]\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator = nb_model, \n",
    "                           param_grid = grid_param, \n",
    "                           scoring = 'accuracy', \n",
    "                           cv = 5, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa0559-cada-443a-8496-92201566a8c8",
   "metadata": {},
   "source": [
    "##### Testing on unreduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11023a-0787-4e2f-8bbb-0404bb3a8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5f3d0-0297-4755-893e-c638e548d363",
   "metadata": {},
   "source": [
    "##### Testing on LDA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d845ba8-8b0f-4115-b884-877818ae2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grid_search.fit(X_train_lda, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc82e9-5bf2-401a-aea7-1c1aff6ee3f1",
   "metadata": {},
   "source": [
    "##### Testing on PCA data where n = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ac81-ce20-48bf-9a40-f36b1372d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grid_search.fit(X_train_pca_13, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77fc53-a30c-4c81-9c22-d1d714473685",
   "metadata": {},
   "source": [
    "##### Testing on PCA data where n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f87ba-8c35-413c-8323-ecf96662174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_grid_search.fit(X_train_pca_10, y_resampled_adasyn)\n",
    "\n",
    "elapsed_time = time.time() - start_time \n",
    "print(f\"The total elapsed time is: {elapsed_time}\")\n",
    "\n",
    "best_score = nb_grid_search.best_score_\n",
    "best_params = nb_grid_search.best_params_\n",
    "\n",
    "print(best_score)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b9939-faf1-48a4-9507-46e8bf9b9d5b",
   "metadata": {
    "id": "423b9939-faf1-48a4-9507-46e8bf9b9d5b"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df72ff-d842-4556-94bf-54c322cfc05d",
   "metadata": {
    "id": "59df72ff-d842-4556-94bf-54c322cfc05d"
   },
   "source": [
    "# Cristian Zendejas\n",
    "* RandomForestClassifier\n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217afe96-9a5c-4e14-ada5-2b0ce17a9c1b",
   "metadata": {
    "id": "217afe96-9a5c-4e14-ada5-2b0ce17a9c1b"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547541b-b758-4c5b-a843-9858e68fe96b",
   "metadata": {
    "id": "b547541b-b758-4c5b-a843-9858e68fe96b"
   },
   "source": [
    "### Performing PCA here with the 2 different resampled datasets. Both will also be used to train separate models for RandomForestClassifier & Decision Tree. The experiement for this section will be to see which form of analysis PCA, LDA, or Kernel PCA will produce the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f921d-58a2-4078-b9d7-52e95755d4be",
   "metadata": {
    "id": "1a0f921d-58a2-4078-b9d7-52e95755d4be"
   },
   "outputs": [],
   "source": [
    "# look into a chart to display the current data we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b181db-5ada-460a-bd3c-77cf8a0cc9bf",
   "metadata": {
    "id": "03b181db-5ada-460a-bd3c-77cf8a0cc9bf"
   },
   "outputs": [],
   "source": [
    "# keep an eye on the accuracy for the base models and after the dimensionality reduction, Karryn said her accuracy did not change much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751960a-da24-45ce-931c-d468374c11f1",
   "metadata": {
    "id": "2751960a-da24-45ce-931c-d468374c11f1"
   },
   "outputs": [],
   "source": [
    "# did we decide to drop random under sampler since it didn't provide much value when using it in the models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbeb620-fc2c-43e4-a51b-bb7fc6b23d94",
   "metadata": {
    "id": "dcbeb620-fc2c-43e4-a51b-bb7fc6b23d94"
   },
   "source": [
    "## Establishing some base models to compare later models too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23060a-68de-481e-978d-d03649fd938b",
   "metadata": {
    "id": "3f23060a-68de-481e-978d-d03649fd938b"
   },
   "outputs": [],
   "source": [
    "rfc_base_model = RandomForestClassifier(criterion='entropy')\n",
    "rfc_base_model.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "rfc_base_y_hat = rfc_base_model.predict(X_test)\n",
    "print(rfc_base_y_hat)\n",
    "\n",
    "rfc_base_precision = precision_score(y_test, rfc_base_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_base_recall = recall_score(y_test, rfc_base_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_base_f1 = f1_score(y_test, rfc_base_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_base_accuracy = rfc_base_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_base_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_base_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_base_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_base_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8685c-a3a2-4c83-a0d6-d6915bc35b5d",
   "metadata": {
    "id": "41d8685c-a3a2-4c83-a0d6-d6915bc35b5d"
   },
   "outputs": [],
   "source": [
    "dtc_base_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_base_model.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "dtc_base_y_hat = dtc_base_model.predict(X_test)\n",
    "\n",
    "dtc_base_precision = precision_score(y_test, dtc_base_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_base_recall = recall_score(y_test, dtc_base_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_base_f1 = f1_score(y_test, dtc_base_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_base_accuracy = dtc_base_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_base_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_base_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_base_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_base_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbaeb9-f820-41d0-b4aa-b128998136cd",
   "metadata": {
    "id": "f4cbaeb9-f820-41d0-b4aa-b128998136cd"
   },
   "source": [
    "### I'm expecting the RandomForestClassifier to do better than DecisionTreeClassifier since it is just an improved version of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5959665-a190-425a-bbc4-7b54a2078b54",
   "metadata": {
    "id": "b5959665-a190-425a-bbc4-7b54a2078b54"
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8544ca-9bfc-4ff3-8a1e-859a3e262abe",
   "metadata": {
    "id": "3a8544ca-9bfc-4ff3-8a1e-859a3e262abe"
   },
   "outputs": [],
   "source": [
    "def find_best_explained_variance(model_class, X_train, y_train):\n",
    "    print(model_class)\n",
    "    best_explained_variance = -np.inf # using negative infinity to ensure the variable is updated.\n",
    "    best_n_components = None\n",
    "    n_range = np.arange(1,15)\n",
    "\n",
    "    for n in n_range:\n",
    "        if model_class == PCA:\n",
    "            model = PCA(n_components=n)\n",
    "        elif model_class == LinearDiscriminantAnalysis: # do I event want to find the best components for this?\n",
    "            n_classes = len(np.unique(y_train))\n",
    "            max_components = min(X_train.shape[1], n_classes - 1)\n",
    "            if n > max_components:\n",
    "                continue\n",
    "            model = LinearDiscriminantAnalysis(n_components=n)\n",
    "        elif model_class == KernelPCA:\n",
    "            model = KernelPCA(n_components=n, kernel='rbf')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model class\")\n",
    "\n",
    "        if model_class == PCA or model_class == KernelPCA:\n",
    "            X_train_transformed = model.fit_transform(X_train)\n",
    "        else:\n",
    "            X_train_transformed = model.fit_transform(X_train, y_train)\n",
    "\n",
    "        if model_class == PCA or model_class == LinearDiscriminantAnalysis:\n",
    "            explained_variance = np.sum(model.explained_variance_ratio_)\n",
    "            # print(explained_variance)\n",
    "        elif model_class == KernelPCA:\n",
    "            explained_variance = np.sum(np.var(X_train_transformed, axis=0)) / np.sum(np.var(X_train, axis=0))\n",
    "\n",
    "        if explained_variance > best_explained_variance:\n",
    "            best_explained_variance = explained_variance\n",
    "            best_n_components = n\n",
    "\n",
    "    return best_explained_variance, best_n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6e2dd-bdcc-4d6a-9805-41e569c4d747",
   "metadata": {
    "id": "41e6e2dd-bdcc-4d6a-9805-41e569c4d747"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(PCA, X_resampled_adasyn, y_resampled_adasyn)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f0dcc-8a6d-4a77-a1c1-dd4231c36c09",
   "metadata": {
    "id": "473f0dcc-8a6d-4a77-a1c1-dd4231c36c09"
   },
   "outputs": [],
   "source": [
    "pca_1 = PCA(n_components=best_n_components)\n",
    "X_train_pca_adasyn = pca_1.fit_transform(X_resampled_adasyn)\n",
    "print(X_train_pca_adasyn.shape)\n",
    "# did not actually use adasyn for test set, just using the naming to keep track which variables belong with their respective algorithms\n",
    "X_test_pca_adasyn = pca_1.transform(X_test)\n",
    "print(X_test_pca_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de567eeb-b7dd-420e-9bc0-9f7399c4b917",
   "metadata": {
    "id": "de567eeb-b7dd-420e-9bc0-9f7399c4b917"
   },
   "outputs": [],
   "source": [
    "pca_1.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560eeadc-b52e-4cb7-8a90-866c3c9b56f3",
   "metadata": {
    "id": "560eeadc-b52e-4cb7-8a90-866c3c9b56f3"
   },
   "outputs": [],
   "source": [
    "pca_1.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2151ba-3794-4e54-b103-e5eb0025b13c",
   "metadata": {
    "id": "9e2151ba-3794-4e54-b103-e5eb0025b13c"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_1.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7c701-2af2-4df8-baca-4d24bd382cdf",
   "metadata": {
    "id": "51f7c701-2af2-4df8-baca-4d24bd382cdf"
   },
   "outputs": [],
   "source": [
    "print(X_train_pca_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086cfcf7-7fb8-463d-917b-5fa00a37df97",
   "metadata": {
    "id": "086cfcf7-7fb8-463d-917b-5fa00a37df97"
   },
   "source": [
    "### 14 components seems to get me the closest to .95 or greater variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c842622-31df-4580-b0d2-52b5512b92cf",
   "metadata": {
    "id": "2c842622-31df-4580-b0d2-52b5512b92cf"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(PCA, X_resampled_rus, y_resampled_rus)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9cb1d-137b-4a46-a807-8abe44ab1e59",
   "metadata": {
    "id": "05d9cb1d-137b-4a46-a807-8abe44ab1e59"
   },
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=best_n_components)\n",
    "X_train_pca_rus = pca_2.fit_transform(X_resampled_rus)\n",
    "print(X_train_pca_rus.shape)\n",
    "# did not actually use rus for test set, just using the naming to keep track which variables belong with their respective algorithms\n",
    "X_test_pca_rus = pca_2.transform(X_test)\n",
    "print(X_test_pca_rus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0a3d5-9d36-4146-8602-86ae99b2e9e3",
   "metadata": {
    "id": "ddf0a3d5-9d36-4146-8602-86ae99b2e9e3"
   },
   "outputs": [],
   "source": [
    "pca_2.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0a445-6131-46f9-8f85-49c28c68fd64",
   "metadata": {
    "id": "bcd0a445-6131-46f9-8f85-49c28c68fd64"
   },
   "outputs": [],
   "source": [
    "pca_2.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19446e64-bd60-4924-bf49-f94024a7470f",
   "metadata": {
    "id": "19446e64-bd60-4924-bf49-f94024a7470f"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_2.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1effc-cd32-4981-a7be-d10ad1e312ae",
   "metadata": {
    "id": "5ae1effc-cd32-4981-a7be-d10ad1e312ae"
   },
   "outputs": [],
   "source": [
    "print(X_train_pca_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939a50d-cbe9-4dad-bd00-f9b5ba37a389",
   "metadata": {
    "id": "0939a50d-cbe9-4dad-bd00-f9b5ba37a389"
   },
   "source": [
    "### RandomForestClassifier models with one using the ADASYN training data and the other using the RandomUnderSampler data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c3956-026f-4a1a-b5e5-0a91b1597eaa",
   "metadata": {
    "id": "435c3956-026f-4a1a-b5e5-0a91b1597eaa"
   },
   "outputs": [],
   "source": [
    "rfc_pca_1_model = RandomForestClassifier(criterion='entropy')# need to verify this is the right criterion\n",
    "rfc_pca_1_model.fit(X_train_pca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b0b2a-f5c7-415b-9b2c-fc2ea9275a37",
   "metadata": {
    "id": "175b0b2a-f5c7-415b-9b2c-fc2ea9275a37"
   },
   "outputs": [],
   "source": [
    "rfc_pca_1_y_hat = rfc_pca_1_model.predict(X_test_pca_adasyn)\n",
    "print(rfc_pca_1_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7e3a9-cbaf-41e0-a950-bc9219d000aa",
   "metadata": {
    "id": "cda7e3a9-cbaf-41e0-a950-bc9219d000aa"
   },
   "outputs": [],
   "source": [
    "rfc_pca_1_precision = precision_score(y_test, rfc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_1_recall = recall_score(y_test, rfc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_1_f1 = f1_score(y_test, rfc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_1_accuracy = rfc_pca_1_model.score(X_test_pca_adasyn, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_pca_1_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_pca_1_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_pca_1_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_pca_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23c493-c50d-493b-80d0-e90ced884280",
   "metadata": {
    "id": "1c23c493-c50d-493b-80d0-e90ced884280"
   },
   "outputs": [],
   "source": [
    "rfc_pca_2_model = RandomForestClassifier(criterion='entropy')# need to verify this is the right criterion\n",
    "rfc_pca_2_model.fit(X_train_pca_rus, y_resampled_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e19ab-8fef-4791-8bdd-282f37b1967d",
   "metadata": {
    "id": "d83e19ab-8fef-4791-8bdd-282f37b1967d"
   },
   "outputs": [],
   "source": [
    "rfc_pca_2_y_hat = rfc_pca_2_model.predict(X_test_pca_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481a2ed-6619-4fe2-ac7d-a4f60a5d8a8f",
   "metadata": {
    "id": "2481a2ed-6619-4fe2-ac7d-a4f60a5d8a8f"
   },
   "outputs": [],
   "source": [
    "rfc_pca_2_precision = precision_score(y_test, rfc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_2_recall = recall_score(y_test, rfc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_2_f1 = f1_score(y_test, rfc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_pca_2_accuracy = rfc_pca_2_model.score(X_test_pca_rus, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_pca_2_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_pca_2_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_pca_2_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_pca_2_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c61d260-45f0-49f6-862b-8c0381e901a5",
   "metadata": {
    "id": "0c61d260-45f0-49f6-862b-8c0381e901a5"
   },
   "source": [
    "### When looking at the metrics there isn't much of a difference between using RandomUnderSampling and ADASYN. I may decide not use RandomUnderSampling for future models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c3e37-8d84-4f60-b256-74c315e6887f",
   "metadata": {
    "id": "732c3e37-8d84-4f60-b256-74c315e6887f"
   },
   "source": [
    "### Let's check with the decision tree models to see if there is any improvements. I'll use ADASYN and the RandomUnderSampling data sets again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49a307-5da8-4551-b56c-d9192df2488a",
   "metadata": {
    "id": "1f49a307-5da8-4551-b56c-d9192df2488a"
   },
   "outputs": [],
   "source": [
    "dtc_pca_1_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_pca_1_model.fit(X_train_pca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb94d07f-f779-4b30-bace-4df5cc874f6d",
   "metadata": {
    "id": "eb94d07f-f779-4b30-bace-4df5cc874f6d"
   },
   "outputs": [],
   "source": [
    "dtc_pca_1_y_hat = dtc_pca_1_model.predict(X_test_pca_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2286e-9667-4db1-aac7-9566f21b7037",
   "metadata": {
    "id": "f4e2286e-9667-4db1-aac7-9566f21b7037"
   },
   "outputs": [],
   "source": [
    "dtc_pca_1_precision = precision_score(y_test, dtc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_1_recall = recall_score(y_test, dtc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_1_f1 = f1_score(y_test, dtc_pca_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_1_accuracy = dtc_pca_1_model.score(X_test_pca_adasyn, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_pca_1_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_pca_1_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_pca_1_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_pca_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb6fae-5ac2-4ed9-9d23-99bb86ff9187",
   "metadata": {
    "id": "9afb6fae-5ac2-4ed9-9d23-99bb86ff9187"
   },
   "outputs": [],
   "source": [
    "dtc_pca_2_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_pca_2_model.fit(X_train_pca_rus, y_resampled_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d0435d-86a1-4fcc-9410-f2d171320c72",
   "metadata": {
    "id": "06d0435d-86a1-4fcc-9410-f2d171320c72"
   },
   "outputs": [],
   "source": [
    "dtc_pca_2_y_hat = dtc_pca_2_model.predict(X_test_pca_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633cb69-882f-4607-8cfe-08bc8f11913c",
   "metadata": {
    "id": "7633cb69-882f-4607-8cfe-08bc8f11913c"
   },
   "outputs": [],
   "source": [
    "dtc_pca_2_precision = precision_score(y_test, dtc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_2_recall = recall_score(y_test, dtc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_2_f1 = f1_score(y_test, dtc_pca_2_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_pca_2_accuracy = dtc_pca_2_model.score(X_test_pca_rus, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_pca_2_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_pca_2_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_pca_2_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_pca_2_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570fec1-eaf1-4898-8a28-9f54072ddaf9",
   "metadata": {
    "id": "6570fec1-eaf1-4898-8a28-9f54072ddaf9"
   },
   "source": [
    "### Using the RandomUnderSampling technique again didn't provide much benefit here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e82626-5319-47f7-b196-61e444f078e9",
   "metadata": {
    "id": "c5e82626-5319-47f7-b196-61e444f078e9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c771f-6fe3-45a4-962e-96ff5fcf1430",
   "metadata": {
    "id": "c16c771f-6fe3-45a4-962e-96ff5fcf1430"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(LinearDiscriminantAnalysis, X_resampled_adasyn, y_resampled_adasyn)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6703b0-6a08-4249-b6b2-34172c4904c3",
   "metadata": {
    "id": "9a6703b0-6a08-4249-b6b2-34172c4904c3"
   },
   "outputs": [],
   "source": [
    "lda_1 = LinearDiscriminantAnalysis(n_components=best_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072294e3-a9fe-4577-9445-44ee7933d292",
   "metadata": {
    "id": "072294e3-a9fe-4577-9445-44ee7933d292"
   },
   "outputs": [],
   "source": [
    "X_train_lda_adasyn = lda_1.fit_transform(X_resampled_adasyn, y_resampled_adasyn)\n",
    "X_test_lda_adasyn = lda_1.transform(X_test)\n",
    "print(X_train_lda_adasyn.shape)\n",
    "print(X_test_lda_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b74a78-9f4d-4ca1-be6a-4dae738ef01e",
   "metadata": {
    "id": "14b74a78-9f4d-4ca1-be6a-4dae738ef01e"
   },
   "outputs": [],
   "source": [
    "# need to update these\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(X_train_lda_adasyn, y_resampled_adasyn, c=y_resampled_adasyn, cmap='tab20')\n",
    "\n",
    "# plt.xlabel('LDA Component')\n",
    "# plt.ylabel('Class')\n",
    "# plt.title('LDA Component 1 vs Class')\n",
    "# plt.colorbar(label='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17756bb-8a57-4d23-9922-c8b3b6450e12",
   "metadata": {
    "id": "d17756bb-8a57-4d23-9922-c8b3b6450e12"
   },
   "outputs": [],
   "source": [
    "rfc_lda_1_model = RandomForestClassifier(criterion='entropy')\n",
    "rfc_lda_1_model.fit(X_train_lda_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d8aba-3543-4fa0-bdf7-06dc057eda92",
   "metadata": {
    "id": "fb5d8aba-3543-4fa0-bdf7-06dc057eda92"
   },
   "outputs": [],
   "source": [
    "rfc_lda_1_y_hat = rfc_lda_1_model.predict(X_test_lda_adasyn)\n",
    "print(rfc_lda_1_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606b8c0-a8e6-4f39-a776-c2c27849fe6b",
   "metadata": {
    "id": "f606b8c0-a8e6-4f39-a776-c2c27849fe6b"
   },
   "outputs": [],
   "source": [
    "rfc_lda_1_precision = precision_score(y_test, rfc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_lda_1_recall = recall_score(y_test, rfc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_lda_1_f1 = f1_score(y_test, rfc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_lda_1_accuracy = rfc_lda_1_model.score(X_test_lda_adasyn, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_lda_1_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_lda_1_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_lda_1_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_lda_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fee02f-9005-4272-95d7-d9736956c9cf",
   "metadata": {
    "id": "00fee02f-9005-4272-95d7-d9736956c9cf"
   },
   "outputs": [],
   "source": [
    "dtc_lda_1_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_lda_1_model.fit(X_train_lda_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b432053-a92d-44e0-94a2-8a9dae7f2c89",
   "metadata": {
    "id": "2b432053-a92d-44e0-94a2-8a9dae7f2c89"
   },
   "outputs": [],
   "source": [
    "dtc_lda_1_y_hat = dtc_lda_1_model.predict(X_test_lda_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0064b-cfcc-4dd4-8c64-0a34640bb846",
   "metadata": {
    "id": "32f0064b-cfcc-4dd4-8c64-0a34640bb846"
   },
   "outputs": [],
   "source": [
    "dtc_lda_1_precision = precision_score(y_test, dtc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_lda_1_recall = recall_score(y_test, dtc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_lda_1_f1 = f1_score(y_test, dtc_lda_1_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_lda_1_accuracy = dtc_lda_1_model.score(X_test_lda_adasyn, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_lda_1_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_lda_1_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_lda_1_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_lda_1_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418c57f-4da9-41af-b009-f4947cb83d58",
   "metadata": {
    "id": "0418c57f-4da9-41af-b009-f4947cb83d58"
   },
   "source": [
    "### With LDA proving to have lower metrics for both the RandomForestClassifier and DecisionTreeClassifiers, I do not believe using LinearDiscriminantAnalysis with the RandomUnderSampling technique will be much better so I'll go straight to Kernel PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e358b-fea6-4fe2-8114-3f825b43fa7f",
   "metadata": {
    "id": "725e358b-fea6-4fe2-8114-3f825b43fa7f"
   },
   "outputs": [],
   "source": [
    "# a chart here to display the metrics for both?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1bad0-f138-4a73-943a-5ba2fa9f2ebe",
   "metadata": {
    "id": "a3a1bad0-f138-4a73-943a-5ba2fa9f2ebe"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f76f7-24b0-4cec-8c43-309714b82a03",
   "metadata": {
    "id": "7c7f76f7-24b0-4cec-8c43-309714b82a03"
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('kpca', KernelPCA(kernel='rbf')),\n",
    "#     ('rfc', RandomForestClassifier(criterion='entropy'))\n",
    "# ])\n",
    "\n",
    "# n = np.arange(1,11)\n",
    "# param_grid = {\n",
    "#     'kpca__n_components': n,\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline, param_grid)\n",
    "# grid_search.fit(X_resampled_adasyn, y_resampled_adasyn)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# print(f\"Optimal parameters: {best_params}\")\n",
    "\n",
    "# kernel_pca_optimal = KernelPCA(n_components=best_params['kpca__n_components'], kernel='rbf')\n",
    "# X_train_kpca_adasyn = kernel_pca_optimal.fit_transform(X_resampled_adasyn)\n",
    "# X_test_kpca_adasyn = kernel_pca_optimal.transform(X_test)\n",
    "\n",
    "# rfc_kpca_model = RandomForestClassifier(criterion='entropy')\n",
    "# rfc_kpca_model.fit(X_train_kpca_adasyn, y_resampled_adasyn)\n",
    "\n",
    "# cv_scores = cross_val_score(rfc_kpca_model, X_train_kpca_adasyn, y_resampled_adasyn)\n",
    "# print(f\"Cross-validation scores: {cv_scores}\")\n",
    "# print(f\"Mean cross-validation score: {cv_scores.mean()}\")\n",
    "\n",
    "# test_score = rfc_kpca_model.score(X_test_kpca_adasyn, y_test)\n",
    "# print(f\"Test set score: {test_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124a6df-0f62-4a3d-b7ab-8883b6f1fe29",
   "metadata": {
    "id": "1124a6df-0f62-4a3d-b7ab-8883b6f1fe29"
   },
   "outputs": [],
   "source": [
    "# kernel_pca_1 = KernelPCA(n_components=2, kernel='rbf')\n",
    "# X_train_kpca_adasyn = kernel_pca_1.fit_transform(X_resampled_adasyn)\n",
    "# X_test_kpca_adasyn = kernel_pca_1.transform(X_test)\n",
    "# print(X_train_kpca_adasyn.shape)\n",
    "# print(X_test_kpca_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182de7d4-95e3-4c0b-8d2e-f15486dfadf5",
   "metadata": {
    "id": "182de7d4-95e3-4c0b-8d2e-f15486dfadf5"
   },
   "outputs": [],
   "source": [
    "best_explained_variance, best_n_components = find_best_explained_variance(KernelPCA, X_resampled_adasyn, y_resampled_adasyn)\n",
    "print(f\"Best explained variance: {best_explained_variance}\")\n",
    "print(f\"Optimal number of components: {best_n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1768152-7eff-4ef4-8f63-03c1b522e67f",
   "metadata": {
    "id": "a1768152-7eff-4ef4-8f63-03c1b522e67f"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(X_train_kpca_adasyn, X_train_kpca_adasyn, c=y_resampled_adasyn, cmap='tab20')\n",
    "\n",
    "# plt.xlabel('Kernel PCA Component 1')\n",
    "# plt.ylabel('Kernel PCA Component 2')\n",
    "# plt.title('Kernel PCA Component vs Class')\n",
    "# plt.colorbar(label='Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd08513-d902-4e1d-89ca-15e348ebecd2",
   "metadata": {
    "id": "acd08513-d902-4e1d-89ca-15e348ebecd2"
   },
   "outputs": [],
   "source": [
    "optimal_kpca = KernelPCA(n_components=best_n_components, kernel='rbf')\n",
    "X_train_kpca_adasyn = optimal_kpca.fit_transform(X_resampled_adasyn)\n",
    "X_test_kpca_adasyn = optimal_kpca.transform(X_test)\n",
    "print(X_train_kpca_adasyn.shape)\n",
    "print(X_test_kpca_adasyn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bada26b-9da0-4ba0-9454-77423c069f7c",
   "metadata": {
    "id": "1bada26b-9da0-4ba0-9454-77423c069f7c"
   },
   "outputs": [],
   "source": [
    "rfc_kpca_model = RandomForestClassifier(criterion='entropy')\n",
    "rfc_kpca_model.fit(X_train_kpca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca81b93-0098-4a8a-bf89-6e0ddb208ce4",
   "metadata": {
    "id": "1ca81b93-0098-4a8a-bf89-6e0ddb208ce4"
   },
   "outputs": [],
   "source": [
    "rfc_kpca_y_hat = rfc_kpca_model.predict(X_test_kpca_adasyn)\n",
    "print(rfc_kpca_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ab7a9-85f6-45c6-b1d6-b4b69cd5eb0b",
   "metadata": {
    "id": "690ab7a9-85f6-45c6-b1d6-b4b69cd5eb0b"
   },
   "outputs": [],
   "source": [
    "rfc_kpca_precision = precision_score(y_test, rfc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_kpca_recall = recall_score(y_test, rfc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_kpca_f1 = f1_score(y_test, rfc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "rfc_kpca_accuracy = rfc_kpca_model.score(X_test_kpca_adasyn, y_test)\n",
    "\n",
    "print(f\"RFC Precision: {rfc_kpca_precision:.2f}\")\n",
    "print(f\"RFC Recall: {rfc_kpca_recall:.2f}\")\n",
    "print(f\"RFC F1 Score: {rfc_kpca_f1:.2f}\")\n",
    "print(f\"RFC Accuracy: {rfc_kpca_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1094cd2-af52-46f3-920f-b7b96278acd9",
   "metadata": {
    "id": "f1094cd2-af52-46f3-920f-b7b96278acd9"
   },
   "outputs": [],
   "source": [
    "dtc_kpca_model = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc_kpca_model.fit(X_train_kpca_adasyn, y_resampled_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda52f5-c68f-40ec-a914-52af07916e48",
   "metadata": {
    "id": "eeda52f5-c68f-40ec-a914-52af07916e48"
   },
   "outputs": [],
   "source": [
    "dtc_kpca_y_hat = dtc_kpca_model.predict(X_test_kpca_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b49e4-b007-40f8-9ad5-3e72d601a7b8",
   "metadata": {
    "id": "fc5b49e4-b007-40f8-9ad5-3e72d601a7b8"
   },
   "outputs": [],
   "source": [
    "dtc_kpca_precision = precision_score(y_test, dtc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_kpca_recall = recall_score(y_test, dtc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_kpca_f1 = f1_score(y_test, dtc_kpca_y_hat, average='macro', zero_division=0.0)\n",
    "dtc_kpca_accuracy = dtc_kpca_model.score(X_test_kpca_adasyn, y_test)\n",
    "\n",
    "print(f\"DTC Precision: {dtc_kpca_precision:.2f}\")\n",
    "print(f\"DTC Recall: {dtc_kpca_recall:.2f}\")\n",
    "print(f\"DTC F1 Score: {dtc_kpca_f1:.2f}\")\n",
    "print(f\"DTC Accuracy: {dtc_kpca_accuracy: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc564b-bb6a-416c-808a-3167ad92d87d",
   "metadata": {
    "id": "04cc564b-bb6a-416c-808a-3167ad92d87d"
   },
   "source": [
    "### Both models did not do well with KPCA, which means I will want to stick with just PCA outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cb9d6-bc71-41ab-ace0-3359ada5f0c7",
   "metadata": {
    "id": "e40cb9d6-bc71-41ab-ace0-3359ada5f0c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad661f2f-fbe0-40a7-a176-340cae0a9581",
   "metadata": {
    "id": "ad661f2f-fbe0-40a7-a176-340cae0a9581"
   },
   "source": [
    "### Could use this code to compare all the models accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a86fe-69ff-44ad-bc15-74a6ddd7b9e6",
   "metadata": {
    "id": "7b4a86fe-69ff-44ad-bc15-74a6ddd7b9e6"
   },
   "outputs": [],
   "source": [
    "# need to update it still\n",
    "accuracies = {\n",
    "    'Logistic Regression': lr_accuracy,\n",
    "    'PCA 1': lr_accuracy_2,\n",
    "    'PCA 2': lr_accuracy_3,\n",
    "    'LDA': lr_accuracy_4,\n",
    "    'KPCA': lr_accuracy_5\n",
    "}\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(list(accuracies.keys()), list(accuracies.values()),\n",
    "         marker='o',\n",
    "         linestyle='-',\n",
    "         linewidth=2,\n",
    "         markersize=8)\n",
    "\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.xlabel('Models', fontsize=12)\n",
    "plt.ylabel('Accuracy Score', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "for i, v in enumerate(accuracies.values()):\n",
    "    plt.text(i, v, f'{v:.3f}',\n",
    "             ha='center',\n",
    "             va='bottom',\n",
    "             fontsize=10)\n",
    "\n",
    "plt.ylim(0, 1.0)  # Assuming accuracy values are between 0 and 1\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Accuracy'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
